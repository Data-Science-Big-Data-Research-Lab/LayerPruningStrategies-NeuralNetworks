{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1 - BACKWARD STRATEGY (BS)\n",
    "def backward_strategy_prune(model, target_layer_index):\n",
    "    \"\"\"\n",
    "    Removes a specific hidden layer and reconfigures weights to correctly connect\n",
    "    adjacent layers. Redirects weights from the pruned layer to the next layer,\n",
    "    adjusting their size if necessary.\n",
    "    \"\"\"\n",
    "    \n",
    "    layers = model.layers\n",
    "\n",
    "    if target_layer_index < 2 or target_layer_index >= len(layers) - 1:\n",
    "        raise ValueError(\"The hidden layer index must be between 2 and the total number of hidden layers.\")\n",
    "\n",
    "    print(\"\\n=== STARTING PRUNING PROCESS ===\")\n",
    "    print(f\"Target layer index to remove: {target_layer_index}\")\n",
    "    print(f\"Total layers in model: {len(layers)}\")\n",
    "\n",
    "    # Involved layers\n",
    "    previous_layer = layers[target_layer_index - 1]\n",
    "    layer_to_prune = layers[target_layer_index]\n",
    "    next_layer = layers[target_layer_index + 1]\n",
    "\n",
    "    print(\"\\n--- Layers Involved ---\")\n",
    "    print(f\"Previous Layer: {previous_layer.name}\")\n",
    "    print(f\"Layer to Prune: {layer_to_prune.name}\")\n",
    "    print(f\"Next Layer: {next_layer.name}\")\n",
    "\n",
    "    print(f\"\\nRetrieving weights and biases from target layer: {layer_to_prune.name}\")\n",
    "    print(f\"Using '{previous_layer.name}' as reference layer.\")\n",
    "\n",
    "    # Retrieve weights and biases\n",
    "    input_weights, input_bias = layer_to_prune.get_weights()\n",
    "    print(f\"\\nTarget layer weights (shape {input_weights.shape}):\\n{input_weights}\")\n",
    "    print(f\"Target layer bias:\\n{input_bias}\")\n",
    "\n",
    "    ref_weights, ref_bias = previous_layer.get_weights()\n",
    "    print(f\"\\nReference layer weights (shape {ref_weights.shape}):\\n{ref_weights}\")\n",
    "    print(f\"Reference layer bias:\\n{ref_bias}\")\n",
    "\n",
    "    num_neurons_prev = input_weights.shape[0]\n",
    "    num_neurons_prune = input_weights.shape[1]\n",
    "    num_neurons_next = next_layer.units\n",
    "\n",
    "    print(\"\\n--- Weight Adjustment ---\")\n",
    "    print(f\"Neurons in previous layer: {num_neurons_prev}\")\n",
    "    print(f\"Neurons in layer to prune: {num_neurons_prune}\")\n",
    "    print(f\"Neurons in next layer: {num_neurons_next}\")\n",
    "\n",
    "    if input_weights.shape[1] > num_neurons_next:\n",
    "        print(\"\\n------------------------- OPTION 1, BS ----------------------\")\n",
    "        print(\"\\nReducing weights and bias: selecting neurons based on absolute mean similarity.\")\n",
    "\n",
    "        # 1. Target layer means\n",
    "        origin_means = np.mean(input_weights, axis=0)\n",
    "        print(\"\\nMean vector (target layer):\")\n",
    "        print(np.round(origin_means, 4))\n",
    "\n",
    "        # 2. Next layer means\n",
    "        next_weights, _ = next_layer.get_weights()\n",
    "        reference_means = np.mean(next_weights, axis=0)\n",
    "        print(\"\\nMean vector (next layer):\")\n",
    "        print(np.round(reference_means, 4))\n",
    "\n",
    "        # 3. Select indices of the closest neurons (without repetition)\n",
    "        selected_indices = []\n",
    "        used_indices = set()\n",
    "        for ref_val in reference_means:\n",
    "            differences = np.abs(origin_means - ref_val)\n",
    "            sorted_order = np.argsort(differences)\n",
    "            for idx in sorted_order:\n",
    "                if idx not in used_indices:\n",
    "                    selected_indices.append(idx)\n",
    "                    used_indices.add(idx)\n",
    "                    break\n",
    "\n",
    "        print(\"\\nFinal selected indices based on mean similarity:\")\n",
    "        print(selected_indices)\n",
    "\n",
    "        # 4. Filter weights and biases using selected indices\n",
    "        input_weights = input_weights[:, selected_indices]\n",
    "        input_bias = input_bias[selected_indices]\n",
    "\n",
    "    elif input_weights.shape[1] < num_neurons_next:\n",
    "        print(\"\\n------- Next layer neuron count is larger; BS not applicable --------\")\n",
    "        return model\n",
    "\n",
    "    print(f\"New weights shape for connecting previous to next layer: {input_weights.shape}\")\n",
    "    print(f\"New adjusted bias shape: {input_bias.shape}\")\n",
    "\n",
    "    new_weights = input_weights\n",
    "    new_bias = input_bias\n",
    "\n",
    "    # FIXED FOR Keras 3/TF 2.16.1\n",
    "    # 1. Get model input shape\n",
    "    full_input_shape = model.input_shape\n",
    "    \n",
    "    # 2. Handle multiple inputs (if list)\n",
    "    if isinstance(full_input_shape, list):\n",
    "        full_input_shape = full_input_shape[0]\n",
    "        \n",
    "    # 3. Extract features dimension (e.g., 12 from (None, 12))\n",
    "    if isinstance(full_input_shape, tuple):\n",
    "        input_dim = full_input_shape[-1] \n",
    "    else:\n",
    "        raise ValueError(f\"Could not determine model input shape: {full_input_shape}\")\n",
    "\n",
    "    print(f\"\\n--- Creating new model with input_shape={input_dim} ---\")\n",
    "\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "\n",
    "    # Iterate through original model layers to build the new one\n",
    "    for i, layer in enumerate(layers[1:]): \n",
    "        # Skip non-Dense layers\n",
    "        if not isinstance(layer, keras.layers.Dense):\n",
    "            continue \n",
    "            \n",
    "        # Skip the pruned layer\n",
    "        if i + 1 == target_layer_index:\n",
    "            print(f\"Skipping layer: {layer.name}\")\n",
    "            continue\n",
    "            \n",
    "        # Reconstruct layer with original attributes\n",
    "        x = keras.layers.Dense(layer.units, activation=layer.activation, name=layer.name)(x)\n",
    "        print(f\"Adding layer: {layer.name} with {layer.units} units\")\n",
    "\n",
    "    new_model = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    print(\"\\n--- Adjusting weights in the new model ---\")\n",
    "    for layer in new_model.layers:\n",
    "        if isinstance(layer, keras.layers.Dense):\n",
    "            # 1. Assign the merged weights to the \"next\" layer\n",
    "            if layer.name == next_layer.name:\n",
    "                layer.set_weights([new_weights, new_bias])\n",
    "                print(f\"‚úÖ Assigned adjusted weights to layer: {layer.name}\")\n",
    "            # 2. Copy original weights for all other layers\n",
    "            else:\n",
    "                original_layer = next((c for c in model.layers if c.name == layer.name), None)\n",
    "                if original_layer is not None:\n",
    "                    layer.set_weights(original_layer.get_weights())\n",
    "                    print(f\"‚úÖ Copied original weights to layer: {layer.name}\")\n",
    "\n",
    "    # Re-compile model with original configuration\n",
    "    optimizer = keras.optimizers.Adam(epsilon=1e-8, learning_rate=learning_rate)\n",
    "    new_model.compile(optimizer=optimizer, loss='mae', metrics=['mse', 'mae'])\n",
    "\n",
    "    print(\"\\n=== PROCESS COMPLETE ===\")\n",
    "    new_model.summary()\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2 - FORWARD STRATEGY (FS)\n",
    "def forward_strategy_prune(model, target_layer_index):\n",
    "    import keras\n",
    "    import numpy as np\n",
    "    \n",
    "    layers = model.layers\n",
    "\n",
    "    if target_layer_index < 1 or target_layer_index >= len(layers) - 1:\n",
    "        raise ValueError(\"Index must correspond to a hidden layer (not input or output).\")\n",
    "\n",
    "    print(\"\\n=== STARTING PRUNING PROCESS (FS) ===\")\n",
    "\n",
    "    previous_layer = layers[target_layer_index - 1]\n",
    "    layer_to_prune = layers[target_layer_index]\n",
    "    next_layer = layers[target_layer_index + 1]\n",
    "\n",
    "    print(\"\\n--- Layers Involved ---\")\n",
    "    print(f\"Previous Layer: {previous_layer.name}\")\n",
    "    print(f\"Layer to Prune: {layer_to_prune.name}\")\n",
    "    print(f\"Next Layer: {next_layer.name}\")\n",
    "\n",
    "    # Original weights from the next layer\n",
    "    next_weights, next_bias = next_layer.get_weights()\n",
    "\n",
    "    print(f\"\\nLayer to prune: {layer_to_prune.name}\")\n",
    "    print(f\"Next layer: {next_layer.name}\")\n",
    "    print(f\"Original next layer weights shape: {next_weights.shape}\")\n",
    "\n",
    "    print(f\"\\nRetrieving weights and bias from target layer: {layer_to_prune.name}\")\n",
    "    print(f\"Using next layer '{next_layer.name}' as reference.\")\n",
    "\n",
    "    input_weights, input_bias = layer_to_prune.get_weights()\n",
    "    print(f\"\\nTarget layer weights (shape {input_weights.shape}):\\n{input_weights}\")\n",
    "    print(f\"Target layer bias:\\n{input_bias}\")\n",
    "\n",
    "    ref_weights, ref_bias = next_layer.get_weights()\n",
    "    print(f\"\\nReference layer weights (shape {ref_weights.shape}):\\n{ref_weights}\")\n",
    "    print(f\"Reference layer bias:\\n{ref_bias}\")\n",
    "\n",
    "    num_neurons_prev = input_weights.shape[0]\n",
    "    num_neurons_prune = input_weights.shape[1]\n",
    "    num_neurons_next = next_layer.units\n",
    "\n",
    "    print(\"\\n--- Weight Adjustment ---\")\n",
    "    print(f\"Neurons in previous layer: {num_neurons_prev}\")\n",
    "    print(f\"Neurons in layer to prune: {num_neurons_prune}\")\n",
    "    print(f\"Neurons in next layer: {num_neurons_next}\")\n",
    "\n",
    "    # --- CORRECTION 1: Determine new input dimension ---\n",
    "    if hasattr(previous_layer, \"units\"):\n",
    "        # If the previous layer is Dense, use its units\n",
    "        new_input_dim = previous_layer.units\n",
    "    else:\n",
    "        # If previous is InputLayer, use model's input shape\n",
    "        full_input_shape = model.input_shape\n",
    "        if isinstance(full_input_shape, list):\n",
    "            full_input_shape = full_input_shape[0]\n",
    "        # Extract feature dimension (e.g., 12 from (None, 12))\n",
    "        new_input_dim = full_input_shape[-1] \n",
    "    \n",
    "    output_neurons = next_layer.units\n",
    "\n",
    "    print(f\"\\nAdjusting weights for layer '{next_layer.name}' from {next_weights.shape} ‚Üí ({new_input_dim}, {output_neurons})\")\n",
    "\n",
    "    if next_weights.shape[0] > new_input_dim:\n",
    "        print(\"\\nüîª Row reduction via mean similarity\")\n",
    "        original_means = np.mean(next_weights, axis=1)\n",
    "        # Generate reference means with uniform spacing\n",
    "        reference_means = np.linspace(np.min(original_means), np.max(original_means), new_input_dim)\n",
    "\n",
    "        print(\"\\n‚ñ∂ Original row means:\")\n",
    "        print(original_means)\n",
    "\n",
    "        print(\"\\n‚ñ∂ Generated reference means (uniform spacing):\")\n",
    "        print(reference_means)\n",
    "\n",
    "        selected_indices = []\n",
    "        used_indices = set()\n",
    "        for i, ref in enumerate(reference_means):\n",
    "            distances = np.abs(original_means - ref)\n",
    "            sorted_order = np.argsort(distances)\n",
    "            print(f\"\\n‚Üí Comparing with reference {i} ({ref:.4f}):\")\n",
    "            print(\"  Distances:\", distances)\n",
    "            print(\"  Order:\", sorted_order)\n",
    "\n",
    "            for idx in sorted_order:\n",
    "                if idx not in used_indices:\n",
    "                    selected_indices.append(idx)\n",
    "                    used_indices.add(idx)\n",
    "                    print(f\"  ‚úÖ Selected index {idx} (mean {original_means[idx]:.4f})\")\n",
    "                    break\n",
    "\n",
    "        print(\"\\n‚úÖ Final indices selected to keep:\")\n",
    "        print(selected_indices)\n",
    "\n",
    "        # Slice the weights using the selected row indices\n",
    "        next_weights = next_weights[selected_indices, :]\n",
    "\n",
    "    elif next_weights.shape[0] < new_input_dim:\n",
    "        print(\"\\n----------- Next layer has more neurons; FS not applicable -----------\")\n",
    "        return model\n",
    "        \n",
    "    print(f\"\\n‚úÖ Final adjusted weights shape: {next_weights.shape}\")\n",
    "\n",
    "    # --- CORRECTION 2: Get input shape for model reconstruction ---\n",
    "    full_input_shape = model.input_shape\n",
    "    if isinstance(full_input_shape, list):\n",
    "        full_input_shape = full_input_shape[0]\n",
    "    input_dim = full_input_shape[-1] \n",
    "    \n",
    "    print(f\"\\n--- Creating new model with input_shape={input_dim} ---\")\n",
    "\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "\n",
    "    for i, layer in enumerate(layers[1:]):\n",
    "        if i + 1 == target_layer_index:\n",
    "            print(f\"Skipping pruned layer: {layer.name}\")\n",
    "            continue\n",
    "        \n",
    "        # Ensure only Dense layers are processed\n",
    "        if not isinstance(layer, keras.layers.Dense):\n",
    "            continue\n",
    "            \n",
    "        x = keras.layers.Dense(layer.units, activation=layer.activation, name=layer.name)(x)\n",
    "\n",
    "    new_model = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    # Assign weights to the new model\n",
    "    for layer in new_model.layers:\n",
    "        if isinstance(layer, keras.layers.Dense):\n",
    "            if layer.name == next_layer.name:\n",
    "                layer.set_weights([next_weights, next_bias])\n",
    "                print(f\"‚úÖ Assigned new weights to layer: {layer.name}\")\n",
    "            else:\n",
    "                # Copy original weights for unchanged layers\n",
    "                original_layer = next((c for c in model.layers if c.name == layer.name), None)\n",
    "                if original_layer:\n",
    "                    layer.set_weights(original_layer.get_weights())\n",
    "                    print(f\"‚úÖ Copied original weights to layer: {layer.name}\")\n",
    "\n",
    "    # Recompile with the global learning rate\n",
    "    optimizer = keras.optimizers.Adam(epsilon=1e-8, learning_rate=learning_rate)\n",
    "    new_model.compile(optimizer=optimizer, loss='mae', metrics=['mse', 'mae'])\n",
    "\n",
    "    print(\"\\n=== PROCESS COMPLETE ===\")\n",
    "    new_model.summary()\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARD PRUNING\n",
    "def standard_pruning(\n",
    "    original_model: keras.Model,\n",
    "    layer_index_to_remove: int,\n",
    ") -> keras.Model:\n",
    "    \"\"\"\n",
    "    Standard pruning that removes a hidden layer and reconstructs the model.\n",
    "    Note: This method does not preserve weights for the adjacent layers; \n",
    "    it simply defines a new architecture with one less layer.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. Extract configuration and index ---\n",
    "\n",
    "    # Hidden layers in your model start at index 1 (index 0 is InputLayer)\n",
    "    hidden_dense_layers = original_model.layers[1:-1]\n",
    "    \n",
    "    # The provided hidden layer index is 1-based (1, 2, 3...)\n",
    "    # For the `hidden_dense_layers` list, we use 0-based indexing, so we subtract 1.\n",
    "    remove_idx = layer_index_to_remove - 1\n",
    "\n",
    "    if remove_idx < 0 or remove_idx >= len(hidden_dense_layers):\n",
    "        print(f\"ERROR: Index {layer_index_to_remove} is out of the hidden layer range (1 to {len(hidden_dense_layers)}).\")\n",
    "        return original_model\n",
    "\n",
    "    # --- 2. Define New Architecture (Layer Pruning) ---\n",
    "\n",
    "    # Get the unit count for all original hidden layers\n",
    "    original_hidden_units = [layer.units for layer in hidden_dense_layers]\n",
    "    \n",
    "    # Create the new unit list by omitting the selected layer\n",
    "    reduced_hidden_units = (\n",
    "        original_hidden_units[:remove_idx] + \n",
    "        original_hidden_units[remove_idx+1:]\n",
    "    )\n",
    "\n",
    "    print(f\"Pruning hidden layer #{layer_index_to_remove} with {original_hidden_units[remove_idx]} units.\")\n",
    "    print(f\"New architecture (hidden units): {reduced_hidden_units}\")\n",
    "\n",
    "    # --- 3. Model Reconstruction ---\n",
    "\n",
    "    # Extract input shape and the original output layer activation\n",
    "    input_shape = original_model.input_shape[1:]\n",
    "    output_activation = original_model.layers[-1].activation.__name__\n",
    "    \n",
    "    input_layer = keras.Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    # Add reduced hidden layers\n",
    "    for units in reduced_hidden_units:\n",
    "        # Assuming 'tanh' as the standard activation for hidden layers\n",
    "        x = keras.layers.Dense(units, activation='tanh')(x)\n",
    "\n",
    "    # Add output layer\n",
    "    # Maintains 24 units and the original output activation\n",
    "    output_layer = keras.layers.Dense(24, activation=output_activation)(x)\n",
    "\n",
    "    # Create the reduced functional model\n",
    "    reduced_model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the reduced model\n",
    "    # Using the global 'learning_rate' variable defined previously\n",
    "    optimizer = keras.optimizers.Adam(epsilon=1e-8, learning_rate=learning_rate)\n",
    "    reduced_model.compile(optimizer=optimizer, loss='mae', metrics=['mae', 'mse'])\n",
    "    \n",
    "    print(\"\\n--- Reduced Model Summary ---\")\n",
    "    reduced_model.summary()\n",
    "    print(\"----------------------------------\\n\")\n",
    "    \n",
    "    return reduced_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMA 2 - FS\n",
    "def forwardStrategyPrune(model, indice_capa_oculta):    \n",
    "    capas = model.layers\n",
    "\n",
    "    if indice_capa_oculta < 1 or indice_capa_oculta >= len(capas) - 1:\n",
    "        raise ValueError(\"El √≠ndice debe ser el de una capa oculta, no input ni output.\")\n",
    "\n",
    "    print(\"\\n=== INICIO DEL PROCESO ===\")\n",
    "\n",
    "    capa_antes = capas[indice_capa_oculta - 1]\n",
    "    capa_eliminar = capas[indice_capa_oculta]\n",
    "    capa_despues = capas[indice_capa_oculta + 1]\n",
    "\n",
    "    print(\"\\n--- Capas involucradas ---\")\n",
    "    print(f\"Capa antes: {capa_antes.name}\")\n",
    "    print(f\"Capa a eliminar: {capa_eliminar.name}\")\n",
    "    print(f\"Capa despu√©s: {capa_despues.name}\")\n",
    "\n",
    "    # Pesos originales de la capa siguiente\n",
    "    pesos_siguiente, bias_siguiente = capa_despues.get_weights()\n",
    "\n",
    "    print(f\"\\nCapa a eliminar: {capa_eliminar.name}\")\n",
    "    print(f\"Capa siguiente: {capa_despues.name}\")\n",
    "    print(f\"Forma original de pesos de la capa siguiente: {pesos_siguiente.shape}\")\n",
    "\n",
    "    print(f\"\\nObteniendo pesos y bias de la capa a eliminar: {capa_eliminar.name}\")\n",
    "    print(f\"Usando la capa posterior '{capa_despues.name}' como referencia.\")\n",
    "\n",
    "    pesos_entrada, bias_entrada = capa_eliminar.get_weights()\n",
    "    print(f\"\\nPesos de la capa a eliminar (forma {pesos_entrada.shape}):\\n{pesos_entrada}\")\n",
    "    print(f\"Bias de la capa a eliminar:\\n{bias_entrada}\")\n",
    "\n",
    "    pesos_ref, bias_ref = capa_despues.get_weights()\n",
    "    print(f\"\\nPesos de la capa de referencia (forma {pesos_ref.shape}):\\n{pesos_ref}\")\n",
    "    print(f\"Bias de la capa de referencia:\\n{bias_ref}\")\n",
    "\n",
    "    num_neuronas_antes = pesos_entrada.shape[0]\n",
    "    num_neuronas_eliminar = pesos_entrada.shape[1]\n",
    "    num_neuronas_siguiente = capa_despues.units\n",
    "\n",
    "    print(\"\\n--- Ajuste de pesos ---\")\n",
    "    print(f\"N√∫mero de neuronas de la capa previa: {num_neuronas_antes}\")\n",
    "    print(f\"N√∫mero de neuronas de la capa a eliminar: {num_neuronas_eliminar}\")\n",
    "    print(f\"N√∫mero de neuronas de la capa siguiente: {num_neuronas_siguiente}\")\n",
    "\n",
    "    # --- CORRECCI√ìN 1: Obtener la nueva dimensi√≥n de entrada ---\n",
    "    if hasattr(capa_antes, \"units\"):\n",
    "        # Si la capa anterior es Dense, usamos sus units\n",
    "        neuronas_entrada_nueva = capa_antes.units\n",
    "    else:\n",
    "        # Si la capa anterior es la InputLayer, la dimensi√≥n es el input_shape del modelo\n",
    "        input_shape_full = model.input_shape\n",
    "        if isinstance(input_shape_full, list):\n",
    "            input_shape_full = input_shape_full[0]\n",
    "        # Extraer la dimensi√≥n de la caracter√≠stica (ej: 12 de (None, 12))\n",
    "        neuronas_entrada_nueva = input_shape_full[-1] \n",
    "    # --- FIN CORRECCI√ìN 1 ---\n",
    "    \n",
    "    neuronas_salida = capa_despues.units\n",
    "\n",
    "    print(f\"\\nAjustando pesos de la capa '{capa_despues.name}' de forma ({pesos_siguiente.shape}) ‚Üí ({neuronas_entrada_nueva}, {neuronas_salida})\")\n",
    "\n",
    "    if pesos_siguiente.shape[0] > neuronas_entrada_nueva:\n",
    "        print(\"\\nüîª Reducci√≥n de filas por similitud de medias\")\n",
    "        medias_originales = np.mean(pesos_siguiente, axis=1)\n",
    "        medias_referencia = np.linspace(np.min(medias_originales), np.max(medias_originales), neuronas_entrada_nueva)\n",
    "\n",
    "        print(\"\\n‚ñ∂ Medias de filas originales:\")\n",
    "        print(medias_originales)\n",
    "\n",
    "        print(\"\\n‚ñ∂ Medias de referencia generadas (espaciado uniforme):\")\n",
    "        print(medias_referencia)\n",
    "\n",
    "        indices_seleccionados = []\n",
    "        usadas = set()\n",
    "        for i, ref in enumerate(medias_referencia):\n",
    "            distancias = np.abs(medias_originales - ref)\n",
    "            orden = np.argsort(distancias)\n",
    "            print(f\"\\n‚Üí Comparando con referencia {i} ({ref:.4f}):\")\n",
    "            print(\" ¬†Distancias:\", distancias)\n",
    "            print(\" ¬†Orden:\", orden)\n",
    "\n",
    "            for idx in orden:\n",
    "                if idx not in usadas:\n",
    "                    indices_seleccionados.append(idx)\n",
    "                    usadas.add(idx)\n",
    "                    print(f\" ¬†‚úÖ Seleccionado √≠ndice {idx} (media {medias_originales[idx]:.4f})\")\n",
    "                    break\n",
    "\n",
    "        print(\"\\n‚úÖ √çndices seleccionados para mantener:\")\n",
    "        print(indices_seleccionados)\n",
    "\n",
    "        pesos_siguiente = pesos_siguiente[indices_seleccionados, :]\n",
    "\n",
    "    elif pesos_siguiente.shape[0] < neuronas_entrada_nueva:\n",
    "        print(\"\\n-----------La siguiente capa tiene mas neuronas que la actual, FS no apta-----------\")\n",
    "        return model\n",
    "        \n",
    "    print(f\"\\n‚úÖ Forma final de pesos ajustados: {pesos_siguiente.shape}\")\n",
    "\n",
    "    # --- CORRECCI√ìN 2: Obtener la dimensi√≥n de entrada para recrear el modelo ---\n",
    "    input_shape_full = model.input_shape\n",
    "    if isinstance(input_shape_full, list):\n",
    "        input_shape_full = input_shape_full[0]\n",
    "    # Extraer la dimensi√≥n de la caracter√≠stica\n",
    "    input_shape = input_shape_full[-1] \n",
    "    # --- FIN CORRECCI√ìN 2 ---\n",
    "    \n",
    "    print(f\"\\n--- Creando nuevo modelo con input_shape={input_shape} ---\")\n",
    "\n",
    "    inputs = keras.Input(shape=(input_shape,))\n",
    "    x = inputs\n",
    "\n",
    "    for i, capa in enumerate(capas[1:]):\n",
    "        if i + 1 == indice_capa_oculta:\n",
    "            print(f\"Omitiendo capa eliminada: {capa.name}\")\n",
    "            continue\n",
    "        \n",
    "        # Asegurarse de que solo agregamos capas Dense\n",
    "        if not isinstance(capa, keras.layers.Dense):\n",
    "            continue\n",
    "            \n",
    "        x = keras.layers.Dense(capa.units, activation=capa.activation, name=capa.name)(x)\n",
    "\n",
    "    nuevo_modelo = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    # Asignar pesos\n",
    "    for capa in nuevo_modelo.layers:\n",
    "        if isinstance(capa, keras.layers.Dense):\n",
    "            if capa.name == capa_despues.name:\n",
    "                capa.set_weights([pesos_siguiente, bias_siguiente])\n",
    "                print(f\"‚úÖ Asignados nuevos pesos a la capa: {capa.name}\")\n",
    "            else:\n",
    "                capa_original = next((c for c in model.layers if c.name == capa.name), None)\n",
    "                if capa_original:\n",
    "                    capa.set_weights(capa_original.get_weights())\n",
    "                    print(f\"‚úÖ Copiados pesos originales a la capa: {capa.name}\")\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(epsilon=1E-8, learning_rate=lr)\n",
    "    nuevo_modelo.compile(optimizer=optimizer, loss='mae', metrics=['mse', 'mae'])\n",
    "\n",
    "    print(\"\\n=== FINAL DEL PROCESO ===\")\n",
    "    nuevo_modelo.summary()\n",
    "\n",
    "    return nuevo_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_model_weights(model):\n",
    "    \"\"\"\n",
    "    Inspects the weights and biases of each layer in a Keras model.\n",
    "\n",
    "    Parameter:\n",
    "    - model: Keras/TensorFlow model object.\n",
    "\n",
    "    Prints:\n",
    "    - Name, type of each layer, and its weights if they are trainable.\n",
    "    \"\"\"\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        # Retrieve layer weights and biases\n",
    "        weights = layer.get_weights()  \n",
    "        print(f\"\\nüîπ Layer {i}: {layer.name} ({layer.__class__.__name__})\")\n",
    "\n",
    "        if weights:  # Check if the layer contains trainable parameters\n",
    "            for j, parameter_block in enumerate(weights):\n",
    "                print(f\"  - Weight Block {j}: {parameter_block.shape}\\n{parameter_block}\")\n",
    "        else:\n",
    "            print(\"  - ‚ö†Ô∏è This layer does not have trainable weights.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIO DEL PROCESO ===\n",
      "\n",
      "--- Capas involucradas ---\n",
      "Capa antes: dense_2\n",
      "Capa a eliminar: dense_3\n",
      "Capa despu√©s: dense_4\n",
      "\n",
      "Capa a eliminar: dense_3\n",
      "Capa siguiente: dense_4\n",
      "Forma original de pesos de la capa siguiente: (60, 60)\n",
      "\n",
      "Obteniendo pesos y bias de la capa a eliminar: dense_3\n",
      "Usando la capa posterior 'dense_4' como referencia.\n",
      "\n",
      "Pesos de la capa a eliminar (forma (90, 60)):\n",
      "[[-0.08882892  0.06672331  0.1106843  ... -0.20323947  0.06148278\n",
      "   0.2421428 ]\n",
      " [ 0.19140379 -0.21269378 -0.09361155 ...  0.22304621  0.17197263\n",
      "   0.004413  ]\n",
      " [ 0.06765034  0.22428113 -0.2594401  ...  0.08092441 -0.23108414\n",
      "   0.04495906]\n",
      " ...\n",
      " [ 0.07980245  0.17283972 -0.14182174 ... -0.18219991 -0.06776182\n",
      "   0.2398633 ]\n",
      " [ 0.1251675  -0.20480551 -0.07700592 ... -0.10676853 -0.02044641\n",
      "  -0.15120286]\n",
      " [ 0.04675413  0.06360561  0.07661088 ...  0.12218941  0.00556134\n",
      "   0.13549331]]\n",
      "Bias de la capa a eliminar:\n",
      "[ 2.73897741e-02 -1.60246436e-02  8.16922449e-03  1.95053068e-03\n",
      "  4.56092320e-02 -3.51369567e-02 -3.02716549e-02 -2.67758667e-02\n",
      " -3.74487862e-02  1.35333359e-01 -6.68897331e-02 -2.84438469e-02\n",
      "  9.67391655e-02  3.22757699e-02 -1.21693406e-02  2.51435991e-02\n",
      " -4.95005324e-02 -2.38665994e-02 -5.23240417e-02  4.98072885e-04\n",
      "  6.51273085e-03 -5.60807995e-02 -2.03549713e-02  2.55216081e-02\n",
      "  1.07644893e-01 -6.70335442e-02 -4.67160903e-02 -4.84559685e-03\n",
      "  5.87925166e-02  4.41458933e-02 -2.59422455e-02  4.71076258e-02\n",
      "  1.41094830e-02  5.63325733e-02  1.12256706e-02 -5.14149433e-03\n",
      "  2.42518075e-02  8.54641274e-02  8.08667755e-05 -8.74222023e-04\n",
      "  5.62789617e-03  4.88476045e-02  9.64339375e-02  1.47506315e-02\n",
      " -9.61676911e-02  2.97054071e-02 -1.35414791e-03 -2.96065509e-02\n",
      "  5.27343303e-02 -9.94409202e-04 -3.32511663e-02 -5.19828033e-03\n",
      " -1.58718918e-02 -4.75984141e-02  4.82498445e-02  1.55842332e-02\n",
      " -7.80916074e-03 -3.20461579e-02  1.05198786e-01 -1.47973597e-02]\n",
      "\n",
      "Pesos de la capa de referencia (forma (60, 60)):\n",
      "[[ 0.23371746 -0.1930981   0.04507841 ... -0.26897755  0.23074472\n",
      "   0.10804804]\n",
      " [ 0.04894358  0.28237346 -0.11289919 ...  0.00950653  0.01190446\n",
      "   0.15688206]\n",
      " [ 0.11591674  0.02417363 -0.08353303 ... -0.23445408 -0.24500091\n",
      "   0.22690506]\n",
      " ...\n",
      " [ 0.11188368 -0.03870755  0.1071846  ... -0.25112066 -0.24745269\n",
      "  -0.09890812]\n",
      " [-0.03688513 -0.20412323 -0.20081593 ...  0.23004872 -0.44579625\n",
      "   0.0603328 ]\n",
      " [ 0.21112017  0.09334805 -0.17777815 ...  0.06292927 -0.12918755\n",
      "  -0.28303707]]\n",
      "Bias de la capa de referencia:\n",
      "[ 0.0111679   0.05568569 -0.05688175 -0.03984217 -0.01020152 -0.05924926\n",
      " -0.01890121 -0.01028091  0.02779885 -0.0676383  -0.0558191  -0.05262298\n",
      "  0.00447822 -0.02968977 -0.03975218 -0.01237091 -0.06023223 -0.04476263\n",
      "  0.00495888 -0.00846515 -0.0088008   0.01533347  0.1224175   0.06516827\n",
      " -0.00321043  0.06416816 -0.07183813  0.12118856 -0.03181678 -0.02106484\n",
      "  0.03403269  0.02096535  0.00828536  0.0973163   0.00715945 -0.03187969\n",
      "  0.00623459  0.10258788 -0.04045923 -0.02361501  0.087715   -0.051567\n",
      " -0.03350686  0.07744898 -0.02872236  0.01762374  0.00291161 -0.00720261\n",
      " -0.00720211 -0.0086514   0.01267427 -0.00800382  0.03510587 -0.00128733\n",
      "  0.05508557 -0.02301784  0.01276125 -0.03138829  0.01084567 -0.08107482]\n",
      "\n",
      "--- Ajuste de pesos ---\n",
      "N√∫mero de neuronas de la capa previa: 90\n",
      "N√∫mero de neuronas de la capa a eliminar: 60\n",
      "N√∫mero de neuronas de la capa siguiente: 60\n",
      "\n",
      "Ajustando pesos de la capa 'dense_4' de forma ((60, 60)) ‚Üí (90, 60)\n",
      "\n",
      "-----------La siguiente capa tiene mas neuronas que la actual, FS no apta-----------\n"
     ]
    }
   ],
   "source": [
    "# Strategy Selection: 1 = Backward, 2 = Forward, 3 = Standard\n",
    "pruning_strategy = 2  \n",
    "target_hidden_layer = 4\n",
    "\n",
    "if pruning_strategy == 1:\n",
    "    # Option 1: Backward Strategy Pruning (BS)\n",
    "    model_pruned = backward_strategy_prune(model, target_hidden_layer)\n",
    "elif pruning_strategy == 2:\n",
    "    # Option 2: Forward Strategy Pruning (FS)\n",
    "    model_pruned = forward_strategy_prune(model, target_hidden_layer)\n",
    "elif pruning_strategy == 3:\n",
    "    # Option 3: Standard Layer Pruning (Classic)\n",
    "    model_pruned = standard_pruning(model, target_hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Capa 0: input_layer_14 (InputLayer)\n",
      "  - ‚ö†Ô∏è Esta capa no tiene pesos entrenables.\n",
      "\n",
      "üîπ Capa 1: dense_65 (Dense)\n",
      "  - Pesos 0: (12, 40)\n",
      "[[-0.09370826  0.1648086  -0.04056354  0.20126562 -0.01161632 -0.08252753\n",
      "  -0.29845887 -0.20267463  0.04238677  0.04885807 -0.3260325   0.16161369\n",
      "   0.22421041  0.19623907  0.03051327 -0.03902812  0.2757984   0.04351014\n",
      "   0.04160324  0.1769534  -0.259557    0.27386674 -0.13647202  0.24432117\n",
      "   0.22435176  0.13586353 -0.04853562 -0.20521729  0.12013845 -0.06374133\n",
      "  -0.02477405  0.02528322 -0.01590031  0.04751011 -0.17829372 -0.22820728\n",
      "   0.2971012  -0.2446874  -0.05363576 -0.03390842]\n",
      " [-0.29390913  0.09263787 -0.33330426 -0.18944603 -0.25264004  0.06865249\n",
      "   0.26102686 -0.18672867 -0.07013597  0.09645228  0.06126654 -0.10778011\n",
      "  -0.04747451 -0.22576983  0.1012185   0.02811892 -0.17445968  0.27496547\n",
      "   0.05527949  0.08184452 -0.17765856  0.11106235 -0.16169366  0.00613702\n",
      "  -0.3017288   0.14146754  0.33003038  0.2176185   0.01011087 -0.06358144\n",
      "  -0.12042985 -0.1060584  -0.21358882  0.27947208 -0.19307391 -0.01903724\n",
      "  -0.23455887 -0.02675616  0.2753932  -0.1896125 ]\n",
      " [-0.26939207  0.27747908 -0.19412225  0.27902788 -0.08136605  0.28964138\n",
      "  -0.20648159 -0.2956281  -0.1370177   0.05202961 -0.1731085   0.14865576\n",
      "  -0.19031373 -0.0383183  -0.24685442 -0.14666638  0.03356162  0.10568856\n",
      "   0.16149172  0.22826272  0.17022443  0.20379084  0.10024427 -0.06832308\n",
      "  -0.14731659 -0.10833056  0.09913034 -0.2745185  -0.32387698 -0.1791534\n",
      "  -0.12181991  0.14582454 -0.12226651 -0.20755619 -0.2249327   0.2176223\n",
      "  -0.31444594  0.25875318  0.28079832 -0.20829879]\n",
      " [-0.15439995  0.21333124  0.11753169  0.08511163 -0.18557075 -0.01272423\n",
      "  -0.27159604 -0.2256349   0.20650138  0.07550941  0.04795396 -0.24368428\n",
      "   0.17720138 -0.13995908  0.1768803   0.05924888 -0.08895902  0.14866209\n",
      "   0.32201278  0.03995647 -0.2544598  -0.10435997 -0.29794377  0.28524283\n",
      "   0.17503457 -0.21782349 -0.2726403   0.18434635 -0.05935012 -0.19358435\n",
      "  -0.27989942 -0.00462236  0.14090157 -0.2354305  -0.34011975  0.31958637\n",
      "   0.07327966  0.04409036  0.13200754  0.12367194]\n",
      " [-0.03310163 -0.3113926   0.00739078 -0.01883604  0.25578526  0.13243517\n",
      "   0.03294142 -0.02489055  0.17028438 -0.00102609 -0.07493197  0.09092353\n",
      "  -0.05263808  0.19322139  0.32566732  0.16368876  0.30576056 -0.30650708\n",
      "  -0.29189643  0.20622537  0.04041605 -0.251908    0.34270304  0.25272444\n",
      "  -0.10614295 -0.07854681  0.08594411 -0.33532733  0.25443453 -0.26658207\n",
      "   0.30882296  0.0126534  -0.10716984 -0.1433002   0.09414403 -0.29873616\n",
      "   0.25792852 -0.28742144  0.11824343  0.17652233]\n",
      " [-0.24377947 -0.0822511   0.14921087  0.26140392 -0.15766965  0.0508007\n",
      "   0.27264133  0.20830473 -0.33149594 -0.28266907  0.04778343  0.00311946\n",
      "   0.14875953  0.11249211 -0.19029416  0.22747043 -0.14579758  0.14133982\n",
      "   0.29986274  0.21604133 -0.07363102 -0.2880475  -0.11789533 -0.06015079\n",
      "  -0.01511521  0.00099744  0.02330038 -0.24601072  0.08284986 -0.28535154\n",
      "  -0.23204532  0.01423197  0.18746865  0.25010565  0.06396925 -0.21994627\n",
      "  -0.05323256  0.05517508  0.2080108   0.07281043]\n",
      " [-0.00279183 -0.3019396   0.21971141 -0.11885459  0.05804576  0.0874868\n",
      "   0.21447292 -0.2061064   0.13112588 -0.1034178  -0.3303023   0.11543312\n",
      "   0.0895704  -0.28894845  0.264774    0.3305203  -0.32188684  0.13014682\n",
      "   0.06979819  0.10505269 -0.04977207 -0.3179738  -0.23907536  0.09002981\n",
      "  -0.1750987  -0.25516793  0.12882715 -0.22816613  0.26913124 -0.12731232\n",
      "   0.06362611  0.21504276  0.27763513 -0.0215969   0.27451712  0.24761751\n",
      "   0.00396323 -0.15485577  0.15804717  0.30691338]\n",
      " [ 0.24037132  0.10598037  0.28595734  0.11648489 -0.18796535  0.19848831\n",
      "   0.3170248   0.01195098  0.15664637  0.13579714 -0.02239792  0.11164998\n",
      "  -0.03070947 -0.27540502 -0.14257655  0.04429071 -0.2719183   0.21303883\n",
      "   0.3058439   0.12754537 -0.04247689  0.24626167 -0.00950589 -0.23823096\n",
      "  -0.01382003 -0.2544704   0.27217087 -0.30701888 -0.0396012  -0.26470593\n",
      "  -0.27280307  0.13631028 -0.0638867   0.1474298   0.2993741  -0.19851424\n",
      "  -0.17592098  0.09611715 -0.08822445  0.30522346]\n",
      " [ 0.27226847  0.16410877 -0.24920925 -0.08390294 -0.15553305 -0.28246683\n",
      "  -0.10984225  0.03274951 -0.14622831 -0.04914873 -0.00497701 -0.21890023\n",
      "  -0.11529093 -0.02234435  0.17727396 -0.1096582   0.24485639  0.1311078\n",
      "   0.1416424   0.0409972  -0.16100696 -0.33709708  0.20030811 -0.24833359\n",
      "  -0.05514384 -0.3185604   0.15016374  0.35757962 -0.24895778  0.1459829\n",
      "  -0.11675497  0.31609082  0.14556989 -0.15097928  0.02680645  0.00993035\n",
      "   0.21616264  0.01933387  0.3272921  -0.13851625]\n",
      " [ 0.01160496  0.14035332  0.21988724  0.17396756 -0.27377293  0.21545497\n",
      "  -0.24191628 -0.08687075  0.13328257  0.09732132 -0.27361152  0.34319922\n",
      "   0.25943446  0.06098701 -0.22173087  0.0844253  -0.01889438 -0.161244\n",
      "  -0.03542536  0.24431486 -0.10669971  0.27772287 -0.08525141 -0.22972524\n",
      "  -0.11086882 -0.2899766   0.1764158   0.05576904  0.01940067 -0.12687983\n",
      "  -0.31176546 -0.15585564 -0.02198737  0.18158743  0.12090573 -0.3293099\n",
      "  -0.00777267  0.3427922  -0.31523687  0.01295295]\n",
      " [-0.15222558  0.27160177  0.1372835   0.1984555   0.2057898  -0.03733971\n",
      "  -0.23026437 -0.29715618 -0.22579859  0.2597583   0.31517187  0.003873\n",
      "  -0.11977936  0.19890243 -0.0277024  -0.07070708  0.20241153 -0.05011777\n",
      "  -0.2009041  -0.29907626 -0.2969692  -0.12837672 -0.04925374  0.25209808\n",
      "   0.19506077  0.20720887  0.01636712  0.18499884  0.05672893 -0.32088256\n",
      "   0.34551808  0.0168306  -0.07150984 -0.32796854 -0.27861804 -0.16139427\n",
      "   0.19036624 -0.09693537  0.10517665  0.05256628]\n",
      " [ 0.05500288  0.1606446   0.07957129 -0.06405731 -0.18238817 -0.22333165\n",
      "  -0.0714185  -0.01721171  0.12964979  0.1589977   0.21879943 -0.25674704\n",
      "  -0.04752989  0.2556359   0.03898714 -0.14841713 -0.23441234 -0.12091725\n",
      "  -0.05743549  0.21249017 -0.18293433 -0.07969837  0.33786473  0.16421905\n",
      "  -0.32539865  0.10963008  0.23128381 -0.03347775  0.01392824  0.26824728\n",
      "  -0.22563313 -0.07650235 -0.27081934 -0.16144581  0.23914962  0.01058443\n",
      "  -0.08265892 -0.20125428 -0.218358   -0.09629954]]\n",
      "  - Pesos 1: (40,)\n",
      "[-0.00015946 -0.01544077 -0.00694535 -0.00136549  0.01667873  0.00778993\n",
      "  0.00445124 -0.01540794  0.00783247 -0.0038645   0.00663894  0.00863584\n",
      " -0.00608933 -0.00765862 -0.00636873 -0.00699021  0.01009415  0.00077657\n",
      "  0.00317885 -0.0110099  -0.00266565 -0.00364317 -0.01084948 -0.00017546\n",
      "  0.00584826  0.00280209 -0.01319782 -0.00240331  0.00175663 -0.01181797\n",
      "  0.01022485 -0.00633098  0.00568186  0.01780739 -0.01716635  0.01486338\n",
      " -0.00204067 -0.00702358 -0.00766381  0.00687402]\n",
      "\n",
      "üîπ Capa 2: dense_66 (Dense)\n",
      "  - Pesos 0: (40, 60)\n",
      "[[ 0.11492094  0.11966398 -0.08762878 ...  0.2127994   0.238317\n",
      "  -0.15156628]\n",
      " [ 0.06667633 -0.16953804 -0.0100338  ...  0.03178664  0.12581512\n",
      "  -0.06719587]\n",
      " [ 0.13462824 -0.092703   -0.05398148 ... -0.06825818 -0.04627371\n",
      "   0.02669418]\n",
      " ...\n",
      " [-0.02558923  0.05632432  0.24952456 ...  0.06532087  0.09331114\n",
      "  -0.12650155]\n",
      " [-0.10579289  0.10783351 -0.08876651 ...  0.02276259 -0.05641151\n",
      "   0.02741361]\n",
      " [-0.22796649 -0.05964892 -0.07376745 ...  0.01203347 -0.16927782\n",
      "   0.05620176]]\n",
      "  - Pesos 1: (60,)\n",
      "[ 0.00739113  0.00296231  0.00024714 -0.00892219  0.01000487 -0.00274643\n",
      "  0.00547423  0.00712019  0.00411125  0.00256104  0.00563628 -0.00113014\n",
      " -0.02098165 -0.00155854  0.00675107  0.01054939 -0.00434957  0.01922797\n",
      "  0.00302092 -0.01216038 -0.00532472  0.00363371 -0.00039521  0.0022499\n",
      "  0.00192254 -0.01989438 -0.00922863 -0.00608169 -0.00380537  0.02859454\n",
      " -0.00802221 -0.01411367  0.01109087  0.01117563 -0.00239437  0.00166903\n",
      " -0.00066086 -0.01483597  0.00813614  0.00964791  0.00020759  0.02267933\n",
      " -0.00377752 -0.00087753 -0.00329181  0.00014134  0.00269309  0.00290385\n",
      "  0.00173101  0.00635185  0.01005517 -0.00880824  0.0031292  -0.02078521\n",
      "  0.01000595  0.00712689  0.00105383 -0.00208952  0.00634465  0.00325505]\n",
      "\n",
      "üîπ Capa 3: dense_67 (Dense)\n",
      "  - Pesos 0: (60, 80)\n",
      "[[-0.10608682  0.03607523 -0.06328054 ...  0.11862912  0.00807579\n",
      "   0.20795418]\n",
      " [ 0.03405995 -0.00769318  0.15778624 ... -0.10570003 -0.07080966\n",
      "   0.12239359]\n",
      " [-0.16343284  0.0499783   0.16744237 ... -0.15804815  0.2399104\n",
      "  -0.02973077]\n",
      " ...\n",
      " [-0.12427769 -0.11529586 -0.20618768 ... -0.05198215 -0.1262459\n",
      "   0.19679138]\n",
      " [-0.19952124  0.18787183  0.1101336  ... -0.12355266 -0.17228992\n",
      "   0.14924614]\n",
      " [ 0.1931655  -0.05368262  0.1682382  ...  0.09848569  0.13447517\n",
      "   0.02309386]]\n",
      "  - Pesos 1: (80,)\n",
      "[ 9.2885913e-03 -1.1263599e-02 -2.2369900e-03  4.5678588e-03\n",
      "  5.9097582e-03  1.2327321e-02  2.1360996e-04  8.5589447e-05\n",
      " -4.0211915e-03 -1.9207475e-05  1.0703498e-02  9.1202697e-03\n",
      "  1.4225784e-03 -2.8245142e-03  3.0243788e-03 -2.9148769e-03\n",
      "  7.8793000e-03  1.2364125e-02 -1.7320093e-02  4.7194008e-03\n",
      " -1.4554620e-03 -1.1118796e-02 -2.8449367e-03  5.3134309e-03\n",
      "  1.9814696e-03  1.1792431e-03  5.9857504e-03  2.3695419e-03\n",
      " -1.0278092e-02 -9.1182395e-05 -1.5479128e-03 -9.1016386e-03\n",
      "  1.7082606e-02  4.3059583e-03 -1.9575050e-03  1.8490624e-03\n",
      "  2.3885628e-03  1.1330980e-02 -2.7420567e-03  1.0232566e-02\n",
      " -2.7596336e-03 -1.7133019e-03 -6.8844967e-03 -3.8760852e-03\n",
      "  1.0019329e-03 -3.1018810e-04  3.7702096e-03  6.4186694e-04\n",
      "  3.8757403e-03  7.3604730e-05  4.0337453e-03  5.1299133e-03\n",
      "  2.7289274e-03 -8.6063351e-03  1.3336869e-03  7.4197270e-04\n",
      "  1.0406590e-02  3.0745578e-03 -5.8506615e-03 -2.2253452e-03\n",
      " -5.0837710e-03 -1.1624986e-03  8.7008281e-03  7.6153944e-04\n",
      "  5.1392480e-03 -4.6751006e-03  1.8848580e-03 -7.4974837e-04\n",
      " -9.8141842e-04  3.1370206e-03 -3.2022763e-03 -7.4977316e-03\n",
      " -4.1018515e-03  2.0374518e-03  4.3459763e-04 -5.6668301e-03\n",
      " -2.6740549e-02 -1.8345891e-04 -8.2760546e-03 -3.7295988e-03]\n",
      "\n",
      "üîπ Capa 4: dense_68 (Dense)\n",
      "  - Pesos 0: (80, 80)\n",
      "[[ 0.1676082   0.14400315 -0.02994482 ...  0.1431545   0.06770363\n",
      "   0.07861955]\n",
      " [ 0.18625672  0.1605919   0.05185982 ... -0.07977789  0.1085342\n",
      "   0.09883668]\n",
      " [ 0.1196783   0.07241159  0.16898702 ... -0.01090163 -0.13863769\n",
      "  -0.18608381]\n",
      " ...\n",
      " [ 0.12323667 -0.13565916 -0.00163673 ... -0.04367435 -0.07005361\n",
      "   0.06820615]\n",
      " [ 0.16430198  0.00482686  0.0392078  ... -0.16043457  0.01018622\n",
      "  -0.16995598]\n",
      " [ 0.11959296  0.01822918 -0.05914114 ... -0.0640229  -0.11208064\n",
      "   0.13564572]]\n",
      "  - Pesos 1: (80,)\n",
      "[-3.0627521e-03  2.6004820e-03  3.8496586e-03 -1.2969574e-03\n",
      " -7.6356246e-03 -7.6813432e-03 -3.2334652e-04  2.5260991e-03\n",
      "  2.5078396e-03  5.8574714e-03 -3.5924776e-04 -2.4250140e-03\n",
      " -6.2664128e-03 -7.4954843e-03 -4.1767373e-03  1.1470595e-02\n",
      " -7.4471242e-04 -4.2911558e-03 -5.0384579e-03  9.8782610e-03\n",
      "  3.3864003e-02  1.4037885e-03 -6.6495095e-03  3.1637594e-03\n",
      " -3.6944507e-03 -8.8008521e-03  1.0212683e-03  4.6619293e-03\n",
      " -3.5631638e-03 -1.1234125e-03 -5.0375918e-03  2.8839982e-03\n",
      "  2.0685964e-04 -1.0896377e-03 -1.0808072e-02 -1.8447203e-03\n",
      "  7.9219829e-04 -1.7744316e-04  2.7280863e-04 -8.3631743e-03\n",
      " -3.0687307e-03  5.9668547e-03 -7.4114319e-04 -1.5537710e-04\n",
      "  8.4406772e-04 -8.2706225e-05 -2.2608493e-03  6.6619636e-03\n",
      "  2.6158881e-03 -6.8883579e-03 -1.7908543e-02  3.3450662e-04\n",
      "  1.2341530e-02  2.3350515e-04  1.1421538e-02  6.7453841e-03\n",
      "  4.0096440e-03 -5.9764064e-03 -1.2346436e-03  4.9035992e-03\n",
      " -1.4549046e-03 -1.4453664e-05 -4.9573216e-03 -7.6589826e-04\n",
      "  3.6278300e-03  1.7378818e-02 -1.3096310e-02 -2.4145478e-03\n",
      "  1.2872962e-03 -2.2312179e-03 -2.1570048e-03  6.7740800e-03\n",
      "  8.0183253e-04 -3.8656392e-04  4.6779430e-03 -4.4404087e-03\n",
      " -1.0407979e-03  1.3033649e-03  9.2795235e-04  8.8427553e-04]\n",
      "\n",
      "üîπ Capa 5: dense_69 (Dense)\n",
      "  - Pesos 0: (80, 70)\n",
      "[[-0.00537548  0.09631748  0.03362076 ...  0.17276724  0.16027534\n",
      "  -0.16347511]\n",
      " [-0.15472803 -0.02063469 -0.17636144 ...  0.09646577  0.09553502\n",
      "   0.16314726]\n",
      " [-0.1546117  -0.00421278  0.18581544 ... -0.05435497  0.13604048\n",
      "   0.18226255]\n",
      " ...\n",
      " [-0.11287683 -0.08003858  0.0127928  ...  0.06037443  0.18629904\n",
      "  -0.14718063]\n",
      " [ 0.01936869  0.03188994  0.15302277 ... -0.09690366 -0.16235676\n",
      "   0.03849727]\n",
      " [-0.18897444 -0.03668327  0.05853616 ... -0.15659955  0.03970696\n",
      "   0.04327745]]\n",
      "  - Pesos 1: (70,)\n",
      "[-1.7140382e-03 -3.5996153e-03  1.4112712e-02 -5.9259718e-04\n",
      " -5.6568375e-03 -1.0310664e-03 -2.1888399e-03 -5.7434877e-03\n",
      "  2.4589887e-03 -7.3298765e-04 -3.8911307e-03 -7.1166549e-05\n",
      "  3.1027442e-04 -1.5918514e-03 -6.2762736e-04  1.2254484e-03\n",
      " -1.3688690e-03 -8.0666761e-04  3.8099340e-03 -4.2250194e-04\n",
      "  2.7024554e-04  5.9730659e-04  9.4963135e-03 -2.3001649e-03\n",
      "  3.7594740e-03 -2.9160990e-03  1.8512051e-03  4.4483682e-03\n",
      "  2.6631418e-03 -4.9603656e-03  1.5207359e-03  6.6383453e-03\n",
      " -2.6069066e-04  1.5730890e-02  1.5150798e-04  2.0263612e-03\n",
      "  2.7080793e-03 -1.1986246e-02  4.0411530e-03 -7.5756446e-03\n",
      " -1.0626836e-03  1.1541931e-03  1.7140801e-03  1.1230456e-03\n",
      "  5.0919165e-04  4.1829338e-03 -4.7942838e-03  3.5535362e-05\n",
      " -2.3412041e-03  3.7976154e-03 -1.9307939e-03 -8.9018210e-04\n",
      "  1.2209684e-03 -1.6545619e-04  1.4983246e-03 -9.7165089e-03\n",
      "  5.0918601e-04  2.0886110e-03  3.7176721e-03  1.0795270e-03\n",
      "  5.4142317e-03 -1.0948430e-03  4.4361851e-04 -1.6153946e-03\n",
      "  1.1387839e-03  6.1154511e-04 -2.9251329e-04 -2.3766658e-03\n",
      " -7.3545217e-04 -3.2008547e-04]\n",
      "\n",
      "üîπ Capa 6: dense_70 (Dense)\n",
      "  - Pesos 0: (70, 30)\n",
      "[[-0.0572822  -0.04478326 -0.24355897 ... -0.04998172  0.16011594\n",
      "  -0.18396781]\n",
      " [ 0.19791098 -0.2439152  -0.04821352 ... -0.180215    0.05792432\n",
      "   0.09601128]\n",
      " [ 0.06357272  0.14619154 -0.08151475 ...  0.18793428 -0.20890847\n",
      "   0.03867467]\n",
      " ...\n",
      " [ 0.11200663  0.10837794  0.03246728 ... -0.22998136  0.04627914\n",
      "  -0.13057277]\n",
      " [ 0.0914312  -0.17946884  0.0575766  ...  0.08076323 -0.00938431\n",
      "  -0.06699113]\n",
      " [-0.20021287  0.09238353  0.17030899 ...  0.11290384  0.10659574\n",
      "  -0.13206972]]\n",
      "  - Pesos 1: (30,)\n",
      "[ 3.9804978e-03  1.6351128e-03 -6.6269291e-05  1.1049142e-03\n",
      "  2.3693782e-03 -6.3598814e-04  7.4678725e-03  4.9212086e-04\n",
      " -2.0206594e-03  7.4533089e-03 -5.7992764e-04 -1.9817255e-04\n",
      "  2.0095014e-03 -6.6472413e-03 -2.7175224e-04 -1.6249201e-03\n",
      "  8.6805079e-04  2.4150636e-03  1.2941159e-02  2.1029357e-02\n",
      " -9.0312125e-04  1.6099617e-05 -7.3618195e-03  7.1462378e-04\n",
      " -4.3694889e-03  1.4708253e-03 -2.5241598e-04 -6.8017413e-05\n",
      " -7.5738505e-04 -1.7159791e-03]\n",
      "\n",
      "üîπ Capa 7: dense_71 (Dense)\n",
      "  - Pesos 0: (30, 70)\n",
      "[[ 0.02925821 -0.21657938 -0.21905068 ... -0.06048652  0.06241437\n",
      "  -0.02625688]\n",
      " [ 0.06150954  0.00580834  0.22095656 ...  0.03280517 -0.18537982\n",
      "   0.1785157 ]\n",
      " [ 0.06511502  0.15469639 -0.10700864 ...  0.17404556 -0.13913742\n",
      "   0.22664294]\n",
      " ...\n",
      " [ 0.17425083  0.18171981  0.18206815 ...  0.20272048 -0.16971257\n",
      "  -0.09075041]\n",
      " [-0.25995818  0.06066614  0.13987076 ... -0.22323306 -0.23532976\n",
      "   0.03967312]\n",
      " [-0.07088081  0.06925678  0.20352781 ... -0.19793895  0.17911227\n",
      "  -0.03821677]]\n",
      "  - Pesos 1: (70,)\n",
      "[ 0.01420351  0.00208704 -0.00178142  0.00061722  0.00209306  0.00095346\n",
      "  0.0021252   0.00454157  0.0064567   0.00187016 -0.00109073  0.00167469\n",
      "  0.0016927  -0.00261632  0.00708979 -0.00346936 -0.0007635   0.00204552\n",
      " -0.00429573 -0.0007114   0.00511519 -0.00095617  0.00423976  0.01076115\n",
      " -0.00276729 -0.00258013  0.00273939  0.0023027  -0.01077158 -0.00108897\n",
      " -0.00144289 -0.00017126  0.00065975 -0.00241797 -0.00179048 -0.00063572\n",
      " -0.02016701 -0.00244249  0.00056144  0.00376078 -0.00189416  0.00310166\n",
      " -0.003387   -0.00274001  0.001203   -0.00314045  0.00264413 -0.00987351\n",
      " -0.00133661 -0.00131582 -0.00096668  0.0041019  -0.00021546  0.00274977\n",
      " -0.00065063  0.01191158  0.00544141  0.0018357   0.00280889 -0.0082397\n",
      " -0.00867153 -0.00093597  0.00031435  0.00162817  0.00013849 -0.00275696\n",
      " -0.00117544 -0.00236827  0.00032207  0.00506   ]\n",
      "\n",
      "üîπ Capa 8: dense_72 (Dense)\n",
      "  - Pesos 0: (70, 70)\n",
      "[[ 0.14263618  0.04633788  0.12742923 ...  0.04190784 -0.09957184\n",
      "  -0.09983855]\n",
      " [ 0.11279597 -0.16477989 -0.09085345 ... -0.17105582 -0.15424669\n",
      "   0.06371266]\n",
      " [-0.05484029  0.06130867 -0.04282324 ... -0.06527739  0.09396312\n",
      "   0.15794408]\n",
      " ...\n",
      " [ 0.0302594  -0.12523708  0.04760653 ...  0.04238617  0.02891629\n",
      "   0.13377264]\n",
      " [-0.19516663  0.14063336 -0.12267358 ...  0.16304529 -0.10125075\n",
      "   0.16368723]\n",
      " [-0.15523086  0.19224386  0.04416298 ... -0.06552156 -0.10033971\n",
      "  -0.05197401]]\n",
      "  - Pesos 1: (70,)\n",
      "[-0.00051597  0.00477     0.01076919 -0.00269393  0.00239882  0.00332486\n",
      " -0.00377453 -0.00698879 -0.00895463 -0.00270485  0.00120399 -0.01044554\n",
      "  0.00453418 -0.00010901 -0.00355097  0.00187376  0.00112494 -0.00381862\n",
      " -0.00571527  0.00042936 -0.00080281  0.00140721  0.031514    0.00056845\n",
      "  0.00324485 -0.00052124 -0.0044281  -0.00212947 -0.0024969   0.00241625\n",
      "  0.00106984  0.00248603  0.00774493  0.00914011 -0.00658887 -0.00205804\n",
      "  0.00660224 -0.00187036 -0.00231655 -0.0002346   0.00239484  0.00111338\n",
      " -0.00210507 -0.0009127  -0.0019028   0.0021954  -0.00224824 -0.00073702\n",
      " -0.00287368 -0.00292457  0.00262824  0.00189266 -0.00070454  0.00263857\n",
      "  0.00259477 -0.00136987  0.00119798 -0.0031546   0.00213655 -0.00098024\n",
      " -0.00079346 -0.00152643 -0.00460598 -0.00021262 -0.00209319  0.0047548\n",
      " -0.00247032 -0.00354931  0.00740057 -0.00787834]\n",
      "\n",
      "üîπ Capa 9: dense_73 (Dense)\n",
      "  - Pesos 0: (70, 30)\n",
      "[[-0.01499635  0.02576076  0.08102421 ... -0.00862523 -0.03549709\n",
      "  -0.1678079 ]\n",
      " [ 0.13892175  0.24650137  0.08317547 ...  0.23480566 -0.03405192\n",
      "   0.14688627]\n",
      " [ 0.19813168 -0.10347524 -0.07269574 ...  0.02590105  0.19465531\n",
      "  -0.13492845]\n",
      " ...\n",
      " [-0.00966195 -0.15968351  0.16845886 ... -0.23223951 -0.19861358\n",
      "  -0.13726184]\n",
      " [-0.1393497  -0.04089518  0.1508299  ... -0.16680402  0.15738577\n",
      "   0.1343412 ]\n",
      " [-0.05799662 -0.11248238 -0.17822681 ... -0.08017621  0.13870877\n",
      "  -0.07101724]]\n",
      "  - Pesos 1: (30,)\n",
      "[ 0.00160171 -0.0011744  -0.00955403 -0.0044128  -0.00524144 -0.00146118\n",
      " -0.00091272  0.00100836  0.00470012 -0.00262937  0.00183967 -0.00468721\n",
      "  0.00326239  0.00437855 -0.00309929  0.00022507 -0.00394417  0.00234318\n",
      "  0.00264716 -0.00404426  0.00356611 -0.0024908  -0.00429114  0.00244984\n",
      "  0.00197664 -0.0038123  -0.00280661  0.00329305  0.00354384  0.00253043]\n",
      "\n",
      "üîπ Capa 10: dense_74 (Dense)\n",
      "  - Pesos 0: (30, 70)\n",
      "[[ 0.23377998 -0.1612903   0.12929606 ...  0.00856989  0.05056198\n",
      "  -0.00810315]\n",
      " [-0.10707744 -0.02734374 -0.04569679 ...  0.17261277  0.16667317\n",
      "   0.17172296]\n",
      " [-0.11084775  0.06884986  0.20373584 ...  0.13583188  0.02644454\n",
      "   0.16387236]\n",
      " ...\n",
      " [ 0.01513486 -0.14105809  0.03703817 ...  0.12949428 -0.06482385\n",
      "  -0.03654363]\n",
      " [ 0.04056544 -0.03648943  0.20415087 ...  0.03432176 -0.2167589\n",
      "   0.06786938]\n",
      " [ 0.16545506  0.03474021 -0.17935857 ... -0.22849779  0.03064802\n",
      "  -0.11086825]]\n",
      "  - Pesos 1: (70,)\n",
      "[ 0.00298763  0.00379388  0.0047887  -0.00177841  0.00044668  0.00258476\n",
      "  0.00329952 -0.00297026  0.00325193  0.0022754  -0.0044637  -0.00557331\n",
      "  0.00335169  0.00339202  0.00303375  0.00274497 -0.00234725  0.00068215\n",
      "  0.00325838  0.00912907 -0.00255536 -0.0023239   0.00721413  0.00333376\n",
      "  0.00182422  0.0040107  -0.00097991 -0.00303099 -0.0022462   0.00304939\n",
      " -0.00672587 -0.00299491 -0.00383233  0.00269747 -0.0014251   0.00440963\n",
      "  0.00260348 -0.00300197 -0.00889407 -0.00321892  0.00460117 -0.00238491\n",
      "  0.00266437  0.00198913  0.00255828  0.00299948  0.00020332  0.00229311\n",
      " -0.00423559  0.00199797 -0.00282534  0.00238958  0.00394783 -0.00329207\n",
      " -0.00282131 -0.00400997 -0.00305131  0.00126293  0.0027522  -0.00305967\n",
      " -0.0046631  -0.00212029 -0.00257733 -0.00626622 -0.00275599 -0.00256735\n",
      "  0.0016624   0.00066223 -0.00335352  0.00206749]\n",
      "\n",
      "üîπ Capa 11: dense_75 (Dense)\n",
      "  - Pesos 0: (70, 20)\n",
      "[[ 0.07957371 -0.11157481  0.02538999 ...  0.07533664  0.17664471\n",
      "  -0.10251479]\n",
      " [ 0.12012471 -0.04286312  0.19270189 ... -0.07671645 -0.08182049\n",
      "   0.02923805]\n",
      " [ 0.21222256  0.0423151  -0.24557877 ... -0.01442664 -0.24386086\n",
      "   0.03670026]\n",
      " ...\n",
      " [-0.16340668 -0.14862154  0.00759646 ...  0.01090204  0.05172972\n",
      "   0.21722102]\n",
      " [ 0.0394811   0.24057852 -0.24431168 ... -0.01369335  0.27613163\n",
      "  -0.04670892]\n",
      " [ 0.14446059  0.05546029 -0.01390059 ... -0.05384252 -0.240457\n",
      "  -0.04184653]]\n",
      "  - Pesos 1: (20,)\n",
      "[ 3.8565630e-03 -3.0948329e-03  2.9936063e-03  2.4972560e-03\n",
      " -3.3670384e-03 -2.6253117e-03 -3.1749052e-03  1.9308863e-03\n",
      " -5.6237984e-03 -4.8313076e-03  3.0526693e-03 -2.9992987e-03\n",
      "  3.0814670e-03 -1.5648831e-02 -3.4845502e-03 -3.3102110e-03\n",
      " -3.9584697e-03  8.6935019e-05  3.6305906e-03 -3.1711233e-03]\n",
      "\n",
      "üîπ Capa 12: dense_76 (Dense)\n",
      "  - Pesos 0: (20, 60)\n",
      "[[-0.23947988 -0.03296357 -0.21436642 ...  0.25065282  0.15965828\n",
      "   0.16486363]\n",
      " [ 0.06347056  0.01391031 -0.07585187 ...  0.22151802  0.12770408\n",
      "  -0.25240824]\n",
      " [ 0.12046175  0.02008232  0.22935215 ... -0.17085834  0.02744587\n",
      "   0.24371448]\n",
      " ...\n",
      " [-0.18407954  0.09364296  0.15525658 ...  0.03802914  0.02088518\n",
      "   0.00541358]\n",
      " [-0.01982836 -0.05325431 -0.18741211 ...  0.01598323 -0.18265367\n",
      "   0.0203526 ]\n",
      " [ 0.08292952  0.12209441 -0.256535   ...  0.12117828  0.22912931\n",
      "  -0.23350193]]\n",
      "  - Pesos 1: (60,)\n",
      "[ 0.00420171 -0.00354312  0.00399531  0.00440894  0.0025176  -0.00400685\n",
      " -0.00410902  0.00356304 -0.00419707  0.00384356  0.00397584 -0.00300009\n",
      "  0.00424652  0.00442437  0.00436973  0.00402188 -0.00416056  0.00340239\n",
      " -0.00427072 -0.00390653  0.00432575  0.00406683  0.00316564  0.00422287\n",
      "  0.00367838  0.00447909  0.00396014 -0.00410162 -0.00289084 -0.00314311\n",
      "  0.00406994 -0.00429361 -0.00424202 -0.00416433 -0.00349164  0.00408575\n",
      "  0.00419462  0.00396951 -0.00390121  0.00445297  0.00384048 -0.00403782\n",
      " -0.00419545  0.00343637  0.0043034   0.00305702 -0.00439897  0.00409744\n",
      " -0.00398466 -0.00345987  0.00435327  0.00379386 -0.00413777  0.00379393\n",
      "  0.00395873  0.00451272  0.00254866 -0.00399978  0.00449015  0.00345293]\n",
      "\n",
      "üîπ Capa 13: dense_77 (Dense)\n",
      "  - Pesos 0: (60, 1)\n",
      "[[ 0.30339408]\n",
      " [-0.25767502]\n",
      " [ 0.22851272]\n",
      " [ 0.2996451 ]\n",
      " [ 0.30578646]\n",
      " [-0.15560094]\n",
      " [-0.20279178]\n",
      " [ 0.32001123]\n",
      " [-0.2670629 ]\n",
      " [ 0.01613952]\n",
      " [ 0.24431308]\n",
      " [-0.28504717]\n",
      " [ 0.2851922 ]\n",
      " [ 0.16749787]\n",
      " [ 0.12982461]\n",
      " [ 0.09436976]\n",
      " [-0.2157519 ]\n",
      " [ 0.2340564 ]\n",
      " [-0.19801776]\n",
      " [-0.20145048]\n",
      " [ 0.16525409]\n",
      " [ 0.06409822]\n",
      " [ 0.24772511]\n",
      " [ 0.10023061]\n",
      " [ 0.24897824]\n",
      " [ 0.26023105]\n",
      " [ 0.2411335 ]\n",
      " [-0.14561322]\n",
      " [-0.00183977]\n",
      " [-0.15970375]\n",
      " [ 0.2827731 ]\n",
      " [-0.18880963]\n",
      " [-0.14754646]\n",
      " [-0.08276491]\n",
      " [-0.07846962]\n",
      " [ 0.06988283]\n",
      " [ 0.17882833]\n",
      " [ 0.21063106]\n",
      " [-0.1436294 ]\n",
      " [ 0.3004852 ]\n",
      " [ 0.1135246 ]\n",
      " [-0.07758784]\n",
      " [-0.0350162 ]\n",
      " [ 0.02996452]\n",
      " [ 0.20162532]\n",
      " [ 0.0462306 ]\n",
      " [-0.00905516]\n",
      " [ 0.29509282]\n",
      " [-0.07062191]\n",
      " [-0.30493617]\n",
      " [ 0.30347845]\n",
      " [ 0.10970571]\n",
      " [-0.20478685]\n",
      " [ 0.00717148]\n",
      " [ 0.3223682 ]\n",
      " [ 0.02030658]\n",
      " [ 0.25251126]\n",
      " [-0.1957959 ]\n",
      " [ 0.23706701]\n",
      " [ 0.09537455]]\n",
      "  - Pesos 1: (1,)\n",
      "[0.00420095]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the weights of the model before the pruning process\n",
    "inspect_model_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Capa 0: input_layer_5 (InputLayer)\n",
      "  - ‚ö†Ô∏è Esta capa no tiene pesos entrenables.\n",
      "\n",
      "üîπ Capa 1: dense_66 (Dense)\n",
      "  - Pesos 0: (12, 60)\n",
      "[[-0.20643388  0.01737381 -0.00188578  0.00556127 -0.10054328 -0.2519836\n",
      "  -0.1667882   0.07135277 -0.17053965  0.1275013   0.04329761  0.08041992\n",
      "  -0.1192439  -0.11776188 -0.01921184  0.10459366 -0.11548372  0.08950839\n",
      "   0.1624882  -0.16331919  0.03551297  0.11267059 -0.04133165  0.03294617\n",
      "   0.13955274  0.12717809 -0.11313774 -0.1067669   0.06422283  0.09431536\n",
      "  -0.12213927 -0.08069505 -0.21390247 -0.07917381 -0.16724993 -0.14692762\n",
      "  -0.12473761  0.15342925  0.22386019 -0.08436671 -0.13789415  0.17510635\n",
      "  -0.14657678  0.07016288 -0.0576023  -0.18092096 -0.12540042 -0.05903937\n",
      "  -0.21648926  0.10846126 -0.04665549 -0.17362091 -0.19607621  0.17490526\n",
      "  -0.14085928  0.14255056 -0.01416865 -0.10074482 -0.04997594 -0.01044213]\n",
      " [ 0.20612204 -0.06837474  0.16418466  0.11965851 -0.05126453  0.16008167\n",
      "  -0.22026812 -0.1146555  -0.12831193  0.21519008 -0.20745929 -0.08214993\n",
      "   0.03506324 -0.08378301  0.10971073  0.20177875  0.03992837 -0.19704722\n",
      "  -0.0441857  -0.1606834  -0.15396902  0.15029132  0.05103984  0.18369538\n",
      "  -0.11211053 -0.2503213  -0.02455776  0.09199585 -0.09919521  0.06381448\n",
      "   0.17185453 -0.03882181 -0.19291402  0.08305123 -0.2540551  -0.16331059\n",
      "  -0.17100473 -0.27658358 -0.04295852  0.0375803  -0.18997319  0.06676216\n",
      "  -0.25422874  0.08914133 -0.02811018  0.14950083  0.0810666   0.22317043\n",
      "   0.14215343 -0.13810714  0.00868923 -0.17301434  0.17821193 -0.05030166\n",
      "   0.08237852 -0.1706292  -0.14226682 -0.01220831 -0.19573256 -0.14926565]\n",
      " [ 0.11492094  0.11966398 -0.08762878 -0.10194834 -0.1219135  -0.16812699\n",
      "  -0.16867441 -0.10744796  0.22477266  0.00492539 -0.20637766  0.14611484\n",
      "  -0.04962061  0.0842566  -0.09351897 -0.20570977 -0.10763266 -0.11942083\n",
      "   0.13120545 -0.12940237 -0.12196033 -0.188675   -0.04901424  0.03198989\n",
      "   0.10757046  0.05146294  0.06314678 -0.15038133 -0.00566329 -0.03033716\n",
      "  -0.20852153  0.18013495  0.07334907  0.15711676  0.08152432 -0.1271814\n",
      "  -0.14183398 -0.20366609 -0.12101471 -0.0308333  -0.21225263 -0.07132942\n",
      "   0.21519053 -0.18191238  0.00268374 -0.02470721  0.21680026 -0.18407878\n",
      "   0.20156111 -0.09919251 -0.11819895  0.2324274  -0.12819035 -0.04269591\n",
      "  -0.10297902  0.21743146  0.09678008  0.2127994   0.238317   -0.15156628]\n",
      " [-0.01428419  0.06050376 -0.08994191  0.0646475   0.18943271 -0.1980543\n",
      "  -0.1861147   0.06967444  0.15198873 -0.20054686  0.06514616  0.2521505\n",
      "  -0.07067734 -0.14422466 -0.04721655  0.06015626 -0.20996723 -0.14561322\n",
      "  -0.02752666  0.08888051 -0.22856775 -0.13312091 -0.16132712  0.09160241\n",
      "   0.20115389  0.00151712  0.04762238 -0.13285245  0.03478117 -0.16320819\n",
      "   0.02360097  0.07372314 -0.18285382 -0.20839995  0.16296828 -0.23720051\n",
      "  -0.1544409  -0.10516988  0.06892044 -0.02064239  0.02367531  0.06328005\n",
      "   0.16332503  0.17242189  0.14511305 -0.23327152  0.1667595   0.16266859\n",
      "  -0.04999879  0.07663527  0.21360348 -0.11583438 -0.20383565  0.272442\n",
      "  -0.08824301 -0.05518194 -0.12536292 -0.22440074  0.04942844  0.22470738]\n",
      " [-0.0231556  -0.1676987   0.08720452 -0.06515122  0.01408564  0.09413505\n",
      "   0.06207449 -0.07693487  0.21895288 -0.20205851  0.06904425 -0.08224034\n",
      "  -0.16087103  0.14203824 -0.22026303  0.08717046 -0.17448942  0.16289246\n",
      "   0.14937496  0.25984198  0.02535107  0.01707459 -0.2170642   0.20578635\n",
      "  -0.01308426  0.07785976 -0.08491426 -0.13181956 -0.20284751  0.2668738\n",
      "  -0.00795766 -0.11080091 -0.15652245  0.12403646 -0.06206387 -0.18461739\n",
      "  -0.1617989   0.04573339  0.23623906 -0.12117683 -0.07040909  0.13724504\n",
      "  -0.2510253   0.26140285 -0.08505484  0.04694069 -0.09643123  0.18118459\n",
      "   0.16657534 -0.07665169  0.11873905 -0.1509645  -0.06319245  0.20823382\n",
      "  -0.18129584  0.21550064  0.1433221  -0.14345622 -0.20371157 -0.09409145]\n",
      " [ 0.09146968  0.11580018  0.21613993 -0.08131562 -0.25894845 -0.03846938\n",
      "   0.16017854  0.08645979  0.13761672 -0.22295229  0.06644787  0.01991517\n",
      "   0.1841325   0.23047666 -0.23497543  0.21507894  0.12877919  0.08304773\n",
      "   0.04894144 -0.22037199 -0.23836927  0.14081645  0.1956483  -0.01689903\n",
      "  -0.10960986  0.22068554 -0.15421216 -0.01126357 -0.1306671  -0.01553756\n",
      "   0.15004843  0.14916192 -0.01819457 -0.03758598  0.20139779 -0.1261807\n",
      "   0.00201305 -0.05167918 -0.11864252 -0.13365783 -0.12212598 -0.03016192\n",
      "  -0.1793465  -0.17436273  0.09279738  0.16889383  0.10010829 -0.10930654\n",
      "  -0.17129384  0.17039539 -0.13531788 -0.07710206 -0.03750133  0.02833119\n",
      "   0.08592081 -0.01337658  0.08763099  0.11238766 -0.21832539 -0.07616583]\n",
      " [-0.02558923  0.05632432  0.24952456  0.0074418  -0.050544    0.14618596\n",
      "  -0.17316695  0.07565343 -0.19053398  0.11388733 -0.0939279  -0.06432713\n",
      "  -0.12231919  0.09234073 -0.18698512 -0.16128942 -0.22719236 -0.14609544\n",
      "   0.1361394   0.02546173  0.11775316  0.14922656 -0.04959105  0.24665694\n",
      "  -0.11109613  0.10775927 -0.01051914  0.22307642 -0.1900686  -0.06396717\n",
      "  -0.22384611 -0.22269574  0.01164548  0.08415885  0.22089782 -0.16796897\n",
      "   0.2268076   0.21813157 -0.1942285   0.03566102  0.18991709 -0.13135168\n",
      "   0.07852465  0.1794106   0.13104415  0.02091653  0.04232253 -0.2349731\n",
      "   0.02459416  0.09793469  0.05542767  0.1466469  -0.02196862 -0.22160095\n",
      "  -0.03919645  0.15070547  0.20421907  0.06532087  0.09331114 -0.12650155]\n",
      " [-0.06065678  0.04823832 -0.00974639  0.20061544  0.00110114  0.03724484\n",
      "  -0.22332905  0.16648313 -0.0605144  -0.08697945 -0.20253062  0.21986826\n",
      "  -0.164878    0.2374934   0.11330746  0.2115752  -0.13729541  0.00101431\n",
      "   0.1595332  -0.01229027  0.16654852  0.07912039 -0.02497488 -0.10365672\n",
      "   0.2368904   0.02569338 -0.00245751 -0.03024694  0.09347959  0.12484877\n",
      "  -0.03385837 -0.15551375  0.0028842   0.16112949 -0.0904448   0.1165902\n",
      "  -0.19448818  0.02837714 -0.02371855  0.05770582  0.02870775 -0.10351492\n",
      "  -0.10641455 -0.08342873  0.22119205 -0.19559611  0.10524955  0.22026928\n",
      "   0.0702781   0.25316963 -0.17852868 -0.18205667  0.04071123  0.09560478\n",
      "   0.07333196  0.06210322  0.04265329 -0.23136121  0.21985498 -0.14589174]\n",
      " [ 0.22079405 -0.15796947 -0.18205254 -0.04382699  0.03437828  0.00738822\n",
      "  -0.18715931  0.23647752  0.00086157  0.21918689  0.05214008  0.01490434\n",
      "   0.07794896  0.2368809   0.09236497  0.12547204  0.216773    0.01265821\n",
      "   0.22665368 -0.20410478 -0.07334402  0.1442253  -0.1343275   0.18700273\n",
      "   0.12884898 -0.16995299  0.03223453 -0.23798351 -0.14065552 -0.13779889\n",
      "   0.20342772 -0.16998939  0.06072322  0.12655482  0.20224492 -0.22338349\n",
      "  -0.1164763   0.02249017  0.04152068 -0.07913905 -0.13835973  0.24204178\n",
      "  -0.0949758  -0.16306934 -0.2230932   0.21801475  0.07018352  0.16620858\n",
      "   0.00523741 -0.02038754 -0.14892645  0.22967611 -0.22290231  0.09595413\n",
      "   0.23293078  0.0884331   0.2480489   0.03844362 -0.15066124  0.00240544]\n",
      " [ 0.22369872 -0.13612343  0.18657275 -0.16618691  0.2074167   0.16803662\n",
      "   0.02881564 -0.22509985  0.20893651  0.21073937  0.20553815  0.07940894\n",
      "   0.12038022 -0.22743383 -0.14730859  0.06045223 -0.16782412  0.02344881\n",
      "  -0.08281886 -0.01267933 -0.21213862  0.15269107 -0.03931411 -0.1833942\n",
      "  -0.09306526  0.24055107 -0.12971517 -0.02377069  0.11163896 -0.13749152\n",
      "   0.15752271  0.04698085  0.08372243 -0.06893733  0.04175101 -0.22521313\n",
      "   0.11134104 -0.02862199  0.17061186  0.00867947 -0.22769621  0.17801404\n",
      "   0.17823642  0.04569993  0.08030319  0.15400814  0.08920299 -0.0886587\n",
      "   0.0248056   0.15484515  0.12292059  0.11025443 -0.08138923 -0.14960702\n",
      "   0.08081213  0.22218673  0.07620777  0.13275631  0.13865533  0.20041417]\n",
      " [ 0.17314556  0.19764337  0.00083974 -0.03032672 -0.00948633 -0.1179531\n",
      "   0.20633154  0.24375138 -0.12416302  0.2206215   0.25235334  0.18050869\n",
      "   0.25501928 -0.00657528  0.07985066  0.12121056 -0.01311773 -0.05053203\n",
      "   0.02182744 -0.15885371  0.2377307  -0.14679617 -0.15884341  0.08252996\n",
      "  -0.07748709 -0.12091067  0.17083202  0.21856895  0.09038396  0.2056595\n",
      "  -0.18846217 -0.00349274 -0.25001392  0.10299999 -0.16923371  0.14885701\n",
      "   0.17246306 -0.03844144  0.2524821   0.22717531 -0.00163912  0.20122313\n",
      "  -0.20971812 -0.06085248 -0.04843016  0.02045977  0.11965886  0.10083672\n",
      "   0.1579533  -0.094689   -0.22533791 -0.06450021  0.06722289 -0.090488\n",
      "  -0.03473439  0.23754613  0.0491138  -0.0564012   0.1771803   0.14595342]\n",
      " [ 0.00104765  0.23002733 -0.11740354  0.16741745 -0.15703996 -0.17302652\n",
      "   0.01728963  0.10194273  0.19220456 -0.19955523  0.24327855  0.0132408\n",
      "   0.19400984 -0.18412118  0.09530464 -0.061668    0.12419719  0.15177034\n",
      "   0.0184892   0.22230674 -0.02032524  0.12454572  0.14600813  0.08075901\n",
      "   0.16385242  0.17524354  0.18392737  0.19550928  0.04977611 -0.14190283\n",
      "   0.1387951   0.18391302 -0.14879048  0.07414271  0.1912047   0.15661263\n",
      "  -0.1492823   0.12664816 -0.1703667   0.00622648 -0.035221   -0.11142295\n",
      "  -0.0560452   0.00455739  0.23289804  0.18337765 -0.06649549  0.22924711\n",
      "   0.18982074  0.00757828 -0.06798094  0.176223    0.00705983  0.05211855\n",
      "  -0.20384626  0.01767709  0.21478032 -0.09908085 -0.04057789 -0.09086047]]\n",
      "  - Pesos 1: (60,)\n",
      "[ 0.00739113  0.00296231  0.00024714 -0.00892219  0.01000487 -0.00274643\n",
      "  0.00547423  0.00712019  0.00411125  0.00256104  0.00563628 -0.00113014\n",
      " -0.02098165 -0.00155854  0.00675107  0.01054939 -0.00434957  0.01922797\n",
      "  0.00302092 -0.01216038 -0.00532472  0.00363371 -0.00039521  0.0022499\n",
      "  0.00192254 -0.01989438 -0.00922863 -0.00608169 -0.00380537  0.02859454\n",
      " -0.00802221 -0.01411367  0.01109087  0.01117563 -0.00239437  0.00166903\n",
      " -0.00066086 -0.01483597  0.00813614  0.00964791  0.00020759  0.02267933\n",
      " -0.00377752 -0.00087753 -0.00329181  0.00014134  0.00269309  0.00290385\n",
      "  0.00173101  0.00635185  0.01005517 -0.00880824  0.0031292  -0.02078521\n",
      "  0.01000595  0.00712689  0.00105383 -0.00208952  0.00634465  0.00325505]\n",
      "\n",
      "üîπ Capa 2: dense_67 (Dense)\n",
      "  - Pesos 0: (60, 80)\n",
      "[[-0.10608682  0.03607523 -0.06328054 ...  0.11862912  0.00807579\n",
      "   0.20795418]\n",
      " [ 0.03405995 -0.00769318  0.15778624 ... -0.10570003 -0.07080966\n",
      "   0.12239359]\n",
      " [-0.16343284  0.0499783   0.16744237 ... -0.15804815  0.2399104\n",
      "  -0.02973077]\n",
      " ...\n",
      " [-0.12427769 -0.11529586 -0.20618768 ... -0.05198215 -0.1262459\n",
      "   0.19679138]\n",
      " [-0.19952124  0.18787183  0.1101336  ... -0.12355266 -0.17228992\n",
      "   0.14924614]\n",
      " [ 0.1931655  -0.05368262  0.1682382  ...  0.09848569  0.13447517\n",
      "   0.02309386]]\n",
      "  - Pesos 1: (80,)\n",
      "[ 9.2885913e-03 -1.1263599e-02 -2.2369900e-03  4.5678588e-03\n",
      "  5.9097582e-03  1.2327321e-02  2.1360996e-04  8.5589447e-05\n",
      " -4.0211915e-03 -1.9207475e-05  1.0703498e-02  9.1202697e-03\n",
      "  1.4225784e-03 -2.8245142e-03  3.0243788e-03 -2.9148769e-03\n",
      "  7.8793000e-03  1.2364125e-02 -1.7320093e-02  4.7194008e-03\n",
      " -1.4554620e-03 -1.1118796e-02 -2.8449367e-03  5.3134309e-03\n",
      "  1.9814696e-03  1.1792431e-03  5.9857504e-03  2.3695419e-03\n",
      " -1.0278092e-02 -9.1182395e-05 -1.5479128e-03 -9.1016386e-03\n",
      "  1.7082606e-02  4.3059583e-03 -1.9575050e-03  1.8490624e-03\n",
      "  2.3885628e-03  1.1330980e-02 -2.7420567e-03  1.0232566e-02\n",
      " -2.7596336e-03 -1.7133019e-03 -6.8844967e-03 -3.8760852e-03\n",
      "  1.0019329e-03 -3.1018810e-04  3.7702096e-03  6.4186694e-04\n",
      "  3.8757403e-03  7.3604730e-05  4.0337453e-03  5.1299133e-03\n",
      "  2.7289274e-03 -8.6063351e-03  1.3336869e-03  7.4197270e-04\n",
      "  1.0406590e-02  3.0745578e-03 -5.8506615e-03 -2.2253452e-03\n",
      " -5.0837710e-03 -1.1624986e-03  8.7008281e-03  7.6153944e-04\n",
      "  5.1392480e-03 -4.6751006e-03  1.8848580e-03 -7.4974837e-04\n",
      " -9.8141842e-04  3.1370206e-03 -3.2022763e-03 -7.4977316e-03\n",
      " -4.1018515e-03  2.0374518e-03  4.3459763e-04 -5.6668301e-03\n",
      " -2.6740549e-02 -1.8345891e-04 -8.2760546e-03 -3.7295988e-03]\n",
      "\n",
      "üîπ Capa 3: dense_68 (Dense)\n",
      "  - Pesos 0: (80, 80)\n",
      "[[ 0.1676082   0.14400315 -0.02994482 ...  0.1431545   0.06770363\n",
      "   0.07861955]\n",
      " [ 0.18625672  0.1605919   0.05185982 ... -0.07977789  0.1085342\n",
      "   0.09883668]\n",
      " [ 0.1196783   0.07241159  0.16898702 ... -0.01090163 -0.13863769\n",
      "  -0.18608381]\n",
      " ...\n",
      " [ 0.12323667 -0.13565916 -0.00163673 ... -0.04367435 -0.07005361\n",
      "   0.06820615]\n",
      " [ 0.16430198  0.00482686  0.0392078  ... -0.16043457  0.01018622\n",
      "  -0.16995598]\n",
      " [ 0.11959296  0.01822918 -0.05914114 ... -0.0640229  -0.11208064\n",
      "   0.13564572]]\n",
      "  - Pesos 1: (80,)\n",
      "[-3.0627521e-03  2.6004820e-03  3.8496586e-03 -1.2969574e-03\n",
      " -7.6356246e-03 -7.6813432e-03 -3.2334652e-04  2.5260991e-03\n",
      "  2.5078396e-03  5.8574714e-03 -3.5924776e-04 -2.4250140e-03\n",
      " -6.2664128e-03 -7.4954843e-03 -4.1767373e-03  1.1470595e-02\n",
      " -7.4471242e-04 -4.2911558e-03 -5.0384579e-03  9.8782610e-03\n",
      "  3.3864003e-02  1.4037885e-03 -6.6495095e-03  3.1637594e-03\n",
      " -3.6944507e-03 -8.8008521e-03  1.0212683e-03  4.6619293e-03\n",
      " -3.5631638e-03 -1.1234125e-03 -5.0375918e-03  2.8839982e-03\n",
      "  2.0685964e-04 -1.0896377e-03 -1.0808072e-02 -1.8447203e-03\n",
      "  7.9219829e-04 -1.7744316e-04  2.7280863e-04 -8.3631743e-03\n",
      " -3.0687307e-03  5.9668547e-03 -7.4114319e-04 -1.5537710e-04\n",
      "  8.4406772e-04 -8.2706225e-05 -2.2608493e-03  6.6619636e-03\n",
      "  2.6158881e-03 -6.8883579e-03 -1.7908543e-02  3.3450662e-04\n",
      "  1.2341530e-02  2.3350515e-04  1.1421538e-02  6.7453841e-03\n",
      "  4.0096440e-03 -5.9764064e-03 -1.2346436e-03  4.9035992e-03\n",
      " -1.4549046e-03 -1.4453664e-05 -4.9573216e-03 -7.6589826e-04\n",
      "  3.6278300e-03  1.7378818e-02 -1.3096310e-02 -2.4145478e-03\n",
      "  1.2872962e-03 -2.2312179e-03 -2.1570048e-03  6.7740800e-03\n",
      "  8.0183253e-04 -3.8656392e-04  4.6779430e-03 -4.4404087e-03\n",
      " -1.0407979e-03  1.3033649e-03  9.2795235e-04  8.8427553e-04]\n",
      "\n",
      "üîπ Capa 4: dense_69 (Dense)\n",
      "  - Pesos 0: (80, 70)\n",
      "[[-0.00537548  0.09631748  0.03362076 ...  0.17276724  0.16027534\n",
      "  -0.16347511]\n",
      " [-0.15472803 -0.02063469 -0.17636144 ...  0.09646577  0.09553502\n",
      "   0.16314726]\n",
      " [-0.1546117  -0.00421278  0.18581544 ... -0.05435497  0.13604048\n",
      "   0.18226255]\n",
      " ...\n",
      " [-0.11287683 -0.08003858  0.0127928  ...  0.06037443  0.18629904\n",
      "  -0.14718063]\n",
      " [ 0.01936869  0.03188994  0.15302277 ... -0.09690366 -0.16235676\n",
      "   0.03849727]\n",
      " [-0.18897444 -0.03668327  0.05853616 ... -0.15659955  0.03970696\n",
      "   0.04327745]]\n",
      "  - Pesos 1: (70,)\n",
      "[-1.7140382e-03 -3.5996153e-03  1.4112712e-02 -5.9259718e-04\n",
      " -5.6568375e-03 -1.0310664e-03 -2.1888399e-03 -5.7434877e-03\n",
      "  2.4589887e-03 -7.3298765e-04 -3.8911307e-03 -7.1166549e-05\n",
      "  3.1027442e-04 -1.5918514e-03 -6.2762736e-04  1.2254484e-03\n",
      " -1.3688690e-03 -8.0666761e-04  3.8099340e-03 -4.2250194e-04\n",
      "  2.7024554e-04  5.9730659e-04  9.4963135e-03 -2.3001649e-03\n",
      "  3.7594740e-03 -2.9160990e-03  1.8512051e-03  4.4483682e-03\n",
      "  2.6631418e-03 -4.9603656e-03  1.5207359e-03  6.6383453e-03\n",
      " -2.6069066e-04  1.5730890e-02  1.5150798e-04  2.0263612e-03\n",
      "  2.7080793e-03 -1.1986246e-02  4.0411530e-03 -7.5756446e-03\n",
      " -1.0626836e-03  1.1541931e-03  1.7140801e-03  1.1230456e-03\n",
      "  5.0919165e-04  4.1829338e-03 -4.7942838e-03  3.5535362e-05\n",
      " -2.3412041e-03  3.7976154e-03 -1.9307939e-03 -8.9018210e-04\n",
      "  1.2209684e-03 -1.6545619e-04  1.4983246e-03 -9.7165089e-03\n",
      "  5.0918601e-04  2.0886110e-03  3.7176721e-03  1.0795270e-03\n",
      "  5.4142317e-03 -1.0948430e-03  4.4361851e-04 -1.6153946e-03\n",
      "  1.1387839e-03  6.1154511e-04 -2.9251329e-04 -2.3766658e-03\n",
      " -7.3545217e-04 -3.2008547e-04]\n",
      "\n",
      "üîπ Capa 5: dense_70 (Dense)\n",
      "  - Pesos 0: (70, 30)\n",
      "[[-0.0572822  -0.04478326 -0.24355897 ... -0.04998172  0.16011594\n",
      "  -0.18396781]\n",
      " [ 0.19791098 -0.2439152  -0.04821352 ... -0.180215    0.05792432\n",
      "   0.09601128]\n",
      " [ 0.06357272  0.14619154 -0.08151475 ...  0.18793428 -0.20890847\n",
      "   0.03867467]\n",
      " ...\n",
      " [ 0.11200663  0.10837794  0.03246728 ... -0.22998136  0.04627914\n",
      "  -0.13057277]\n",
      " [ 0.0914312  -0.17946884  0.0575766  ...  0.08076323 -0.00938431\n",
      "  -0.06699113]\n",
      " [-0.20021287  0.09238353  0.17030899 ...  0.11290384  0.10659574\n",
      "  -0.13206972]]\n",
      "  - Pesos 1: (30,)\n",
      "[ 3.9804978e-03  1.6351128e-03 -6.6269291e-05  1.1049142e-03\n",
      "  2.3693782e-03 -6.3598814e-04  7.4678725e-03  4.9212086e-04\n",
      " -2.0206594e-03  7.4533089e-03 -5.7992764e-04 -1.9817255e-04\n",
      "  2.0095014e-03 -6.6472413e-03 -2.7175224e-04 -1.6249201e-03\n",
      "  8.6805079e-04  2.4150636e-03  1.2941159e-02  2.1029357e-02\n",
      " -9.0312125e-04  1.6099617e-05 -7.3618195e-03  7.1462378e-04\n",
      " -4.3694889e-03  1.4708253e-03 -2.5241598e-04 -6.8017413e-05\n",
      " -7.5738505e-04 -1.7159791e-03]\n",
      "\n",
      "üîπ Capa 6: dense_71 (Dense)\n",
      "  - Pesos 0: (30, 70)\n",
      "[[ 0.02925821 -0.21657938 -0.21905068 ... -0.06048652  0.06241437\n",
      "  -0.02625688]\n",
      " [ 0.06150954  0.00580834  0.22095656 ...  0.03280517 -0.18537982\n",
      "   0.1785157 ]\n",
      " [ 0.06511502  0.15469639 -0.10700864 ...  0.17404556 -0.13913742\n",
      "   0.22664294]\n",
      " ...\n",
      " [ 0.17425083  0.18171981  0.18206815 ...  0.20272048 -0.16971257\n",
      "  -0.09075041]\n",
      " [-0.25995818  0.06066614  0.13987076 ... -0.22323306 -0.23532976\n",
      "   0.03967312]\n",
      " [-0.07088081  0.06925678  0.20352781 ... -0.19793895  0.17911227\n",
      "  -0.03821677]]\n",
      "  - Pesos 1: (70,)\n",
      "[ 0.01420351  0.00208704 -0.00178142  0.00061722  0.00209306  0.00095346\n",
      "  0.0021252   0.00454157  0.0064567   0.00187016 -0.00109073  0.00167469\n",
      "  0.0016927  -0.00261632  0.00708979 -0.00346936 -0.0007635   0.00204552\n",
      " -0.00429573 -0.0007114   0.00511519 -0.00095617  0.00423976  0.01076115\n",
      " -0.00276729 -0.00258013  0.00273939  0.0023027  -0.01077158 -0.00108897\n",
      " -0.00144289 -0.00017126  0.00065975 -0.00241797 -0.00179048 -0.00063572\n",
      " -0.02016701 -0.00244249  0.00056144  0.00376078 -0.00189416  0.00310166\n",
      " -0.003387   -0.00274001  0.001203   -0.00314045  0.00264413 -0.00987351\n",
      " -0.00133661 -0.00131582 -0.00096668  0.0041019  -0.00021546  0.00274977\n",
      " -0.00065063  0.01191158  0.00544141  0.0018357   0.00280889 -0.0082397\n",
      " -0.00867153 -0.00093597  0.00031435  0.00162817  0.00013849 -0.00275696\n",
      " -0.00117544 -0.00236827  0.00032207  0.00506   ]\n",
      "\n",
      "üîπ Capa 7: dense_72 (Dense)\n",
      "  - Pesos 0: (70, 70)\n",
      "[[ 0.14263618  0.04633788  0.12742923 ...  0.04190784 -0.09957184\n",
      "  -0.09983855]\n",
      " [ 0.11279597 -0.16477989 -0.09085345 ... -0.17105582 -0.15424669\n",
      "   0.06371266]\n",
      " [-0.05484029  0.06130867 -0.04282324 ... -0.06527739  0.09396312\n",
      "   0.15794408]\n",
      " ...\n",
      " [ 0.0302594  -0.12523708  0.04760653 ...  0.04238617  0.02891629\n",
      "   0.13377264]\n",
      " [-0.19516663  0.14063336 -0.12267358 ...  0.16304529 -0.10125075\n",
      "   0.16368723]\n",
      " [-0.15523086  0.19224386  0.04416298 ... -0.06552156 -0.10033971\n",
      "  -0.05197401]]\n",
      "  - Pesos 1: (70,)\n",
      "[-0.00051597  0.00477     0.01076919 -0.00269393  0.00239882  0.00332486\n",
      " -0.00377453 -0.00698879 -0.00895463 -0.00270485  0.00120399 -0.01044554\n",
      "  0.00453418 -0.00010901 -0.00355097  0.00187376  0.00112494 -0.00381862\n",
      " -0.00571527  0.00042936 -0.00080281  0.00140721  0.031514    0.00056845\n",
      "  0.00324485 -0.00052124 -0.0044281  -0.00212947 -0.0024969   0.00241625\n",
      "  0.00106984  0.00248603  0.00774493  0.00914011 -0.00658887 -0.00205804\n",
      "  0.00660224 -0.00187036 -0.00231655 -0.0002346   0.00239484  0.00111338\n",
      " -0.00210507 -0.0009127  -0.0019028   0.0021954  -0.00224824 -0.00073702\n",
      " -0.00287368 -0.00292457  0.00262824  0.00189266 -0.00070454  0.00263857\n",
      "  0.00259477 -0.00136987  0.00119798 -0.0031546   0.00213655 -0.00098024\n",
      " -0.00079346 -0.00152643 -0.00460598 -0.00021262 -0.00209319  0.0047548\n",
      " -0.00247032 -0.00354931  0.00740057 -0.00787834]\n",
      "\n",
      "üîπ Capa 8: dense_73 (Dense)\n",
      "  - Pesos 0: (70, 30)\n",
      "[[-0.01499635  0.02576076  0.08102421 ... -0.00862523 -0.03549709\n",
      "  -0.1678079 ]\n",
      " [ 0.13892175  0.24650137  0.08317547 ...  0.23480566 -0.03405192\n",
      "   0.14688627]\n",
      " [ 0.19813168 -0.10347524 -0.07269574 ...  0.02590105  0.19465531\n",
      "  -0.13492845]\n",
      " ...\n",
      " [-0.00966195 -0.15968351  0.16845886 ... -0.23223951 -0.19861358\n",
      "  -0.13726184]\n",
      " [-0.1393497  -0.04089518  0.1508299  ... -0.16680402  0.15738577\n",
      "   0.1343412 ]\n",
      " [-0.05799662 -0.11248238 -0.17822681 ... -0.08017621  0.13870877\n",
      "  -0.07101724]]\n",
      "  - Pesos 1: (30,)\n",
      "[ 0.00160171 -0.0011744  -0.00955403 -0.0044128  -0.00524144 -0.00146118\n",
      " -0.00091272  0.00100836  0.00470012 -0.00262937  0.00183967 -0.00468721\n",
      "  0.00326239  0.00437855 -0.00309929  0.00022507 -0.00394417  0.00234318\n",
      "  0.00264716 -0.00404426  0.00356611 -0.0024908  -0.00429114  0.00244984\n",
      "  0.00197664 -0.0038123  -0.00280661  0.00329305  0.00354384  0.00253043]\n",
      "\n",
      "üîπ Capa 9: dense_74 (Dense)\n",
      "  - Pesos 0: (30, 70)\n",
      "[[ 0.23377998 -0.1612903   0.12929606 ...  0.00856989  0.05056198\n",
      "  -0.00810315]\n",
      " [-0.10707744 -0.02734374 -0.04569679 ...  0.17261277  0.16667317\n",
      "   0.17172296]\n",
      " [-0.11084775  0.06884986  0.20373584 ...  0.13583188  0.02644454\n",
      "   0.16387236]\n",
      " ...\n",
      " [ 0.01513486 -0.14105809  0.03703817 ...  0.12949428 -0.06482385\n",
      "  -0.03654363]\n",
      " [ 0.04056544 -0.03648943  0.20415087 ...  0.03432176 -0.2167589\n",
      "   0.06786938]\n",
      " [ 0.16545506  0.03474021 -0.17935857 ... -0.22849779  0.03064802\n",
      "  -0.11086825]]\n",
      "  - Pesos 1: (70,)\n",
      "[ 0.00298763  0.00379388  0.0047887  -0.00177841  0.00044668  0.00258476\n",
      "  0.00329952 -0.00297026  0.00325193  0.0022754  -0.0044637  -0.00557331\n",
      "  0.00335169  0.00339202  0.00303375  0.00274497 -0.00234725  0.00068215\n",
      "  0.00325838  0.00912907 -0.00255536 -0.0023239   0.00721413  0.00333376\n",
      "  0.00182422  0.0040107  -0.00097991 -0.00303099 -0.0022462   0.00304939\n",
      " -0.00672587 -0.00299491 -0.00383233  0.00269747 -0.0014251   0.00440963\n",
      "  0.00260348 -0.00300197 -0.00889407 -0.00321892  0.00460117 -0.00238491\n",
      "  0.00266437  0.00198913  0.00255828  0.00299948  0.00020332  0.00229311\n",
      " -0.00423559  0.00199797 -0.00282534  0.00238958  0.00394783 -0.00329207\n",
      " -0.00282131 -0.00400997 -0.00305131  0.00126293  0.0027522  -0.00305967\n",
      " -0.0046631  -0.00212029 -0.00257733 -0.00626622 -0.00275599 -0.00256735\n",
      "  0.0016624   0.00066223 -0.00335352  0.00206749]\n",
      "\n",
      "üîπ Capa 10: dense_75 (Dense)\n",
      "  - Pesos 0: (70, 20)\n",
      "[[ 0.07957371 -0.11157481  0.02538999 ...  0.07533664  0.17664471\n",
      "  -0.10251479]\n",
      " [ 0.12012471 -0.04286312  0.19270189 ... -0.07671645 -0.08182049\n",
      "   0.02923805]\n",
      " [ 0.21222256  0.0423151  -0.24557877 ... -0.01442664 -0.24386086\n",
      "   0.03670026]\n",
      " ...\n",
      " [-0.16340668 -0.14862154  0.00759646 ...  0.01090204  0.05172972\n",
      "   0.21722102]\n",
      " [ 0.0394811   0.24057852 -0.24431168 ... -0.01369335  0.27613163\n",
      "  -0.04670892]\n",
      " [ 0.14446059  0.05546029 -0.01390059 ... -0.05384252 -0.240457\n",
      "  -0.04184653]]\n",
      "  - Pesos 1: (20,)\n",
      "[ 3.8565630e-03 -3.0948329e-03  2.9936063e-03  2.4972560e-03\n",
      " -3.3670384e-03 -2.6253117e-03 -3.1749052e-03  1.9308863e-03\n",
      " -5.6237984e-03 -4.8313076e-03  3.0526693e-03 -2.9992987e-03\n",
      "  3.0814670e-03 -1.5648831e-02 -3.4845502e-03 -3.3102110e-03\n",
      " -3.9584697e-03  8.6935019e-05  3.6305906e-03 -3.1711233e-03]\n",
      "\n",
      "üîπ Capa 11: dense_76 (Dense)\n",
      "  - Pesos 0: (20, 60)\n",
      "[[-0.23947988 -0.03296357 -0.21436642 ...  0.25065282  0.15965828\n",
      "   0.16486363]\n",
      " [ 0.06347056  0.01391031 -0.07585187 ...  0.22151802  0.12770408\n",
      "  -0.25240824]\n",
      " [ 0.12046175  0.02008232  0.22935215 ... -0.17085834  0.02744587\n",
      "   0.24371448]\n",
      " ...\n",
      " [-0.18407954  0.09364296  0.15525658 ...  0.03802914  0.02088518\n",
      "   0.00541358]\n",
      " [-0.01982836 -0.05325431 -0.18741211 ...  0.01598323 -0.18265367\n",
      "   0.0203526 ]\n",
      " [ 0.08292952  0.12209441 -0.256535   ...  0.12117828  0.22912931\n",
      "  -0.23350193]]\n",
      "  - Pesos 1: (60,)\n",
      "[ 0.00420171 -0.00354312  0.00399531  0.00440894  0.0025176  -0.00400685\n",
      " -0.00410902  0.00356304 -0.00419707  0.00384356  0.00397584 -0.00300009\n",
      "  0.00424652  0.00442437  0.00436973  0.00402188 -0.00416056  0.00340239\n",
      " -0.00427072 -0.00390653  0.00432575  0.00406683  0.00316564  0.00422287\n",
      "  0.00367838  0.00447909  0.00396014 -0.00410162 -0.00289084 -0.00314311\n",
      "  0.00406994 -0.00429361 -0.00424202 -0.00416433 -0.00349164  0.00408575\n",
      "  0.00419462  0.00396951 -0.00390121  0.00445297  0.00384048 -0.00403782\n",
      " -0.00419545  0.00343637  0.0043034   0.00305702 -0.00439897  0.00409744\n",
      " -0.00398466 -0.00345987  0.00435327  0.00379386 -0.00413777  0.00379393\n",
      "  0.00395873  0.00451272  0.00254866 -0.00399978  0.00449015  0.00345293]\n",
      "\n",
      "üîπ Capa 12: dense_77 (Dense)\n",
      "  - Pesos 0: (60, 1)\n",
      "[[ 0.30339408]\n",
      " [-0.25767502]\n",
      " [ 0.22851272]\n",
      " [ 0.2996451 ]\n",
      " [ 0.30578646]\n",
      " [-0.15560094]\n",
      " [-0.20279178]\n",
      " [ 0.32001123]\n",
      " [-0.2670629 ]\n",
      " [ 0.01613952]\n",
      " [ 0.24431308]\n",
      " [-0.28504717]\n",
      " [ 0.2851922 ]\n",
      " [ 0.16749787]\n",
      " [ 0.12982461]\n",
      " [ 0.09436976]\n",
      " [-0.2157519 ]\n",
      " [ 0.2340564 ]\n",
      " [-0.19801776]\n",
      " [-0.20145048]\n",
      " [ 0.16525409]\n",
      " [ 0.06409822]\n",
      " [ 0.24772511]\n",
      " [ 0.10023061]\n",
      " [ 0.24897824]\n",
      " [ 0.26023105]\n",
      " [ 0.2411335 ]\n",
      " [-0.14561322]\n",
      " [-0.00183977]\n",
      " [-0.15970375]\n",
      " [ 0.2827731 ]\n",
      " [-0.18880963]\n",
      " [-0.14754646]\n",
      " [-0.08276491]\n",
      " [-0.07846962]\n",
      " [ 0.06988283]\n",
      " [ 0.17882833]\n",
      " [ 0.21063106]\n",
      " [-0.1436294 ]\n",
      " [ 0.3004852 ]\n",
      " [ 0.1135246 ]\n",
      " [-0.07758784]\n",
      " [-0.0350162 ]\n",
      " [ 0.02996452]\n",
      " [ 0.20162532]\n",
      " [ 0.0462306 ]\n",
      " [-0.00905516]\n",
      " [ 0.29509282]\n",
      " [-0.07062191]\n",
      " [-0.30493617]\n",
      " [ 0.30347845]\n",
      " [ 0.10970571]\n",
      " [-0.20478685]\n",
      " [ 0.00717148]\n",
      " [ 0.3223682 ]\n",
      " [ 0.02030658]\n",
      " [ 0.25251126]\n",
      " [-0.1957959 ]\n",
      " [ 0.23706701]\n",
      " [ 0.09537455]]\n",
      "  - Pesos 1: (1,)\n",
      "[0.00420095]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the weights of the model after the pruning process\n",
    "inspect_model_weights(model_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando evaluaci√≥n de BS Pruning en 4 capas ---\n",
      "------------------------------------------------------------\n",
      "\n",
      "[EXPERIMENTO] Poda de la capa oculta n√∫mero: 2 usando BS\n",
      "\n",
      "=== INICIO DEL PROCESO ===\n",
      "√çndice de la capa a eliminar: 2\n",
      "Total de capas en el modelo: 7\n",
      "\n",
      "--- Capas involucradas ---\n",
      "Capa antes: dense_31\n",
      "Capa a eliminar: dense_32\n",
      "Capa despu√©s: dense_33\n",
      "\n",
      "Obteniendo pesos y bias de la capa a eliminar: dense_32\n",
      "Usando la capa previa 'dense_31' como referencia.\n",
      "\n",
      "Pesos de la capa a eliminar (forma (60, 60)):\n",
      "[[-0.19268203  0.1084566  -0.21906939 ... -0.01030684  0.08241396\n",
      "  -0.04914217]\n",
      " [-0.29224822 -0.15678838  0.01726513 ... -0.06435319  0.07672251\n",
      "  -0.30379033]\n",
      " [ 0.1924373  -0.02836844 -0.12709993 ... -0.019751   -0.5414242\n",
      "  -0.12879966]\n",
      " ...\n",
      " [-0.35584357  0.1123801   0.41310415 ... -0.2304633  -0.40038466\n",
      "   0.18349741]\n",
      " [-1.0776225   0.03957691  0.22652973 ... -0.12808564 -0.85976946\n",
      "   0.716171  ]\n",
      " [-0.06882188 -0.34597257 -0.6551341  ...  0.4174504  -0.6751328\n",
      "   0.36498523]]\n",
      "Bias de la capa a eliminar:\n",
      "[-6.83077499e-02  2.97670037e-01  4.47242595e-02 -1.24255456e-01\n",
      "  1.13129616e-01 -2.06768271e-02  1.37979999e-01  7.12804198e-02\n",
      "  2.09915221e-01 -2.14884013e-01  1.66206416e-02 -1.55845314e-01\n",
      " -8.85166898e-02 -8.48318189e-02  1.27696116e-02 -2.27831542e-01\n",
      " -2.33976226e-02  1.85572550e-01 -7.38716424e-02  2.10505202e-01\n",
      " -1.13878977e-02  3.61651391e-01 -9.99243185e-02 -1.26716167e-01\n",
      "  1.78440034e-01  3.67403887e-02  2.14618951e-01 -1.92894861e-01\n",
      " -6.29690439e-02 -1.22964166e-01  8.34491923e-02  1.43820018e-01\n",
      " -1.62081450e-01  1.98999211e-01 -1.60513848e-01  1.08925886e-01\n",
      "  5.24955802e-02 -1.22550368e-01 -4.02242690e-02 -1.51539966e-03\n",
      " -2.21213236e-01  4.14432257e-01  1.20562904e-01 -1.88657455e-02\n",
      "  1.21947579e-01 -4.11028333e-04 -1.23764919e-02  7.08773658e-02\n",
      "  6.66637272e-02  1.81542590e-01  6.70691133e-02  1.75392255e-01\n",
      "  1.05472915e-01  7.51982704e-02 -2.36046594e-02 -1.12344690e-01\n",
      " -2.15500630e-02 -9.03861076e-02 -2.37605557e-01  1.60697833e-01]\n",
      "\n",
      "Pesos de la capa de referencia (forma (168, 60)):\n",
      "[[ 0.04577628 -0.31198886 -0.35552216 ... -0.09384118 -0.46319985\n",
      "   0.18305114]\n",
      " [ 0.002914   -0.12329572 -0.27447042 ... -0.04040716 -0.22659972\n",
      "   0.19619873]\n",
      " [ 0.16617462  0.01867501 -0.14165686 ...  0.07896805 -0.24748245\n",
      "   0.12408843]\n",
      " ...\n",
      " [-0.3243041   0.5625959   0.01906069 ... -0.24642424  0.12505563\n",
      "  -0.26894858]\n",
      " [-0.49526286  0.86076313 -0.00805804 ... -0.4476236  -0.0544167\n",
      "  -0.31668833]\n",
      " [-0.7494321   1.3308984   0.566126   ... -0.96087694 -0.17416336\n",
      "  -0.49348605]]\n",
      "Bias de la capa de referencia:\n",
      "[ 0.4951927  -0.29770285 -0.4217317  -0.27628464 -0.10690934 -0.51187605\n",
      " -0.11344222  0.5201785  -0.24821255  0.00884986  0.42571324 -0.10885698\n",
      " -0.30400252  0.5196939  -0.01758083  0.09521136  0.49373382 -0.4711787\n",
      "  0.5212081  -0.4959907   0.23883063 -0.19091907  0.44288024 -0.37661806\n",
      "  0.00883269 -0.51165766  0.6502913   0.80390054 -0.20263799 -0.6531233\n",
      "  0.51351196 -0.27405494 -0.34297922  0.39450824  0.00620918  0.0039837\n",
      "  0.4196617  -0.08159467  0.07245699  0.3128308  -0.2579327  -0.36295635\n",
      "  0.1248499  -0.1261738  -0.854934    0.8852789   0.3250692  -0.27802992\n",
      " -0.3517306   0.04978961 -0.4668564   0.5807636  -0.34936133  0.57558805\n",
      "  0.04253445  0.5454484   0.44387484  0.41025564 -0.20763801 -0.00124217]\n",
      "\n",
      "--- Ajuste de pesos ---\n",
      "N√∫mero de neuronas de la capa previa: 60\n",
      "N√∫mero de neuronas de la capa a eliminar: 60\n",
      "N√∫mero de neuronas de la capa siguiente: 60\n",
      "Nuevo shape de pesos para conectar la capa anterior con la siguiente: (60, 60)\n",
      "Nuevo shape de bias ajustado: (60,)\n",
      "\n",
      "--- Creando nuevo modelo con input_shape=168 ---\n",
      "A√±adiendo capa: dense_31 con 60 neuronas\n",
      "Omitiendo capa: dense_32\n",
      "A√±adiendo capa: dense_33 con 60 neuronas\n",
      "A√±adiendo capa: dense_34 con 60 neuronas\n",
      "A√±adiendo capa: dense_35 con 60 neuronas\n",
      "A√±adiendo capa: dense_36 con 24 neuronas\n",
      "\n",
      "--- Ajustando pesos en el nuevo modelo ---\n",
      "‚úÖ Copiando pesos originales a la capa: dense_31\n",
      "‚úÖ Asignando pesos ajustados a la capa: dense_33\n",
      "‚úÖ Copiando pesos originales a la capa: dense_34\n",
      "‚úÖ Copiando pesos originales a la capa: dense_35\n",
      "‚úÖ Copiando pesos originales a la capa: dense_36\n",
      "\n",
      "=== FINAL DEL PROCESO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,140</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_19 (\u001b[38;5;33mInputLayer\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_31 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ        \u001b[38;5;34m10,140\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_33 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_34 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_35 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_36 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             ‚îÇ         \u001b[38;5;34m1,464\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0227 - mae: 0.0227 - mse: 0.0019 - val_loss: 0.0158 - val_mae: 0.0158 - val_mse: 5.0690e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0148 - mae: 0.0148 - mse: 4.4683e-04 - val_loss: 0.0141 - val_mae: 0.0141 - val_mse: 3.9955e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.8585e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.6017e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0134 - mse: 3.5817e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.3971e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.3961e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.3273e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.2555e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.0760e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1505e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.1921e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0552e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.4068e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0056e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.8988e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9208e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.4834e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.8676e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 2.8920e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8298e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7774e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.7951e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8079e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7530e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.6944e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7270e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7501e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6886e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.6982e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6740e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.7894e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6641e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6968e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6312e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5609e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6123e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.6940e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5981e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6521e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5827e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.8035e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5650e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.8419e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5443e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.6304e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5411e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.6651e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5185e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4745e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5071e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5061e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.4999e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4140e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.4885e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4051e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.4891e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4466e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4636e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3685e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4684e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.5854e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4458e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.5338e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4351e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4274e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4362e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4608e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4244e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4856e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4099e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5004e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4157e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4056e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4095e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.4959e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.3970e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5183e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3847e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6075e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3790e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.5409e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3724e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.7364e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3689e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4740e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3574e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3492e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3580e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.4537e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3466e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2622e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3343e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2755e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3364e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3514e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3309e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3363e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3318e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2870e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3114e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2491e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3094e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3378e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3171e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.6435e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3063e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3445e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3054e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2281e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2978e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3582e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2978e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3481e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2921e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2613e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2856e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2392e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2770e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2962e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2809e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.2950e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2716e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.5657e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2651e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2569e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2583e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2043e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2632e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4604e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2573e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2356e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2512e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2106e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2498e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2242e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2412e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3137e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2356e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4007e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2409e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2086e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2270e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3355e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2333e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4004e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2315e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2258e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2262e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3136e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2221e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2086e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2256e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3226e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2090e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.4706e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2213e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.4443e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2014e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2978e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2053e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.4666e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2075e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1566e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2058e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3321e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1921e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1551e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1868e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1404e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1989e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1955e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1909e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2026e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1846e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5269e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1817e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1646e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1843e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.4964e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1742e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1644e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1879e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3084e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1760e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3918e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1650e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2549e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1747e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1266e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1642e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1814e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1663e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1170e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1557e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2234e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1543e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1979e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1534e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1682e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1545e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2274e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1513e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1834e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1469e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.4944e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1501e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3517e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1491e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1798e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1475e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.2649e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1339e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0961e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1344e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1212e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1391e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1606e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1453e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1312e-04\n",
      "\u001b[1m9334/9334\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 800us/step\n",
      "-----------------------------------\n",
      "Se ha usado la opcion BS para eliminar la capa oculta numero 2\n",
      "Mean Absolute Percentage Error (MAPE): 1.0324%\n",
      "Desviaci√≥n est√°ndar del MAPE: 1.066%\n",
      "Tiempo total de fine-tuning: 711.42 segundos\n",
      "√âpocas utilizadas en el fine-tuning: 111\n",
      "------------------------------------------------------------\n",
      "\n",
      "[EXPERIMENTO] Poda de la capa oculta n√∫mero: 3 usando BS\n",
      "\n",
      "=== INICIO DEL PROCESO ===\n",
      "√çndice de la capa a eliminar: 3\n",
      "Total de capas en el modelo: 7\n",
      "\n",
      "--- Capas involucradas ---\n",
      "Capa antes: dense_32\n",
      "Capa a eliminar: dense_33\n",
      "Capa despu√©s: dense_34\n",
      "\n",
      "Obteniendo pesos y bias de la capa a eliminar: dense_33\n",
      "Usando la capa previa 'dense_32' como referencia.\n",
      "\n",
      "Pesos de la capa a eliminar (forma (60, 60)):\n",
      "[[-0.24563827  0.447078   -0.16919883 ...  0.16315179 -0.20068333\n",
      "  -0.18501633]\n",
      " [ 0.12414011  0.25757185  0.1646729  ... -0.15275842 -0.38128734\n",
      "  -0.29065347]\n",
      " [-0.33307132 -0.09760816  0.20132202 ... -0.19204257 -0.3137986\n",
      "   0.09787302]\n",
      " ...\n",
      " [ 0.06385616 -0.62098974 -0.25069162 ... -0.33652663 -0.05194653\n",
      "  -0.07164094]\n",
      " [ 0.21070078  0.04940715  0.03346231 ...  0.03775876 -0.23409016\n",
      "   0.26584077]\n",
      " [ 0.30114967  0.00535867 -0.08677935 ... -0.3182292  -0.64186037\n",
      "   0.1111781 ]]\n",
      "Bias de la capa a eliminar:\n",
      "[-0.09162816  0.20739758  0.04422469  0.01520745  0.16849403 -0.11121725\n",
      " -0.05176804 -0.15191782 -0.13097975  0.15768114  0.00692057 -0.02909329\n",
      "  0.12402272  0.41945213  0.18558814 -0.11993813  0.28223804  0.10814685\n",
      " -0.11837231 -0.06641804 -0.13597697  0.2650741   0.04387257  0.03698559\n",
      "  0.07093717 -0.12018366  0.0642371  -0.02537999  0.01016005  0.00558847\n",
      "  0.22475272 -0.00059539  0.35719925  0.05624732 -0.08005114  0.06274904\n",
      "  0.0272528  -0.48423767  0.04644448  0.11871605 -0.13192265 -0.03306139\n",
      "  0.14413323 -0.36309087 -0.02646417 -0.32799578  0.05443901 -0.07570678\n",
      " -0.19653653 -0.0626701   0.00225035  0.11722121  0.10915946  0.346273\n",
      "  0.07936985 -0.0962301   0.02078079 -0.10539326 -0.13148478 -0.0807751 ]\n",
      "\n",
      "Pesos de la capa de referencia (forma (60, 60)):\n",
      "[[-0.19268203  0.1084566  -0.21906939 ... -0.01030684  0.08241396\n",
      "  -0.04914217]\n",
      " [-0.29224822 -0.15678838  0.01726513 ... -0.06435319  0.07672251\n",
      "  -0.30379033]\n",
      " [ 0.1924373  -0.02836844 -0.12709993 ... -0.019751   -0.5414242\n",
      "  -0.12879966]\n",
      " ...\n",
      " [-0.35584357  0.1123801   0.41310415 ... -0.2304633  -0.40038466\n",
      "   0.18349741]\n",
      " [-1.0776225   0.03957691  0.22652973 ... -0.12808564 -0.85976946\n",
      "   0.716171  ]\n",
      " [-0.06882188 -0.34597257 -0.6551341  ...  0.4174504  -0.6751328\n",
      "   0.36498523]]\n",
      "Bias de la capa de referencia:\n",
      "[-6.83077499e-02  2.97670037e-01  4.47242595e-02 -1.24255456e-01\n",
      "  1.13129616e-01 -2.06768271e-02  1.37979999e-01  7.12804198e-02\n",
      "  2.09915221e-01 -2.14884013e-01  1.66206416e-02 -1.55845314e-01\n",
      " -8.85166898e-02 -8.48318189e-02  1.27696116e-02 -2.27831542e-01\n",
      " -2.33976226e-02  1.85572550e-01 -7.38716424e-02  2.10505202e-01\n",
      " -1.13878977e-02  3.61651391e-01 -9.99243185e-02 -1.26716167e-01\n",
      "  1.78440034e-01  3.67403887e-02  2.14618951e-01 -1.92894861e-01\n",
      " -6.29690439e-02 -1.22964166e-01  8.34491923e-02  1.43820018e-01\n",
      " -1.62081450e-01  1.98999211e-01 -1.60513848e-01  1.08925886e-01\n",
      "  5.24955802e-02 -1.22550368e-01 -4.02242690e-02 -1.51539966e-03\n",
      " -2.21213236e-01  4.14432257e-01  1.20562904e-01 -1.88657455e-02\n",
      "  1.21947579e-01 -4.11028333e-04 -1.23764919e-02  7.08773658e-02\n",
      "  6.66637272e-02  1.81542590e-01  6.70691133e-02  1.75392255e-01\n",
      "  1.05472915e-01  7.51982704e-02 -2.36046594e-02 -1.12344690e-01\n",
      " -2.15500630e-02 -9.03861076e-02 -2.37605557e-01  1.60697833e-01]\n",
      "\n",
      "--- Ajuste de pesos ---\n",
      "N√∫mero de neuronas de la capa previa: 60\n",
      "N√∫mero de neuronas de la capa a eliminar: 60\n",
      "N√∫mero de neuronas de la capa siguiente: 60\n",
      "Nuevo shape de pesos para conectar la capa anterior con la siguiente: (60, 60)\n",
      "Nuevo shape de bias ajustado: (60,)\n",
      "\n",
      "--- Creando nuevo modelo con input_shape=168 ---\n",
      "A√±adiendo capa: dense_31 con 60 neuronas\n",
      "A√±adiendo capa: dense_32 con 60 neuronas\n",
      "Omitiendo capa: dense_33\n",
      "A√±adiendo capa: dense_34 con 60 neuronas\n",
      "A√±adiendo capa: dense_35 con 60 neuronas\n",
      "A√±adiendo capa: dense_36 con 24 neuronas\n",
      "\n",
      "--- Ajustando pesos en el nuevo modelo ---\n",
      "‚úÖ Copiando pesos originales a la capa: dense_31\n",
      "‚úÖ Copiando pesos originales a la capa: dense_32\n",
      "‚úÖ Asignando pesos ajustados a la capa: dense_34\n",
      "‚úÖ Copiando pesos originales a la capa: dense_35\n",
      "‚úÖ Copiando pesos originales a la capa: dense_36\n",
      "\n",
      "=== FINAL DEL PROCESO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,140</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_20 (\u001b[38;5;33mInputLayer\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_31 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ        \u001b[38;5;34m10,140\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_32 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_34 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_35 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_36 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             ‚îÇ         \u001b[38;5;34m1,464\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0215 - mae: 0.0215 - mse: 0.0020 - val_loss: 0.0142 - val_mae: 0.0142 - val_mse: 4.1453e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.8256e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.4273e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.3289e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.1448e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.0990e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.9848e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9377e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8784e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8400e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7177e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7749e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.8307e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7051e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8141e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6637e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7498e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6174e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5688e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5885e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5096e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5421e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.6539e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5424e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5097e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.4969e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4600e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4796e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4751e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4577e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3820e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4518e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.7768e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4299e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4684e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4142e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.5686e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3918e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3043e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3985e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.7684e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3595e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5653e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3713e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3312e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3552e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2951e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3501e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4806e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3272e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2600e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3317e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3774e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3134e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4587e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3015e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.5862e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2978e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2690e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2980e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2361e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2828e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.5788e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2834e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2203e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2801e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.6364e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2788e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1666e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2490e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4006e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2523e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2338e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2508e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.3313e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2445e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4663e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2395e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2579e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2263e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2465e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2227e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2898e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2160e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1789e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2112e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2138e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2151e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.4170e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2087e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1497e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1915e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2323e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1927e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1643e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1917e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2237e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1869e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.6017e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1817e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2866e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1843e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1418e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1718e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.4126e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1708e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1470e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1679e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1167e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1725e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2433e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1538e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1457e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1534e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.1875e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1442e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1316e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1527e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0597e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1429e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2082e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1511e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1028e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1381e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2425e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1376e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1438e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1329e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0909e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1279e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2236e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1322e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.2873e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1261e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1301e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1280e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.2287e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1172e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0977e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1215e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.0993e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1177e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2305e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1077e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.4981e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1048e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1692e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1176e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0531e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1034e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1528e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1044e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.3428e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1074e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0504e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1098e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.0975e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.0973e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2012e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.0973e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2136e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0929e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2345e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.0986e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0838e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0781e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0641e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1017e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1765e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.0983e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1419e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0815e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1641e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0846e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1283e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0754e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.1813e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0749e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1627e-04\n",
      "\u001b[1m9334/9334\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 859us/step\n",
      "-----------------------------------\n",
      "Se ha usado la opcion BS para eliminar la capa oculta numero 3\n",
      "Mean Absolute Percentage Error (MAPE): 1.0188%\n",
      "Desviaci√≥n est√°ndar del MAPE: 1.021%\n",
      "Tiempo total de fine-tuning: 598.05 segundos\n",
      "√âpocas utilizadas en el fine-tuning: 90\n",
      "------------------------------------------------------------\n",
      "\n",
      "[EXPERIMENTO] Poda de la capa oculta n√∫mero: 4 usando BS\n",
      "\n",
      "=== INICIO DEL PROCESO ===\n",
      "√çndice de la capa a eliminar: 4\n",
      "Total de capas en el modelo: 7\n",
      "\n",
      "--- Capas involucradas ---\n",
      "Capa antes: dense_33\n",
      "Capa a eliminar: dense_34\n",
      "Capa despu√©s: dense_35\n",
      "\n",
      "Obteniendo pesos y bias de la capa a eliminar: dense_34\n",
      "Usando la capa previa 'dense_33' como referencia.\n",
      "\n",
      "Pesos de la capa a eliminar (forma (60, 60)):\n",
      "[[-0.23727755 -0.08693478 -0.07448845 ...  0.03960223  0.391354\n",
      "   0.47671035]\n",
      " [ 0.17216457  0.12871681 -0.11470895 ...  0.1301305   0.3354429\n",
      "   0.3328772 ]\n",
      " [ 0.05635592 -0.34685817 -0.13651624 ...  0.23808326  0.43923157\n",
      "   0.08251803]\n",
      " ...\n",
      " [-0.04895069 -0.17240013  0.10999792 ... -0.22931318 -0.32245162\n",
      "   0.17278555]\n",
      " [-0.06478581 -0.13666071  0.11840428 ... -0.23902528  0.00870718\n",
      "   0.11497327]\n",
      " [ 0.2220758  -0.6443175  -0.23029321 ...  0.10412966 -0.05832637\n",
      "   0.04556142]]\n",
      "Bias de la capa a eliminar:\n",
      "[-0.28824484  0.14020361  0.10892595  0.15211609  0.181053   -0.03117775\n",
      "  0.10066095 -0.03252262 -0.06842067  0.02421226 -0.25018236 -0.16620842\n",
      " -0.15378167 -0.34806326  0.31219473  0.04405783  0.09850872  0.32418743\n",
      " -0.264248    0.2630103   0.06875355 -0.07966443 -0.02693868 -0.13978471\n",
      "  0.04076771  0.00844562  0.09191826  0.01776682  0.35264373  0.07485334\n",
      "  0.33653694  0.050078   -0.02541167 -0.35917708 -0.08292323  0.19544968\n",
      "  0.12322321 -0.35602525  0.05215029 -0.33013925  0.04236043 -0.02041468\n",
      " -0.10491912  0.09060574 -0.08189977  0.47757873  0.42669502 -0.15758453\n",
      "  0.2670842   0.05235488  0.02155863 -0.02179999  0.19280271  0.15847823\n",
      "  0.04062536  0.10726785 -0.21671773  0.05530073  0.16145517 -0.15327007]\n",
      "\n",
      "Pesos de la capa de referencia (forma (60, 60)):\n",
      "[[-0.24563827  0.447078   -0.16919883 ...  0.16315179 -0.20068333\n",
      "  -0.18501633]\n",
      " [ 0.12414011  0.25757185  0.1646729  ... -0.15275842 -0.38128734\n",
      "  -0.29065347]\n",
      " [-0.33307132 -0.09760816  0.20132202 ... -0.19204257 -0.3137986\n",
      "   0.09787302]\n",
      " ...\n",
      " [ 0.06385616 -0.62098974 -0.25069162 ... -0.33652663 -0.05194653\n",
      "  -0.07164094]\n",
      " [ 0.21070078  0.04940715  0.03346231 ...  0.03775876 -0.23409016\n",
      "   0.26584077]\n",
      " [ 0.30114967  0.00535867 -0.08677935 ... -0.3182292  -0.64186037\n",
      "   0.1111781 ]]\n",
      "Bias de la capa de referencia:\n",
      "[-0.09162816  0.20739758  0.04422469  0.01520745  0.16849403 -0.11121725\n",
      " -0.05176804 -0.15191782 -0.13097975  0.15768114  0.00692057 -0.02909329\n",
      "  0.12402272  0.41945213  0.18558814 -0.11993813  0.28223804  0.10814685\n",
      " -0.11837231 -0.06641804 -0.13597697  0.2650741   0.04387257  0.03698559\n",
      "  0.07093717 -0.12018366  0.0642371  -0.02537999  0.01016005  0.00558847\n",
      "  0.22475272 -0.00059539  0.35719925  0.05624732 -0.08005114  0.06274904\n",
      "  0.0272528  -0.48423767  0.04644448  0.11871605 -0.13192265 -0.03306139\n",
      "  0.14413323 -0.36309087 -0.02646417 -0.32799578  0.05443901 -0.07570678\n",
      " -0.19653653 -0.0626701   0.00225035  0.11722121  0.10915946  0.346273\n",
      "  0.07936985 -0.0962301   0.02078079 -0.10539326 -0.13148478 -0.0807751 ]\n",
      "\n",
      "--- Ajuste de pesos ---\n",
      "N√∫mero de neuronas de la capa previa: 60\n",
      "N√∫mero de neuronas de la capa a eliminar: 60\n",
      "N√∫mero de neuronas de la capa siguiente: 60\n",
      "Nuevo shape de pesos para conectar la capa anterior con la siguiente: (60, 60)\n",
      "Nuevo shape de bias ajustado: (60,)\n",
      "\n",
      "--- Creando nuevo modelo con input_shape=168 ---\n",
      "A√±adiendo capa: dense_31 con 60 neuronas\n",
      "A√±adiendo capa: dense_32 con 60 neuronas\n",
      "A√±adiendo capa: dense_33 con 60 neuronas\n",
      "Omitiendo capa: dense_34\n",
      "A√±adiendo capa: dense_35 con 60 neuronas\n",
      "A√±adiendo capa: dense_36 con 24 neuronas\n",
      "\n",
      "--- Ajustando pesos en el nuevo modelo ---\n",
      "‚úÖ Copiando pesos originales a la capa: dense_31\n",
      "‚úÖ Copiando pesos originales a la capa: dense_32\n",
      "‚úÖ Copiando pesos originales a la capa: dense_33\n",
      "‚úÖ Asignando pesos ajustados a la capa: dense_35\n",
      "‚úÖ Copiando pesos originales a la capa: dense_36\n",
      "\n",
      "=== FINAL DEL PROCESO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,140</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_21 (\u001b[38;5;33mInputLayer\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_31 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ        \u001b[38;5;34m10,140\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_32 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_33 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_35 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_36 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             ‚îÇ         \u001b[38;5;34m1,464\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0253 - mae: 0.0253 - mse: 0.0031 - val_loss: 0.0153 - val_mae: 0.0153 - val_mse: 4.7183e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0149 - mae: 0.0149 - mse: 4.3629e-04 - val_loss: 0.0140 - val_mae: 0.0140 - val_mse: 3.8654e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.8016e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.6426e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0134 - mse: 3.5449e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.4253e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.3410e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.2167e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.2033e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 3.2781e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1056e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0160e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0082e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.9712e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 2.9469e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 2.9492e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.8616e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8069e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8137e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7652e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.7724e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6485e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7250e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8055e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6773e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7437e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6614e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7222e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6321e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5482e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6017e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5267e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5800e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7619e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5579e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4689e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5368e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6071e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5173e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4930e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5015e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5249e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.4964e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.6288e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4748e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6308e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4534e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7452e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4598e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4316e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4322e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4516e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4275e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3395e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4005e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4273e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4051e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5126e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.3972e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3627e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3800e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2903e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3740e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3760e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3785e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4199e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3566e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 2.7927e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3547e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2871e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3380e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3835e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3393e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3941e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3372e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2319e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3261e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2843e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3255e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2882e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3096e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3393e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3079e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3762e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2959e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4736e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2999e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3034e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2877e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4497e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2845e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3232e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2763e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3148e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2709e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2891e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2642e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.7234e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2684e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2082e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2617e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3034e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2600e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4036e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2506e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2673e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2422e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3182e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2637e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2116e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2315e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3250e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2351e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3926e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2351e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1601e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2293e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.5758e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2350e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2451e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2176e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1782e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2211e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3211e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2195e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1935e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2027e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1821e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2121e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1574e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2018e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2318e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2051e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1649e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2021e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1399e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1944e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1289e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1899e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1805e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1840e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1878e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1737e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1876e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1789e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1356e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1793e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1115e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1702e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1430e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1691e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3347e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1757e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.4308e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1631e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2403e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1638e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2488e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1645e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1215e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1581e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1635e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1584e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1557e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1549e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.4145e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1491e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4248e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1545e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1579e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1465e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1407e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1500e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1678e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1404e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0855e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1448e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1005e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1292e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2812e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1337e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1165e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1372e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2711e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1339e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0600e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1227e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.2498e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1301e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1634e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1228e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1559e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1227e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1736e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1247e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0776e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1202e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1961e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1121e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1135e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1163e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0712e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1124e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0769e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1084e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0867e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1115e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1784e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1059e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1514e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1078e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3069e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1003e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.4046e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1016e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2437e-04\n",
      "\u001b[1m9334/9334\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 772us/step\n",
      "-----------------------------------\n",
      "Se ha usado la opcion BS para eliminar la capa oculta numero 4\n",
      "Mean Absolute Percentage Error (MAPE): 1.0195%\n",
      "Desviaci√≥n est√°ndar del MAPE: 1.037%\n",
      "Tiempo total de fine-tuning: 705.00 segundos\n",
      "√âpocas utilizadas en el fine-tuning: 109\n",
      "------------------------------------------------------------\n",
      "\n",
      "[EXPERIMENTO] Poda de la capa oculta n√∫mero: 5 usando BS\n",
      "\n",
      "=== INICIO DEL PROCESO ===\n",
      "√çndice de la capa a eliminar: 5\n",
      "Total de capas en el modelo: 7\n",
      "\n",
      "--- Capas involucradas ---\n",
      "Capa antes: dense_34\n",
      "Capa a eliminar: dense_35\n",
      "Capa despu√©s: dense_36\n",
      "\n",
      "Obteniendo pesos y bias de la capa a eliminar: dense_35\n",
      "Usando la capa previa 'dense_34' como referencia.\n",
      "\n",
      "Pesos de la capa a eliminar (forma (60, 60)):\n",
      "[[-0.21022126  0.05062755  0.0489639  ... -0.06302469  0.05318845\n",
      "   0.03204888]\n",
      " [ 0.1174057   0.06342596  0.04734189 ... -0.07876239  0.14234704\n",
      "   0.03773049]\n",
      " [ 0.15754785 -0.04654319  0.02227359 ... -0.04662076 -0.1761638\n",
      "  -0.13314687]\n",
      " ...\n",
      " [-0.05961961  0.11581185 -0.08044859 ... -0.03276285 -0.00123076\n",
      "  -0.03601482]\n",
      " [ 0.01766117 -0.0108831  -0.08055525 ... -0.05477627 -0.15781476\n",
      "   0.11391085]\n",
      " [ 0.13993655 -0.21491079 -0.23840089 ...  0.10225832  0.08708552\n",
      "  -0.00789819]]\n",
      "Bias de la capa a eliminar:\n",
      "[ 0.22449158 -0.24519193 -0.24157599  0.07382473 -0.23727812  0.2977721\n",
      "  0.07143122  0.16495042 -0.27051827 -0.24803706  0.03100573  0.0489715\n",
      "  0.05761478 -0.2925482   0.12960848 -0.02550554 -0.18698367  0.07513008\n",
      "  0.07030495  0.04832777 -0.26360467  0.03954221 -0.7237761  -0.31952778\n",
      " -0.05971684 -0.00718672 -0.00752266 -0.03217486  0.01998478 -0.02559628\n",
      " -0.11574546 -0.25018716  0.21819453  0.17697342 -0.20095359  0.36155668\n",
      " -0.07113504 -0.06920483  0.0141491   0.04650005  0.5531203  -0.64633685\n",
      " -0.07523256 -0.38348874  0.05866969 -0.04152207 -0.31967497 -0.15301752\n",
      "  0.07223997  0.1601592   0.02612076  0.12248076  0.287713    0.34652984\n",
      "  0.03076013 -0.148025   -0.02609101 -0.04463986  0.0263145  -0.01067472]\n",
      "\n",
      "Pesos de la capa de referencia (forma (60, 60)):\n",
      "[[-0.23727755 -0.08693478 -0.07448845 ...  0.03960223  0.391354\n",
      "   0.47671035]\n",
      " [ 0.17216457  0.12871681 -0.11470895 ...  0.1301305   0.3354429\n",
      "   0.3328772 ]\n",
      " [ 0.05635592 -0.34685817 -0.13651624 ...  0.23808326  0.43923157\n",
      "   0.08251803]\n",
      " ...\n",
      " [-0.04895069 -0.17240013  0.10999792 ... -0.22931318 -0.32245162\n",
      "   0.17278555]\n",
      " [-0.06478581 -0.13666071  0.11840428 ... -0.23902528  0.00870718\n",
      "   0.11497327]\n",
      " [ 0.2220758  -0.6443175  -0.23029321 ...  0.10412966 -0.05832637\n",
      "   0.04556142]]\n",
      "Bias de la capa de referencia:\n",
      "[-0.28824484  0.14020361  0.10892595  0.15211609  0.181053   -0.03117775\n",
      "  0.10066095 -0.03252262 -0.06842067  0.02421226 -0.25018236 -0.16620842\n",
      " -0.15378167 -0.34806326  0.31219473  0.04405783  0.09850872  0.32418743\n",
      " -0.264248    0.2630103   0.06875355 -0.07966443 -0.02693868 -0.13978471\n",
      "  0.04076771  0.00844562  0.09191826  0.01776682  0.35264373  0.07485334\n",
      "  0.33653694  0.050078   -0.02541167 -0.35917708 -0.08292323  0.19544968\n",
      "  0.12322321 -0.35602525  0.05215029 -0.33013925  0.04236043 -0.02041468\n",
      " -0.10491912  0.09060574 -0.08189977  0.47757873  0.42669502 -0.15758453\n",
      "  0.2670842   0.05235488  0.02155863 -0.02179999  0.19280271  0.15847823\n",
      "  0.04062536  0.10726785 -0.21671773  0.05530073  0.16145517 -0.15327007]\n",
      "\n",
      "--- Ajuste de pesos ---\n",
      "N√∫mero de neuronas de la capa previa: 60\n",
      "N√∫mero de neuronas de la capa a eliminar: 60\n",
      "N√∫mero de neuronas de la capa siguiente: 24\n",
      "\n",
      "-------------------------FORMA 1, BS----------------------\n",
      "\n",
      "Reducci√≥n de pesos y bias: seleccionando neuronas por similitud de medias absolutas.\n",
      "\n",
      "Vector de medias (capa a eliminar):\n",
      "[ 1.57e-02  8.10e-03  8.70e-03  3.69e-02 -1.90e-03 -4.90e-03 -6.90e-03\n",
      "  2.00e-04 -4.40e-03 -1.14e-02  2.25e-02  2.75e-02  2.12e-02  1.17e-02\n",
      "  1.52e-02  1.97e-02 -6.10e-03  7.00e-03  3.00e-03 -1.10e-03 -4.30e-03\n",
      " -2.20e-03  2.81e-02 -2.22e-02 -1.25e-02  1.09e-02 -1.27e-02 -1.41e-02\n",
      " -9.80e-03 -8.30e-03 -1.19e-02 -3.02e-02  1.32e-02  5.70e-03 -1.67e-02\n",
      "  1.05e-02  1.55e-02 -4.20e-03  7.90e-03  3.17e-02 -2.60e-03  9.23e-02\n",
      " -4.01e-02  2.50e-02 -3.32e-02  1.94e-02 -3.00e-04 -3.18e-02 -2.30e-03\n",
      "  2.29e-02  1.00e-04 -1.50e-03  3.24e-02  1.66e-02 -2.56e-02  2.80e-03\n",
      "  6.30e-03  1.08e-02  4.10e-03 -6.60e-03]\n",
      "\n",
      "Vector de medias (capa siguiente):\n",
      "[-0.0065 -0.0248 -0.0161 -0.0111  0.007  -0.0197 -0.0115 -0.0362 -0.034\n",
      " -0.0097 -0.0092  0.007  -0.0142 -0.0388 -0.0298 -0.0267 -0.0226 -0.0176\n",
      " -0.0281 -0.003  -0.0256 -0.0031  0.0083  0.0011]\n",
      "\n",
      "√çndices finales seleccionados seg√∫n similitud de medias:\n",
      "[59, 54, 34, 9, 17, 23, 30, 44, 47, 28, 29, 56, 27, 42, 31, 26, 24, 6, 16, 40, 5, 48, 1, 7]\n",
      "Nuevo shape de pesos para conectar la capa anterior con la siguiente: (60, 24)\n",
      "Nuevo shape de bias ajustado: (24,)\n",
      "\n",
      "--- Creando nuevo modelo con input_shape=168 ---\n",
      "A√±adiendo capa: dense_31 con 60 neuronas\n",
      "A√±adiendo capa: dense_32 con 60 neuronas\n",
      "A√±adiendo capa: dense_33 con 60 neuronas\n",
      "A√±adiendo capa: dense_34 con 60 neuronas\n",
      "Omitiendo capa: dense_35\n",
      "A√±adiendo capa: dense_36 con 24 neuronas\n",
      "\n",
      "--- Ajustando pesos en el nuevo modelo ---\n",
      "‚úÖ Copiando pesos originales a la capa: dense_31\n",
      "‚úÖ Copiando pesos originales a la capa: dense_32\n",
      "‚úÖ Copiando pesos originales a la capa: dense_33\n",
      "‚úÖ Copiando pesos originales a la capa: dense_34\n",
      "‚úÖ Asignando pesos ajustados a la capa: dense_36\n",
      "\n",
      "=== FINAL DEL PROCESO ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,140</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_22 (\u001b[38;5;33mInputLayer\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_31 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ        \u001b[38;5;34m10,140\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_32 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_33 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_34 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             ‚îÇ         \u001b[38;5;34m3,660\u001b[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_36 (\u001b[38;5;33mDense\u001b[0m)                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             ‚îÇ         \u001b[38;5;34m1,464\u001b[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0412 - mae: 0.0412 - mse: 0.0149 - val_loss: 0.0183 - val_mae: 0.0183 - val_mse: 7.0018e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.0175 - mse: 6.1885e-04 - val_loss: 0.0165 - val_mae: 0.0165 - val_mse: 5.5244e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0162 - mae: 0.0162 - mse: 5.2469e-04 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 5.0812e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0155 - mae: 0.0155 - mse: 4.7951e-04 - val_loss: 0.0151 - val_mae: 0.0151 - val_mse: 4.6170e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0149 - mae: 0.0149 - mse: 4.4741e-04 - val_loss: 0.0177 - val_mae: 0.0177 - val_mse: 5.5600e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0146 - mse: 4.2756e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 4.1952e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0144 - mae: 0.0144 - mse: 4.1197e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.9268e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0141 - mse: 3.9918e-04 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 3.7729e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0140 - mse: 3.8803e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.6824e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.7761e-04 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 3.7166e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0136 - mse: 3.6941e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.5790e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.6293e-04 - val_loss: 0.0143 - val_mae: 0.0143 - val_mse: 3.9184e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.5830e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.6173e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.4882e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 3.3535e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.4403e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.4344e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.4039e-04 - val_loss: 0.0141 - val_mae: 0.0141 - val_mse: 3.7338e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.3667e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.3079e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.2994e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.1979e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.2743e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1247e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2152e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1291e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.2104e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1092e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1499e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1674e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1259e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.2381e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.0859e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.1838e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.0771e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.0276e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0433e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 3.0437e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0332e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0035e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 2.9951e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9444e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 2.9712e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.9390e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9466e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.0328e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9236e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9033e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9099e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7884e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.8886e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7983e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.8765e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.8900e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8456e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.8748e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8452e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.8235e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8389e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8572e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8139e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7825e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.7957e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8259e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.7954e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.1780e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.7729e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 2.8485e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.7634e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7106e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7449e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 2.9589e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7440e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6614e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7274e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7132e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7048e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8435e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7078e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.3724e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7026e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6289e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6797e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7757e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6781e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5615e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6614e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6765e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6638e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6241e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6619e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.0930e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6465e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6401e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6315e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.0138e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6393e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.6743e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6278e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5700e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6156e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5419e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6005e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5755e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6065e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6199e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5987e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5782e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5882e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6034e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5830e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6407e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5765e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.5967e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5743e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5588e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5576e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.6795e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5579e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 2.9192e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5548e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.6874e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5293e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6220e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5409e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4621e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5267e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5696e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5223e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4614e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5306e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4592e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5185e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4589e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5257e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4142e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5083e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5453e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5078e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.6363e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4818e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6181e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5012e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5123e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.4785e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4778e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4761e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4888e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.4855e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4756e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4722e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.5999e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.4821e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5163e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4663e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4440e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4495e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4544e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4645e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5230e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4489e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5001e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4611e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4348e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4393e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6797e-04\n",
      "\u001b[1m9334/9334\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 831us/step\n",
      "-----------------------------------\n",
      "Se ha usado la opcion BS para eliminar la capa oculta numero 5\n",
      "Mean Absolute Percentage Error (MAPE): 1.1061%\n",
      "Desviaci√≥n est√°ndar del MAPE: 1.130%\n",
      "Tiempo total de fine-tuning: 580.19 segundos\n",
      "√âpocas utilizadas en el fine-tuning: 90\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "=============== RESUMEN FINAL DE LA PODA POR CAPA ===============\n",
      "Capa #2: MAPE=1.0324%, Desv Std=1.0662%,  Tiempo=711.42s, √âpocas=111\n",
      "Capa #3: MAPE=1.0188%, Desv Std=1.0206%,  Tiempo=598.05s, √âpocas=90\n",
      "Capa #4: MAPE=1.0195%, Desv Std=1.0367%,  Tiempo=705.00s, √âpocas=109\n",
      "Capa #5: MAPE=1.1061%, Desv Std=1.1302%,  Tiempo=580.19s, √âpocas=90\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "# FOR LOOP CODE TO ITERATE OVER LAYERS TO BE PRUNED USING 3 METHODOLOGIES\n",
    "\n",
    "# Indices are 1-based\n",
    "layers_to_prune = [1, 2, 3, 4, 5]\n",
    "pruning_strategy = 3  # Fix the methodology\n",
    "strategy_map = {1: \"BS\", 2: \"FS\", 3: \"Standard\"}\n",
    "strategy_text = strategy_map.get(pruning_strategy, \"Unknown Option\")\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "print(f\"--- Starting evaluation of {strategy_text} Pruning on {len(layers_to_prune)} layers ---\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# --- Load dataset for denormalization ---\n",
    "original_data = pd.read_csv('dataset.csv')\n",
    "min_val = original_data['consumption'].min()\n",
    "max_val = original_data['consumption'].max()\n",
    "\n",
    "# --- Experimentation Loop ---\n",
    "\n",
    "for target_layer in layers_to_prune:\n",
    "    # Configure Early Stopping for each iteration\n",
    "    early_stopping_pruned = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[EXPERIMENT] Pruning hidden layer number: {target_layer} using {strategy_text}\")\n",
    "    \n",
    "    # Select the pruning strategy\n",
    "    if pruning_strategy == 1:\n",
    "        model_pruned = backward_strategy_prune(model, target_layer)\n",
    "    elif pruning_strategy == 2:\n",
    "        model_pruned = forward_strategy_prune(model, target_layer)\n",
    "    elif pruning_strategy == 3:\n",
    "        model_pruned = standard_pruning(model, target_layer)\n",
    "\n",
    "    # Fine-tuning the pruned model\n",
    "    start_time_ft = time.time()\n",
    "    history_pruned = model_pruned.fit(\n",
    "        X_train_norm, \n",
    "        y_train_norm, \n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size, \n",
    "        validation_data=(X_val_norm, y_val_norm), \n",
    "        callbacks=[early_stopping_pruned]\n",
    "    )\n",
    "    end_time_ft = time.time()\n",
    "    \n",
    "    # Perform predictions on test set\n",
    "    y_pred_pruned = model_pruned.predict(X_test_norm)\n",
    "\n",
    "    # --- Denormalization Process (N x 24 Arrays) ---\n",
    "    y_pred_denorm = y_pred_pruned * (max_val - min_val) + min_val\n",
    "    y_test_denorm = y_test * (max_val - min_val) + min_val\n",
    "\n",
    "    # Calculate global MAPE\n",
    "    mape_pruned = mean_absolute_percentage_error(y_test_denorm, y_pred_denorm) * 100\n",
    "\n",
    "    # --- MAPE STANDARD DEVIATION CALCULATION ---\n",
    "\n",
    "    # 1. Flatten arrays for point-by-point error calculation\n",
    "    y_true_flat = y_test_denorm.flatten()\n",
    "    y_pred_flat = y_pred_denorm.flatten()\n",
    "\n",
    "    # 2. Handle division by zero (using epsilon)\n",
    "    epsilon = np.finfo(np.float32).eps \n",
    "    y_true_for_mape = np.copy(y_true_flat)\n",
    "    y_true_for_mape[y_true_for_mape == 0] = epsilon\n",
    "\n",
    "    # 3. Calculate Absolute Percentage Error (APE)\n",
    "    absolute_percentage_errors = (np.abs(y_true_flat - y_pred_flat) / y_true_for_mape) * 100\n",
    "\n",
    "    # 4. Calculate Standard Deviation\n",
    "    std_dev_mape = np.std(absolute_percentage_errors) \n",
    "\n",
    "    # --- Print Iteration Results ---\n",
    "    print(\"-\" * 35)\n",
    "    print(f'Methodology: {strategy_text} | Target Layer: {target_layer}')\n",
    "    print(f'Mean Absolute Percentage Error (MAPE): {mape_pruned:.4f}%')\n",
    "    print(f\"MAPE Standard Deviation: {std_dev_mape:.3f}%\")\n",
    "    \n",
    "    ft_duration = end_time_ft - start_time_ft\n",
    "    print(f\"Total fine-tuning time: {ft_duration:.2f} seconds\")\n",
    "    \n",
    "    final_epochs = len(history_pruned.history['loss'])\n",
    "    print(f\"Epochs used in fine-tuning: {final_epochs}\")\n",
    "    \n",
    "    # Store results for final summary\n",
    "    comparison_results.append({\n",
    "        'strategy': strategy_text,\n",
    "        'pruned_layer': target_layer,\n",
    "        'std_dev': std_dev_mape,\n",
    "        'mape': mape_pruned,\n",
    "        'duration': ft_duration,\n",
    "        'epochs': final_epochs\n",
    "    })\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# --- Final Summary Table ---\n",
    "print(\"\\n\\n=============== FINAL PRUNING SUMMARY BY LAYER ===============\")\n",
    "print(f\"{'Layer':<10} | {'MAPE':<12} | {'Std Dev':<12} | {'Time (s)':<10} | {'Epochs':<8}\")\n",
    "print(\"-\" * 65)\n",
    "for res in comparison_results:\n",
    "    print(f\"#{res['pruned_layer']:<9} | {res['mape']:<11.4f}% | {res['std_dev']:<11.4f}% | {res['duration']:<9.2f} | {res['epochs']:<7}\")\n",
    "print(\"================================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
