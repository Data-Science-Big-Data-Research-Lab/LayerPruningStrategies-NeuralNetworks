{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "VersiÃ³n de Python: 3.11.5\n",
      "VersiÃ³n de TensorFlow: 2.17.0\n",
      "VersiÃ³n de Keras: 3.11.3\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "try:\n",
    "    import keras as keras_standalone\n",
    "    keras_version = keras_standalone.__version__\n",
    "except ImportError:\n",
    "    keras_version = tf.keras.__version__\n",
    "print(\"-\" * 40)\n",
    "print(f\"VersiÃ³n de Python: {sys.version.split(' ')[0]}\")\n",
    "print(f\"VersiÃ³n de TensorFlow: {tf.__version__}\")\n",
    "print(f\"VersiÃ³n de Keras: {keras_version}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_metrics(y_test_denorm, y_pred_denorm, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Calculates error metrics and training duration using denormalized data.\n",
    "\n",
    "    Parameters:\n",
    "    - y_test_denorm: Denormalized ground truth values (NumPy array).\n",
    "    - y_pred_denorm: Denormalized predicted values (NumPy array).\n",
    "    - start_time: Training start timestamp.\n",
    "    - end_time: Training end timestamp.\n",
    "\n",
    "    Returns:\n",
    "    - rmse: Root Mean Squared Error (average across all steps).\n",
    "    - mae: Mean Absolute Error (average across all steps).\n",
    "    - mape: Mean Absolute Percentage Error (average across all steps).\n",
    "    - training_duration: Total training duration in seconds.\n",
    "    - training_time_str: Formatted duration as HH:MM:SS.\n",
    "    \"\"\"\n",
    "    # 1. Process real values and predictions\n",
    "    # Flatten arrays to calculate a global metric across all prediction steps (e.g., 24 steps)\n",
    "    y_true_flat = y_test_denorm.flatten()\n",
    "    y_pred_flat = y_pred_denorm.flatten()\n",
    "\n",
    "    # 2. Calculate error metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_flat, y_pred_flat))\n",
    "    mae = mean_absolute_error(y_true_flat, y_pred_flat)\n",
    "    \n",
    "    # Calculate MAPE, handling potential division by zero\n",
    "    # Using NumPy to compute the mean of the absolute percentage error\n",
    "    mape = np.mean(np.abs((y_true_flat - y_pred_flat) / y_true_flat)) * 100\n",
    "\n",
    "    # 3. Calculate training duration\n",
    "    training_duration = end_time - start_time\n",
    "    training_time_str = time.strftime('%H:%M:%S', time.gmtime(training_duration))\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n--- Global Denormalized Metrics ---\")\n",
    "    print(f\"RMSE (Root Mean Squared Error): {rmse:.4f}\")\n",
    "    print(f\"MAE (Mean Absolute Error): {mae:.4f}\")\n",
    "    print(f\"MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
    "    print(f\"Training Time: {training_time_str}\")\n",
    "\n",
    "    return rmse, mae, mape, training_duration, training_time_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_model_weights(model):\n",
    "    \"\"\"\n",
    "    Inspects the weights and biases of each layer in a Keras model.\n",
    "\n",
    "    Parameter:\n",
    "    - model: Keras/TensorFlow model object.\n",
    "\n",
    "    Prints:\n",
    "    - Name, type of each layer, and its weights if they are trainable.\n",
    "    \"\"\"\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        # Retrieve layer weights and biases\n",
    "        weights = layer.get_weights()  \n",
    "        print(f\"\\nğŸ”¹ Layer {i}: {layer.name} ({layer.__class__.__name__})\")\n",
    "\n",
    "        if weights:  # Check if the layer contains trainable parameters\n",
    "            for j, parameter_block in enumerate(weights):\n",
    "                print(f\"  - Weight Block {j}: {parameter_block.shape}\\n{parameter_block}\")\n",
    "        else:\n",
    "            print(\"  - âš ï¸ This layer does not have trainable weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_graph(history, capa_eliminar):\n",
    "    # Extraer la informaciÃ³n de la funciÃ³n objetivo desde el historial de entrenamiento\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Crear un grÃ¡fico con los valores de la funciÃ³n objetivo respecto a las Ã©pocas\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss')\n",
    "    plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')\n",
    "\n",
    "    # Ajustar los lÃ­mites de los ejes\n",
    "    plt.ylim(0.10, 0.2)\n",
    "    #plt.xlim(0, 100)\n",
    "\n",
    "    # Agregar etiquetas y leyenda al grÃ¡fico\n",
    "    plt.title('Training and Validation Loss over Epochs - HL '+str(capa_eliminar)+' deleted')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Mostrar el grÃ¡fico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame original con 995521 filas.\n",
      "DataFrame duplicado con 1991041 filas.\n",
      "El archivo 'W168H24x4.csv' ha sido creado.\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "data = pd.read_csv(\"W168H24x2.csv\", sep=\",\")\n",
    "\n",
    "# 1. Select all rows from the second one onwards (index 1 to end)\n",
    "rows_to_duplicate = data.iloc[1:]\n",
    "\n",
    "# 2. Concatenate the original DataFrame with the selected rows (duplicating them)\n",
    "# Resulting structure: [Row 0] + [Rows 1 to End] + [Rows 1 to End]\n",
    "extended_data = pd.concat([data, rows_to_duplicate], ignore_index=True)\n",
    "\n",
    "# 3. Save the new DataFrame to a CSV file\n",
    "# Output filename reflects the expanded dataset\n",
    "extended_data.to_csv(\"W168H24x4.csv\", index=False)\n",
    "\n",
    "print(f\"Original DataFrame with {len(data)} rows.\")\n",
    "print(f\"Extended DataFrame with {len(extended_data)} rows.\")\n",
    "print(\"The file 'W168H24x4.csv' has been successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file using a comma as the delimiter\n",
    "data = pd.read_csv(\"W168H24x2.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first column (index 0)\n",
    "data = data.iloc[:, 1:]\n",
    "\n",
    "# Separate features (inputs) and labels (outputs)\n",
    "# First 168 columns are input features, remaining 24 are output labels\n",
    "X = data.iloc[:, :168].values  \n",
    "y = data.iloc[:, 168:].values  \n",
    "\n",
    "# Split the data into training (70%) and testing (30%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Further split the training set into training and validation (70% - 30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)\n",
    "\n",
    "# Convert datasets to float32 for normalization/model compatibility\n",
    "X_train_norm = X_train.astype('float32')\n",
    "X_val_norm = X_val.astype('float32')\n",
    "X_test_norm = X_test.astype('float32')\n",
    "\n",
    "y_train_norm = y_train.astype('float32')\n",
    "y_val_norm = y_val.astype('float32')\n",
    "y_test_norm = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2856591 , 0.2763865 , 0.2692213 , ..., 0.26735976, 0.26163465,\n",
       "        0.2644094 ],\n",
       "       [0.6057392 , 0.60524744, 0.60693336, ..., 0.49776965, 0.4981209 ,\n",
       "        0.49415195],\n",
       "       [0.30532822, 0.33117908, 0.33019564, ..., 0.2552773 , 0.25590953,\n",
       "        0.2652875 ],\n",
       "       ...,\n",
       "       [0.89396226, 0.8772435 , 0.8905904 , ..., 0.6113238 , 0.57641107,\n",
       "        0.5557585 ],\n",
       "       [0.46763372, 0.48069966, 0.47599313, ..., 0.56857854, 0.58909065,\n",
       "        0.5901795 ],\n",
       "       [0.6851884 , 0.6850831 , 0.68726075, ..., 0.61574936, 0.620772  ,\n",
       "        0.62846404]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20578834, 0.20238137, 0.20231113, ..., 0.25144884, 0.2558393 ,\n",
       "        0.26981843],\n",
       "       [0.6352429 , 0.63380283, 0.632152  , ..., 0.6002248 , 0.60271853,\n",
       "        0.5981525 ],\n",
       "       [0.20273261, 0.20368093, 0.20069544, ..., 0.24231674, 0.2572091 ,\n",
       "        0.253486  ],\n",
       "       ...,\n",
       "       [0.10407081, 0.11934952, 0.10768852, ..., 0.44501424, 0.45010713,\n",
       "        0.5033894 ],\n",
       "       [0.50553197, 0.50732327, 0.50641   , ..., 0.566155  , 0.5608514 ,\n",
       "        0.566998  ],\n",
       "       [0.23529205, 0.23631063, 0.23434372, ..., 0.16620421, 0.16160303,\n",
       "        0.15162797]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6494679 , 0.65438515, 0.6477468 , ..., 0.5574444 , 0.55481017,\n",
       "        0.5524569 ],\n",
       "       [0.7694145 , 0.76604265, 0.75620806, ..., 0.6869797 , 0.6848372 ,\n",
       "        0.6803414 ],\n",
       "       [0.3720979 , 0.37680447, 0.39591163, ..., 0.24294896, 0.24052545,\n",
       "        0.25194058],\n",
       "       ...,\n",
       "       [0.44448736, 0.42801446, 0.41466755, ..., 0.23848829, 0.23033965,\n",
       "        0.23090161],\n",
       "       [0.59348106, 0.5978364 , 0.61156964, ..., 0.407397  , 0.39952934,\n",
       "        0.3913807 ],\n",
       "       [0.50026345, 0.5269573 , 0.554494  , ..., 0.7905237 , 0.77875733,\n",
       "        0.76246005]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization flag: 0 = Load, 1 = Create New\n",
    "load_model_mode = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "epochs = 300\n",
    "batch_size = 256\n",
    "learning_rate = 0.0005 \n",
    "\n",
    "# Configure Early Stopping to prevent overfitting\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',         # Metric to monitor (validation loss)\n",
    "    patience=30,                # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True   # Restore model weights from the epoch with the best value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,140</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_31 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚        \u001b[38;5;34m10,140\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_32 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_33 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_34 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_35 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_36 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             â”‚         \u001b[38;5;34m1,464\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,244</span> (102.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,244\u001b[0m (102.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,244</span> (102.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,244\u001b[0m (102.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0325 - mae: 0.0325 - mse: 0.0034 - val_loss: 0.0232 - val_mae: 0.0232 - val_mse: 0.0014\n",
      "Epoch 2/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0221 - mae: 0.0221 - mse: 0.0012 - val_loss: 0.0204 - val_mae: 0.0204 - val_mse: 0.0011\n",
      "Epoch 3/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0203 - mae: 0.0203 - mse: 9.9940e-04 - val_loss: 0.0194 - val_mae: 0.0194 - val_mse: 9.1909e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0193 - mse: 8.7165e-04 - val_loss: 0.0181 - val_mae: 0.0181 - val_mse: 7.8809e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0188 - mse: 7.9645e-04 - val_loss: 0.0175 - val_mae: 0.0175 - val_mse: 6.9268e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0179 - mse: 7.0977e-04 - val_loss: 0.0180 - val_mae: 0.0180 - val_mse: 7.2342e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0175 - mae: 0.0175 - mse: 6.6525e-04 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 6.1170e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.0172 - mse: 6.3039e-04 - val_loss: 0.0198 - val_mae: 0.0198 - val_mse: 8.0519e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0168 - mae: 0.0168 - mse: 6.0018e-04 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 5.5606e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0164 - mse: 5.7206e-04 - val_loss: 0.0171 - val_mae: 0.0171 - val_mse: 6.1674e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0163 - mae: 0.0163 - mse: 5.5639e-04 - val_loss: 0.0156 - val_mae: 0.0156 - val_mse: 5.1958e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0159 - mae: 0.0159 - mse: 5.2869e-04 - val_loss: 0.0151 - val_mae: 0.0151 - val_mse: 5.0898e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0158 - mae: 0.0158 - mse: 5.1539e-04 - val_loss: 0.0153 - val_mae: 0.0153 - val_mse: 4.9430e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0155 - mae: 0.0155 - mse: 4.9880e-04 - val_loss: 0.0159 - val_mae: 0.0159 - val_mse: 5.3750e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0153 - mae: 0.0153 - mse: 4.8769e-04 - val_loss: 0.0149 - val_mae: 0.0149 - val_mse: 4.8425e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0152 - mae: 0.0152 - mse: 4.7636e-04 - val_loss: 0.0232 - val_mae: 0.0232 - val_mse: 0.0011\n",
      "Epoch 17/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0149 - mae: 0.0149 - mse: 4.6230e-04 - val_loss: 0.0159 - val_mae: 0.0159 - val_mse: 4.9522e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0147 - mae: 0.0147 - mse: 4.4604e-04 - val_loss: 0.0141 - val_mae: 0.0141 - val_mse: 4.1171e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0145 - mae: 0.0145 - mse: 4.3535e-04 - val_loss: 0.0149 - val_mae: 0.0149 - val_mse: 4.3390e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0144 - mae: 0.0144 - mse: 4.2482e-04 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 4.3714e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0142 - mae: 0.0142 - mse: 4.1405e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.8742e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0143 - mse: 4.1325e-04 - val_loss: 0.0139 - val_mae: 0.0139 - val_mse: 3.8803e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.9547e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.8563e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.9312e-04 - val_loss: 0.0136 - val_mae: 0.0136 - val_mse: 3.7447e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.8471e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.5906e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0136 - mse: 3.7416e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.6293e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.7001e-04 - val_loss: 0.0136 - val_mae: 0.0136 - val_mse: 3.6216e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.6579e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 3.4088e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.5832e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.4625e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0134 - mse: 3.5824e-04 - val_loss: 0.0142 - val_mae: 0.0142 - val_mse: 3.9472e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.4771e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.3000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.4869e-04 - val_loss: 0.0156 - val_mae: 0.0156 - val_mse: 4.3690e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.4197e-04 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 3.5583e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.3474e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.3022e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.3230e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.1555e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.2678e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.2533e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.2617e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.3256e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2137e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.0980e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1783e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 3.0917e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1351e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.1175e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1557e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0344e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0734e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 3.0008e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0599e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.1886e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0418e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8837e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0131e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.9243e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9990e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.2129e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9568e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8732e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9531e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.0306e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9363e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8320e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9134e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7127e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8864e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 2.9123e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8881e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 3.0376e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8698e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7789e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8538e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.8967e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8345e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.2752e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8220e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6847e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8204e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.9773e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7865e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7520e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7833e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.4219e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7786e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8282e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7391e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 3.0019e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7357e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6262e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7300e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 2.9467e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.7063e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5986e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7229e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 2.9733e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6893e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.1690e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6671e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6416e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6622e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7153e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6416e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5422e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6573e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7293e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6397e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5285e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6384e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5980e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.6205e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5372e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5993e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7133e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5919e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.6458e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5968e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5407e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5917e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4800e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5538e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6642e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5658e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4428e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5610e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5738e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5419e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.5881e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5348e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5193e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.5240e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4949e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.5148e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4350e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.5065e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 2.8836e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4910e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.4087e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.5112e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3499e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4802e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 3.0779e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4900e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3579e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4649e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.5542e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4704e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4905e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4564e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4413e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4640e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5072e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4454e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3114e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4407e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4773e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4284e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5206e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4305e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3693e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4273e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.6708e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4056e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3162e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4183e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3980e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4043e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3102e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4040e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3950e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3934e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5297e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3895e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.5057e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3721e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3018e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3808e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.7252e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3585e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.4337e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3611e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3689e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3555e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2566e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3601e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.5482e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3483e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2968e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3428e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3160e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3450e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2289e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3371e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3001e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3325e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3361e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3159e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2918e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3281e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.5818e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3061e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2054e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3068e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3111e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2985e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2479e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3050e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2769e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2958e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2188e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3028e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2177e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2857e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2405e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2870e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3754e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2748e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2651e-04\n",
      "Epoch 127/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2748e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2119e-04\n",
      "Epoch 128/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2744e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2683e-04\n",
      "Epoch 129/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2575e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1817e-04\n",
      "Epoch 130/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2758e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2376e-04\n",
      "Epoch 131/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2502e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.4253e-04\n",
      "Epoch 132/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2487e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2031e-04\n",
      "Epoch 133/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2596e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2423e-04\n",
      "Epoch 134/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2448e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1888e-04\n",
      "Epoch 135/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2466e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2647e-04\n",
      "Epoch 136/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2428e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4156e-04\n",
      "Epoch 137/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2369e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3385e-04\n",
      "Epoch 138/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2211e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2803e-04\n",
      "Epoch 139/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2247e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1845e-04\n",
      "Epoch 140/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2380e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3281e-04\n",
      "Epoch 141/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2208e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2097e-04\n",
      "Epoch 142/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2190e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2583e-04\n",
      "Epoch 143/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2136e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.5313e-04\n",
      "Epoch 144/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2265e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3314e-04\n",
      "Epoch 145/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2117e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1626e-04\n",
      "Epoch 146/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2018e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.4538e-04\n",
      "Epoch 147/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1925e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.4161e-04\n",
      "Epoch 148/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1921e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 2.8107e-04\n",
      "Epoch 149/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1906e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2154e-04\n",
      "Epoch 150/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1937e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.3175e-04\n",
      "Epoch 151/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1831e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2238e-04\n",
      "Epoch 152/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1799e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3597e-04\n",
      "Epoch 153/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1846e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1048e-04\n",
      "Epoch 154/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1752e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2288e-04\n",
      "Epoch 155/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1716e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1130e-04\n",
      "Epoch 156/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1763e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1418e-04\n",
      "Epoch 157/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1816e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1071e-04\n",
      "Epoch 158/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1775e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 2.7995e-04\n",
      "Epoch 159/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1624e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0939e-04\n",
      "Epoch 160/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1627e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0979e-04\n",
      "Epoch 161/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1586e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1584e-04\n",
      "Epoch 162/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1464e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1530e-04\n",
      "Epoch 163/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1402e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3690e-04\n",
      "Epoch 164/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1443e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1106e-04\n",
      "Epoch 165/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1542e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1442e-04\n",
      "Epoch 166/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1376e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1704e-04\n",
      "Epoch 167/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1275e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1289e-04\n",
      "Epoch 168/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1459e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.3643e-04\n",
      "Epoch 169/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1362e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1146e-04\n",
      "Epoch 170/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1414e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1783e-04\n",
      "Epoch 171/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1280e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0948e-04\n",
      "Epoch 172/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1281e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1064e-04\n",
      "Epoch 173/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1222e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1203e-04\n",
      "Epoch 174/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1258e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2551e-04\n",
      "Epoch 175/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1105e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5341e-04\n",
      "Epoch 176/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1249e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0869e-04\n",
      "Epoch 177/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1185e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1076e-04\n",
      "Epoch 178/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1165e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0532e-04\n",
      "Epoch 179/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1083e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4666e-04\n",
      "Epoch 180/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0993e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2048e-04\n",
      "Epoch 181/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0104 - mse: 2.1131e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1284e-04\n",
      "Epoch 182/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0975e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1672e-04\n",
      "Epoch 183/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0882e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0862e-04\n",
      "Epoch 184/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.1008e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1828e-04\n",
      "Epoch 185/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0952e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0810e-04\n",
      "Epoch 186/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0961e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1868e-04\n",
      "Epoch 187/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0932e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1816e-04\n",
      "Epoch 188/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0874e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0667e-04\n",
      "Epoch 189/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0804e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3173e-04\n",
      "Epoch 190/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0794e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.2980e-04\n",
      "Epoch 191/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0794e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0380e-04\n",
      "Epoch 192/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0797e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1693e-04\n",
      "Epoch 193/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0748e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9883e-04\n",
      "Epoch 194/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0744e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0411e-04\n",
      "Epoch 195/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0750e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0445e-04\n",
      "Epoch 196/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0652e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0574e-04\n",
      "Epoch 197/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0669e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9942e-04\n",
      "Epoch 198/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0628e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0617e-04\n",
      "Epoch 199/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0608e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3289e-04\n",
      "Epoch 200/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0537e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2106e-04\n",
      "Epoch 201/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0563e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1242e-04\n",
      "Epoch 202/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0671e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 2.0321e-04\n",
      "Epoch 203/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0466e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1063e-04\n",
      "Epoch 204/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0529e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9975e-04\n",
      "Epoch 205/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0541e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.2977e-04\n",
      "Epoch 206/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0415e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9924e-04\n",
      "Epoch 207/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0103 - mse: 2.0577e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 2.0018e-04\n",
      "Epoch 208/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0402e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.0736e-04\n",
      "Epoch 209/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0454e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3415e-04\n",
      "Epoch 210/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0448e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1746e-04\n",
      "Epoch 211/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0408e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.3223e-04\n",
      "Epoch 212/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0404e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1070e-04\n",
      "Epoch 213/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0308e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9888e-04\n",
      "Epoch 214/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0431e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.0752e-04\n",
      "Epoch 215/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0241e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 2.1004e-04\n",
      "Epoch 216/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0376e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9895e-04\n",
      "Epoch 217/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0322e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9734e-04\n",
      "Epoch 218/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0245e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9822e-04\n",
      "Epoch 219/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0229e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0427e-04\n",
      "Epoch 220/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0256e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0262e-04\n",
      "Epoch 221/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0225e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 2.0145e-04\n",
      "Epoch 222/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0171e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 2.0310e-04\n",
      "Epoch 223/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 2.0120e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0240e-04\n",
      "Epoch 224/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0282e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1112e-04\n",
      "Epoch 225/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 2.0109e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0615e-04\n",
      "Epoch 226/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 2.0081e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0042e-04\n",
      "Epoch 227/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0099e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.0970e-04\n",
      "Epoch 228/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 2.0055e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0985e-04\n",
      "Epoch 229/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0158e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1326e-04\n",
      "Epoch 230/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9983e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0973e-04\n",
      "Epoch 231/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0102 - mse: 2.0108e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9925e-04\n",
      "Epoch 232/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101 - mse: 2.0030e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1618e-04\n",
      "Epoch 233/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 2.0005e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1140e-04\n",
      "Epoch 234/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9952e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0502e-04\n",
      "Epoch 235/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101 - mse: 2.0074e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 2.0677e-04\n",
      "Epoch 236/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9850e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9793e-04\n",
      "Epoch 237/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 2.0018e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9537e-04\n",
      "Epoch 238/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9868e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9320e-04\n",
      "Epoch 239/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 2.0041e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 2.0076e-04\n",
      "Epoch 240/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9914e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9934e-04\n",
      "Epoch 241/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9833e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1183e-04\n",
      "Epoch 242/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 2.0011e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.4462e-04\n",
      "Epoch 243/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9722e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9881e-04\n",
      "Epoch 244/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9826e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.1512e-04\n",
      "Epoch 245/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9854e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1652e-04\n",
      "Epoch 246/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9869e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9813e-04\n",
      "Epoch 247/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9965e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9963e-04\n",
      "Epoch 248/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9791e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9909e-04\n",
      "Epoch 249/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9831e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9940e-04\n",
      "Epoch 250/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9721e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.0952e-04\n",
      "Epoch 251/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9647e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1066e-04\n",
      "Epoch 252/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9793e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 1.9746e-04\n",
      "Epoch 253/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9692e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9441e-04\n",
      "Epoch 254/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9579e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9631e-04\n",
      "Epoch 255/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9719e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 2.0225e-04\n",
      "Epoch 256/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9600e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1694e-04\n",
      "Epoch 257/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9714e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 2.0125e-04\n",
      "Epoch 258/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9585e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9858e-04\n",
      "Epoch 259/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0101 - mse: 1.9672e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.2961e-04\n",
      "Epoch 260/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9613e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.1508e-04\n",
      "Epoch 261/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9626e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9511e-04\n",
      "Epoch 262/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9636e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2291e-04\n",
      "Epoch 263/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9612e-04 - val_loss: 0.0098 - val_mae: 0.0098 - val_mse: 1.9124e-04\n",
      "Epoch 264/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9541e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0547e-04\n",
      "Epoch 265/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9449e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9935e-04\n",
      "Epoch 266/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9586e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 2.0246e-04\n",
      "Epoch 267/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9550e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9836e-04\n",
      "Epoch 268/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9463e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0314e-04\n",
      "Epoch 269/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9643e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.2843e-04\n",
      "Epoch 270/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9479e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9680e-04\n",
      "Epoch 271/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9491e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.0690e-04\n",
      "Epoch 272/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9559e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0048e-04\n",
      "Epoch 273/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9481e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9591e-04\n",
      "Epoch 274/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9371e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9387e-04\n",
      "Epoch 275/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9498e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9284e-04\n",
      "Epoch 276/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9345e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9537e-04\n",
      "Epoch 277/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9443e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9802e-04\n",
      "Epoch 278/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9396e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9394e-04\n",
      "Epoch 279/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9480e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9366e-04\n",
      "Epoch 280/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9322e-04 - val_loss: 0.0102 - val_mae: 0.0102 - val_mse: 2.0074e-04\n",
      "Epoch 281/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9440e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.0798e-04\n",
      "Epoch 282/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9321e-04 - val_loss: 0.0098 - val_mae: 0.0098 - val_mse: 1.8909e-04\n",
      "Epoch 283/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9274e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 2.0942e-04\n",
      "Epoch 284/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9324e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9353e-04\n",
      "Epoch 285/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9322e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9415e-04\n",
      "Epoch 286/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9301e-04 - val_loss: 0.0098 - val_mae: 0.0098 - val_mse: 1.8820e-04\n",
      "Epoch 287/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9342e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.0687e-04\n",
      "Epoch 288/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9356e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.0415e-04\n",
      "Epoch 289/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9256e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9082e-04\n",
      "Epoch 290/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9206e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 2.0760e-04\n",
      "Epoch 291/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9253e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9687e-04\n",
      "Epoch 292/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9272e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9567e-04\n",
      "Epoch 293/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9270e-04 - val_loss: 0.0098 - val_mae: 0.0098 - val_mse: 1.8768e-04\n",
      "Epoch 294/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9218e-04 - val_loss: 0.0098 - val_mae: 0.0098 - val_mse: 1.9047e-04\n",
      "Epoch 295/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099 - mse: 1.9152e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9252e-04\n",
      "Epoch 296/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9195e-04 - val_loss: 0.0100 - val_mae: 0.0100 - val_mse: 1.9340e-04\n",
      "Epoch 297/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099 - mse: 1.9222e-04 - val_loss: 0.0101 - val_mae: 0.0101 - val_mse: 1.9880e-04\n",
      "Epoch 298/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0100 - mae: 0.0100 - mse: 1.9185e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9246e-04\n",
      "Epoch 299/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0099 - mae: 0.0099 - mse: 1.9157e-04 - val_loss: 0.0099 - val_mae: 0.0099 - val_mse: 1.9362e-04\n",
      "Epoch 300/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0099 - mse: 1.9118e-04 - val_loss: 0.0098 - val_mae: 0.0098 - val_mse: 1.9091e-04\n",
      "\u001b[1m9334/9334\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 887us/step\n",
      "\u001b[1m15244/15244\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 933us/step\n"
     ]
    }
   ],
   "source": [
    "# Check model initialization flag\n",
    "if load_model_mode == 1:\n",
    "    start_time = 0\n",
    "    # Load existing Keras model\n",
    "    # model = load_model(\"WaterDFFNN_MartinDatasetx1_W12.h5\", compile=False) \n",
    "    model = load_model(\"Electricityx1.keras\")\n",
    "    \n",
    "    # Define optimizer with the specific learning rate used originally\n",
    "    optimizer = keras.optimizers.Adam(epsilon=1e-8, learning_rate=learning_rate) \n",
    "\n",
    "    # Re-compile the model for inference or further training\n",
    "    # 'mae' and 'mse' are standard for regression tasks\n",
    "    model.compile(optimizer=optimizer, loss='mae', metrics=['mae', 'mse'])\n",
    "    \n",
    "    # Perform predictions on the test set\n",
    "    y_pred = model.predict(X_test_norm)\n",
    "    print(y_pred)\n",
    "    end_time = 0\n",
    "\n",
    "    # Predictions for evaluation\n",
    "    y_pred = model.predict(X_test_norm)\n",
    "    y_train_pred = model.predict(X_train_norm)\n",
    "\n",
    "if load_model_mode == 0:\n",
    "    # 1. Define the input layer explicitly\n",
    "    input_layer = keras.Input(shape=(168,))\n",
    "    x = input_layer\n",
    "    \n",
    "    # 2. Add hidden layers\n",
    "    hidden_units = [60, 60, 60, 60, 60]  # 5 hidden layers with 60 neurons each\n",
    "    for neurons in hidden_units:\n",
    "        x = keras.layers.Dense(neurons, activation='tanh')(x)\n",
    "        \n",
    "    # 3. Add output layer\n",
    "    output_layer = keras.layers.Dense(24, activation='tanh')(x)\n",
    "    \n",
    "    # 4. Create the Functional API model\n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    # 5. Define the optimizer\n",
    "    optimizer = keras.optimizers.Adam(epsilon=1e-8, learning_rate=learning_rate)\n",
    "    \n",
    "    # 6. Compile the model with the custom optimizer\n",
    "    model.compile(optimizer=optimizer, loss='mae', metrics=['mae', 'mse'])\n",
    "    \n",
    "    # Model architecture summary\n",
    "    model.summary()\n",
    "\n",
    "    # Measure training execution time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train_norm, \n",
    "        y_train_norm, \n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size, \n",
    "        validation_data=(X_val_norm, y_val_norm), \n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    # Capture training end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Perform predictions for performance analysis\n",
    "    y_pred = model.predict(X_test_norm)\n",
    "    y_train_pred = model.predict(X_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error (MAPE): 0.9787%\n",
      "Mean absolute error (MAE): 278.51\n",
      "DesviaciÃ³n estÃ¡ndar del MAPE): 0.979%\n",
      "-----------------------------------\n",
      "Tiempo de entrenamiento: 2016.40 segundos\n"
     ]
    }
   ],
   "source": [
    "# --- Denormalization and Global MAPE Calculation ---\n",
    "original_data = pd.read_csv('dataset.csv')\n",
    "min_val = original_data['consumption'].min()\n",
    "max_val = original_data['consumption'].max()\n",
    "\n",
    "# Denormalize values (N x 24 Arrays)\n",
    "y_pred_denorm = y_pred * (max_val - min_val) + min_val\n",
    "y_test_denorm = y_test * (max_val - min_val) + min_val\n",
    "\n",
    "# Calculate MAPE with denormalized data (as percentage)\n",
    "mape_percentage = mean_absolute_percentage_error(y_test_denorm, y_pred_denorm) * 100\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape_percentage:.4f}%\")\n",
    "\n",
    "# Calculate MAE with denormalized data\n",
    "mae = mean_absolute_error(y_test_denorm, y_pred_denorm)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "\n",
    "# --- MAPE STANDARD DEVIATION CALCULATION ---\n",
    "\n",
    "# 1. Flatten arrays for point-by-point calculation\n",
    "y_true_flat = y_test_denorm.flatten()\n",
    "y_pred_flat = y_pred_denorm.flatten()\n",
    "\n",
    "# 2. Handle division by zero for APE calculation\n",
    "# Use a small value (epsilon) to replace zeros in the denominator\n",
    "epsilon = np.finfo(np.float32).eps \n",
    "y_true_for_mape = np.copy(y_true_flat)\n",
    "y_true_for_mape[y_true_for_mape == 0] = epsilon\n",
    "\n",
    "# 3. Calculate Absolute Percentage Error (APE) for each data point\n",
    "absolute_percentage_errors = (np.abs(y_true_flat - y_pred_flat) / y_true_for_mape) * 100\n",
    "\n",
    "# 4. Calculate MAPE Standard Deviation\n",
    "std_dev_mape = np.std(absolute_percentage_errors)\n",
    "\n",
    "# --- Print MAPE Standard Deviation ---\n",
    "print(f\"MAPE Standard Deviation: {std_dev_mape:.3f}%\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# --- Training Duration (Existing logic) ---\n",
    "# Calculate training duration in seconds\n",
    "training_duration = end_time - start_time\n",
    "# Print training time in seconds and HH:MM:SS format\n",
    "print(f'Training Duration: {training_duration:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in the native Keras format\n",
    "model.save(\"Electricityx2_5HL.keras\")\n",
    "\n",
    "# Print the final training execution time\n",
    "# print(f\"Training Time: {(end_time - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_val_graph(history,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1 - BACKWARD STRATEGY (BS)\n",
    "def backward_strategy_prune(model, target_layer_index):\n",
    "    \"\"\"\n",
    "    Removes a specific hidden layer and reconfigures weights to correctly connect\n",
    "    adjacent layers. Redirects weights from the pruned layer to the next layer,\n",
    "    adjusting their size if necessary.\n",
    "    \"\"\"\n",
    "    \n",
    "    layers = model.layers\n",
    "\n",
    "    if target_layer_index < 2 or target_layer_index >= len(layers) - 1:\n",
    "        raise ValueError(\"The hidden layer index must be between 2 and the total number of hidden layers.\")\n",
    "\n",
    "    print(\"\\n=== STARTING PRUNING PROCESS ===\")\n",
    "    print(f\"Target layer index to remove: {target_layer_index}\")\n",
    "    print(f\"Total layers in model: {len(layers)}\")\n",
    "\n",
    "    # Involved layers\n",
    "    previous_layer = layers[target_layer_index - 1]\n",
    "    layer_to_prune = layers[target_layer_index]\n",
    "    next_layer = layers[target_layer_index + 1]\n",
    "\n",
    "    print(\"\\n--- Layers Involved ---\")\n",
    "    print(f\"Previous Layer: {previous_layer.name}\")\n",
    "    print(f\"Layer to Prune: {layer_to_prune.name}\")\n",
    "    print(f\"Next Layer: {next_layer.name}\")\n",
    "\n",
    "    print(f\"\\nRetrieving weights and biases from target layer: {layer_to_prune.name}\")\n",
    "    print(f\"Using '{previous_layer.name}' as reference layer.\")\n",
    "\n",
    "    # Retrieve weights and biases\n",
    "    input_weights, input_bias = layer_to_prune.get_weights()\n",
    "    print(f\"\\nTarget layer weights (shape {input_weights.shape}):\\n{input_weights}\")\n",
    "    print(f\"Target layer bias:\\n{input_bias}\")\n",
    "\n",
    "    ref_weights, ref_bias = previous_layer.get_weights()\n",
    "    print(f\"\\nReference layer weights (shape {ref_weights.shape}):\\n{ref_weights}\")\n",
    "    print(f\"Reference layer bias:\\n{ref_bias}\")\n",
    "\n",
    "    num_neurons_prev = input_weights.shape[0]\n",
    "    num_neurons_prune = input_weights.shape[1]\n",
    "    num_neurons_next = next_layer.units\n",
    "\n",
    "    print(\"\\n--- Weight Adjustment ---\")\n",
    "    print(f\"Neurons in previous layer: {num_neurons_prev}\")\n",
    "    print(f\"Neurons in layer to prune: {num_neurons_prune}\")\n",
    "    print(f\"Neurons in next layer: {num_neurons_next}\")\n",
    "\n",
    "    if input_weights.shape[1] > num_neurons_next:\n",
    "        print(\"\\n------------------------- OPTION 1, BS ----------------------\")\n",
    "        print(\"\\nReducing weights and bias: selecting neurons based on absolute mean similarity.\")\n",
    "\n",
    "        # 1. Target layer means\n",
    "        origin_means = np.mean(input_weights, axis=0)\n",
    "        print(\"\\nMean vector (target layer):\")\n",
    "        print(np.round(origin_means, 4))\n",
    "\n",
    "        # 2. Next layer means\n",
    "        next_weights, _ = next_layer.get_weights()\n",
    "        reference_means = np.mean(next_weights, axis=0)\n",
    "        print(\"\\nMean vector (next layer):\")\n",
    "        print(np.round(reference_means, 4))\n",
    "\n",
    "        # 3. Select indices of the closest neurons (without repetition)\n",
    "        selected_indices = []\n",
    "        used_indices = set()\n",
    "        for ref_val in reference_means:\n",
    "            differences = np.abs(origin_means - ref_val)\n",
    "            sorted_order = np.argsort(differences)\n",
    "            for idx in sorted_order:\n",
    "                if idx not in used_indices:\n",
    "                    selected_indices.append(idx)\n",
    "                    used_indices.add(idx)\n",
    "                    break\n",
    "\n",
    "        print(\"\\nFinal selected indices based on mean similarity:\")\n",
    "        print(selected_indices)\n",
    "\n",
    "        # 4. Filter weights and biases using selected indices\n",
    "        input_weights = input_weights[:, selected_indices]\n",
    "        input_bias = input_bias[selected_indices]\n",
    "\n",
    "    elif input_weights.shape[1] < num_neurons_next:\n",
    "        print(\"\\n------- Next layer neuron count is larger; BS not applicable --------\")\n",
    "        return model\n",
    "\n",
    "    print(f\"New weights shape for connecting previous to next layer: {input_weights.shape}\")\n",
    "    print(f\"New adjusted bias shape: {input_bias.shape}\")\n",
    "\n",
    "    new_weights = input_weights\n",
    "    new_bias = input_bias\n",
    "\n",
    "    # FIXED FOR Keras 3/TF 2.16.1\n",
    "    # 1. Get model input shape\n",
    "    full_input_shape = model.input_shape\n",
    "    \n",
    "    # 2. Handle multiple inputs (if list)\n",
    "    if isinstance(full_input_shape, list):\n",
    "        full_input_shape = full_input_shape[0]\n",
    "        \n",
    "    # 3. Extract features dimension (e.g., 12 from (None, 12))\n",
    "    if isinstance(full_input_shape, tuple):\n",
    "        input_dim = full_input_shape[-1] \n",
    "    else:\n",
    "        raise ValueError(f\"Could not determine model input shape: {full_input_shape}\")\n",
    "\n",
    "    print(f\"\\n--- Creating new model with input_shape={input_dim} ---\")\n",
    "\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "\n",
    "    # Iterate through original model layers to build the new one\n",
    "    for i, layer in enumerate(layers[1:]): \n",
    "        # Skip non-Dense layers\n",
    "        if not isinstance(layer, keras.layers.Dense):\n",
    "            continue \n",
    "            \n",
    "        # Skip the pruned layer\n",
    "        if i + 1 == target_layer_index:\n",
    "            print(f\"Skipping layer: {layer.name}\")\n",
    "            continue\n",
    "            \n",
    "        # Reconstruct layer with original attributes\n",
    "        x = keras.layers.Dense(layer.units, activation=layer.activation, name=layer.name)(x)\n",
    "        print(f\"Adding layer: {layer.name} with {layer.units} units\")\n",
    "\n",
    "    new_model = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    print(\"\\n--- Adjusting weights in the new model ---\")\n",
    "    for layer in new_model.layers:\n",
    "        if isinstance(layer, keras.layers.Dense):\n",
    "            # 1. Assign the merged weights to the \"next\" layer\n",
    "            if layer.name == next_layer.name:\n",
    "                layer.set_weights([new_weights, new_bias])\n",
    "                print(f\"âœ… Assigned adjusted weights to layer: {layer.name}\")\n",
    "            # 2. Copy original weights for all other layers\n",
    "            else:\n",
    "                original_layer = next((c for c in model.layers if c.name == layer.name), None)\n",
    "                if original_layer is not None:\n",
    "                    layer.set_weights(original_layer.get_weights())\n",
    "                    print(f\"âœ… Copied original weights to layer: {layer.name}\")\n",
    "\n",
    "    # Re-compile model with original configuration\n",
    "    optimizer = keras.optimizers.Adam(epsilon=1e-8, learning_rate=learning_rate)\n",
    "    new_model.compile(optimizer=optimizer, loss='mae', metrics=['mse', 'mae'])\n",
    "\n",
    "    print(\"\\n=== PROCESS COMPLETE ===\")\n",
    "    new_model.summary()\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2 - FORWARD STRATEGY (FS)\n",
    "def forward_strategy_prune(model, target_layer_index):\n",
    "    import keras\n",
    "    import numpy as np\n",
    "    \n",
    "    layers = model.layers\n",
    "\n",
    "    if target_layer_index < 1 or target_layer_index >= len(layers) - 1:\n",
    "        raise ValueError(\"Index must correspond to a hidden layer (not input or output).\")\n",
    "\n",
    "    print(\"\\n=== STARTING PRUNING PROCESS (FS) ===\")\n",
    "\n",
    "    previous_layer = layers[target_layer_index - 1]\n",
    "    layer_to_prune = layers[target_layer_index]\n",
    "    next_layer = layers[target_layer_index + 1]\n",
    "\n",
    "    print(\"\\n--- Layers Involved ---\")\n",
    "    print(f\"Previous Layer: {previous_layer.name}\")\n",
    "    print(f\"Layer to Prune: {layer_to_prune.name}\")\n",
    "    print(f\"Next Layer: {next_layer.name}\")\n",
    "\n",
    "    # Original weights from the next layer\n",
    "    next_weights, next_bias = next_layer.get_weights()\n",
    "\n",
    "    print(f\"\\nLayer to prune: {layer_to_prune.name}\")\n",
    "    print(f\"Next layer: {next_layer.name}\")\n",
    "    print(f\"Original next layer weights shape: {next_weights.shape}\")\n",
    "\n",
    "    print(f\"\\nRetrieving weights and bias from target layer: {layer_to_prune.name}\")\n",
    "    print(f\"Using next layer '{next_layer.name}' as reference.\")\n",
    "\n",
    "    input_weights, input_bias = layer_to_prune.get_weights()\n",
    "    print(f\"\\nTarget layer weights (shape {input_weights.shape}):\\n{input_weights}\")\n",
    "    print(f\"Target layer bias:\\n{input_bias}\")\n",
    "\n",
    "    ref_weights, ref_bias = next_layer.get_weights()\n",
    "    print(f\"\\nReference layer weights (shape {ref_weights.shape}):\\n{ref_weights}\")\n",
    "    print(f\"Reference layer bias:\\n{ref_bias}\")\n",
    "\n",
    "    num_neurons_prev = input_weights.shape[0]\n",
    "    num_neurons_prune = input_weights.shape[1]\n",
    "    num_neurons_next = next_layer.units\n",
    "\n",
    "    print(\"\\n--- Weight Adjustment ---\")\n",
    "    print(f\"Neurons in previous layer: {num_neurons_prev}\")\n",
    "    print(f\"Neurons in layer to prune: {num_neurons_prune}\")\n",
    "    print(f\"Neurons in next layer: {num_neurons_next}\")\n",
    "\n",
    "    # --- CORRECTION 1: Determine new input dimension ---\n",
    "    if hasattr(previous_layer, \"units\"):\n",
    "        # If the previous layer is Dense, use its units\n",
    "        new_input_dim = previous_layer.units\n",
    "    else:\n",
    "        # If previous is InputLayer, use model's input shape\n",
    "        full_input_shape = model.input_shape\n",
    "        if isinstance(full_input_shape, list):\n",
    "            full_input_shape = full_input_shape[0]\n",
    "        # Extract feature dimension (e.g., 12 from (None, 12))\n",
    "        new_input_dim = full_input_shape[-1] \n",
    "    \n",
    "    output_neurons = next_layer.units\n",
    "\n",
    "    print(f\"\\nAdjusting weights for layer '{next_layer.name}' from {next_weights.shape} â†’ ({new_input_dim}, {output_neurons})\")\n",
    "\n",
    "    if next_weights.shape[0] > new_input_dim:\n",
    "        print(\"\\nğŸ”» Row reduction via mean similarity\")\n",
    "        original_means = np.mean(next_weights, axis=1)\n",
    "        # Generate reference means with uniform spacing\n",
    "        reference_means = np.linspace(np.min(original_means), np.max(original_means), new_input_dim)\n",
    "\n",
    "        print(\"\\nâ–¶ Original row means:\")\n",
    "        print(original_means)\n",
    "\n",
    "        print(\"\\nâ–¶ Generated reference means (uniform spacing):\")\n",
    "        print(reference_means)\n",
    "\n",
    "        selected_indices = []\n",
    "        used_indices = set()\n",
    "        for i, ref in enumerate(reference_means):\n",
    "            distances = np.abs(original_means - ref)\n",
    "            sorted_order = np.argsort(distances)\n",
    "            print(f\"\\nâ†’ Comparing with reference {i} ({ref:.4f}):\")\n",
    "            print(\"  Distances:\", distances)\n",
    "            print(\"  Order:\", sorted_order)\n",
    "\n",
    "            for idx in sorted_order:\n",
    "                if idx not in used_indices:\n",
    "                    selected_indices.append(idx)\n",
    "                    used_indices.add(idx)\n",
    "                    print(f\"  âœ… Selected index {idx} (mean {original_means[idx]:.4f})\")\n",
    "                    break\n",
    "\n",
    "        print(\"\\nâœ… Final indices selected to keep:\")\n",
    "        print(selected_indices)\n",
    "\n",
    "        # Slice the weights using the selected row indices\n",
    "        next_weights = next_weights[selected_indices, :]\n",
    "\n",
    "    elif next_weights.shape[0] < new_input_dim:\n",
    "        print(\"\\n----------- Next layer has more neurons; FS not applicable -----------\")\n",
    "        return model\n",
    "        \n",
    "    print(f\"\\nâœ… Final adjusted weights shape: {next_weights.shape}\")\n",
    "\n",
    "    # --- CORRECTION 2: Get input shape for model reconstruction ---\n",
    "    full_input_shape = model.input_shape\n",
    "    if isinstance(full_input_shape, list):\n",
    "        full_input_shape = full_input_shape[0]\n",
    "    input_dim = full_input_shape[-1] \n",
    "    \n",
    "    print(f\"\\n--- Creating new model with input_shape={input_dim} ---\")\n",
    "\n",
    "    inputs = keras.Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "\n",
    "    for i, layer in enumerate(layers[1:]):\n",
    "        if i + 1 == target_layer_index:\n",
    "            print(f\"Skipping pruned layer: {layer.name}\")\n",
    "            continue\n",
    "        \n",
    "        # Ensure only Dense layers are processed\n",
    "        if not isinstance(layer, keras.layers.Dense):\n",
    "            continue\n",
    "            \n",
    "        x = keras.layers.Dense(layer.units, activation=layer.activation, name=layer.name)(x)\n",
    "\n",
    "    new_model = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    # Assign weights to the new model\n",
    "    for layer in new_model.layers:\n",
    "        if isinstance(layer, keras.layers.Dense):\n",
    "            if layer.name == next_layer.name:\n",
    "                layer.set_weights([next_weights, next_bias])\n",
    "                print(f\"âœ… Assigned new weights to layer: {layer.name}\")\n",
    "            else:\n",
    "                # Copy original weights for unchanged layers\n",
    "                original_layer = next((c for c in model.layers if c.name == layer.name), None)\n",
    "                if original_layer:\n",
    "                    layer.set_weights(original_layer.get_weights())\n",
    "                    print(f\"âœ… Copied original weights to layer: {layer.name}\")\n",
    "\n",
    "    # Recompile with the global learning rate\n",
    "    optimizer = keras.optimizers.Adam(epsilon=1e-8, learning_rate=learning_rate)\n",
    "    new_model.compile(optimizer=optimizer, loss='mae', metrics=['mse', 'mae'])\n",
    "\n",
    "    print(\"\\n=== PROCESS COMPLETE ===\")\n",
    "    new_model.summary()\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARD PRUNING\n",
    "def standard_pruning(\n",
    "    original_model: keras.Model,\n",
    "    layer_index_to_remove: int,\n",
    ") -> keras.Model:\n",
    "    \"\"\"\n",
    "    Standard pruning that removes a hidden layer and reconstructs the model.\n",
    "    Note: This method does not preserve weights for the adjacent layers; \n",
    "    it simply defines a new architecture with one less layer.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. Extract configuration and index ---\n",
    "\n",
    "    # Hidden layers in your model start at index 1 (index 0 is InputLayer)\n",
    "    hidden_dense_layers = original_model.layers[1:-1]\n",
    "    \n",
    "    # The provided hidden layer index is 1-based (1, 2, 3...)\n",
    "    # For the `hidden_dense_layers` list, we use 0-based indexing, so we subtract 1.\n",
    "    remove_idx = layer_index_to_remove - 1\n",
    "\n",
    "    if remove_idx < 0 or remove_idx >= len(hidden_dense_layers):\n",
    "        print(f\"ERROR: Index {layer_index_to_remove} is out of the hidden layer range (1 to {len(hidden_dense_layers)}).\")\n",
    "        return original_model\n",
    "\n",
    "    # --- 2. Define New Architecture (Layer Pruning) ---\n",
    "\n",
    "    # Get the unit count for all original hidden layers\n",
    "    original_hidden_units = [layer.units for layer in hidden_dense_layers]\n",
    "    \n",
    "    # Create the new unit list by omitting the selected layer\n",
    "    reduced_hidden_units = (\n",
    "        original_hidden_units[:remove_idx] + \n",
    "        original_hidden_units[remove_idx+1:]\n",
    "    )\n",
    "\n",
    "    print(f\"Pruning hidden layer #{layer_index_to_remove} with {original_hidden_units[remove_idx]} units.\")\n",
    "    print(f\"New architecture (hidden units): {reduced_hidden_units}\")\n",
    "\n",
    "    # --- 3. Model Reconstruction ---\n",
    "\n",
    "    # Extract input shape and the original output layer activation\n",
    "    input_shape = original_model.input_shape[1:]\n",
    "    output_activation = original_model.layers[-1].activation.__name__\n",
    "    \n",
    "    input_layer = keras.Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    # Add reduced hidden layers\n",
    "    for units in reduced_hidden_units:\n",
    "        # Assuming 'tanh' as the standard activation for hidden layers\n",
    "        x = keras.layers.Dense(units, activation='tanh')(x)\n",
    "\n",
    "    # Add output layer\n",
    "    # Maintains 24 units and the original output activation\n",
    "    output_layer = keras.layers.Dense(24, activation=output_activation)(x)\n",
    "\n",
    "    # Create the reduced functional model\n",
    "    reduced_model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the reduced model\n",
    "    # Using the global 'learning_rate' variable defined previously\n",
    "    optimizer = keras.optimizers.Adam(epsilon=1e-8, learning_rate=learning_rate)\n",
    "    reduced_model.compile(optimizer=optimizer, loss='mae', metrics=['mae', 'mse'])\n",
    "    \n",
    "    print(\"\\n--- Reduced Model Summary ---\")\n",
    "    reduced_model.summary()\n",
    "    print(\"----------------------------------\\n\")\n",
    "    \n",
    "    return reduced_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INICIO DEL PROCESO ===\n",
      "\n",
      "--- Capas involucradas ---\n",
      "Capa antes: dense_2\n",
      "Capa a eliminar: dense_3\n",
      "Capa despuÃ©s: dense_4\n",
      "\n",
      "Capa a eliminar: dense_3\n",
      "Capa siguiente: dense_4\n",
      "Forma original de pesos de la capa siguiente: (60, 60)\n",
      "\n",
      "Obteniendo pesos y bias de la capa a eliminar: dense_3\n",
      "Usando la capa posterior 'dense_4' como referencia.\n",
      "\n",
      "Pesos de la capa a eliminar (forma (90, 60)):\n",
      "[[-0.08882892  0.06672331  0.1106843  ... -0.20323947  0.06148278\n",
      "   0.2421428 ]\n",
      " [ 0.19140379 -0.21269378 -0.09361155 ...  0.22304621  0.17197263\n",
      "   0.004413  ]\n",
      " [ 0.06765034  0.22428113 -0.2594401  ...  0.08092441 -0.23108414\n",
      "   0.04495906]\n",
      " ...\n",
      " [ 0.07980245  0.17283972 -0.14182174 ... -0.18219991 -0.06776182\n",
      "   0.2398633 ]\n",
      " [ 0.1251675  -0.20480551 -0.07700592 ... -0.10676853 -0.02044641\n",
      "  -0.15120286]\n",
      " [ 0.04675413  0.06360561  0.07661088 ...  0.12218941  0.00556134\n",
      "   0.13549331]]\n",
      "Bias de la capa a eliminar:\n",
      "[ 2.73897741e-02 -1.60246436e-02  8.16922449e-03  1.95053068e-03\n",
      "  4.56092320e-02 -3.51369567e-02 -3.02716549e-02 -2.67758667e-02\n",
      " -3.74487862e-02  1.35333359e-01 -6.68897331e-02 -2.84438469e-02\n",
      "  9.67391655e-02  3.22757699e-02 -1.21693406e-02  2.51435991e-02\n",
      " -4.95005324e-02 -2.38665994e-02 -5.23240417e-02  4.98072885e-04\n",
      "  6.51273085e-03 -5.60807995e-02 -2.03549713e-02  2.55216081e-02\n",
      "  1.07644893e-01 -6.70335442e-02 -4.67160903e-02 -4.84559685e-03\n",
      "  5.87925166e-02  4.41458933e-02 -2.59422455e-02  4.71076258e-02\n",
      "  1.41094830e-02  5.63325733e-02  1.12256706e-02 -5.14149433e-03\n",
      "  2.42518075e-02  8.54641274e-02  8.08667755e-05 -8.74222023e-04\n",
      "  5.62789617e-03  4.88476045e-02  9.64339375e-02  1.47506315e-02\n",
      " -9.61676911e-02  2.97054071e-02 -1.35414791e-03 -2.96065509e-02\n",
      "  5.27343303e-02 -9.94409202e-04 -3.32511663e-02 -5.19828033e-03\n",
      " -1.58718918e-02 -4.75984141e-02  4.82498445e-02  1.55842332e-02\n",
      " -7.80916074e-03 -3.20461579e-02  1.05198786e-01 -1.47973597e-02]\n",
      "\n",
      "Pesos de la capa de referencia (forma (60, 60)):\n",
      "[[ 0.23371746 -0.1930981   0.04507841 ... -0.26897755  0.23074472\n",
      "   0.10804804]\n",
      " [ 0.04894358  0.28237346 -0.11289919 ...  0.00950653  0.01190446\n",
      "   0.15688206]\n",
      " [ 0.11591674  0.02417363 -0.08353303 ... -0.23445408 -0.24500091\n",
      "   0.22690506]\n",
      " ...\n",
      " [ 0.11188368 -0.03870755  0.1071846  ... -0.25112066 -0.24745269\n",
      "  -0.09890812]\n",
      " [-0.03688513 -0.20412323 -0.20081593 ...  0.23004872 -0.44579625\n",
      "   0.0603328 ]\n",
      " [ 0.21112017  0.09334805 -0.17777815 ...  0.06292927 -0.12918755\n",
      "  -0.28303707]]\n",
      "Bias de la capa de referencia:\n",
      "[ 0.0111679   0.05568569 -0.05688175 -0.03984217 -0.01020152 -0.05924926\n",
      " -0.01890121 -0.01028091  0.02779885 -0.0676383  -0.0558191  -0.05262298\n",
      "  0.00447822 -0.02968977 -0.03975218 -0.01237091 -0.06023223 -0.04476263\n",
      "  0.00495888 -0.00846515 -0.0088008   0.01533347  0.1224175   0.06516827\n",
      " -0.00321043  0.06416816 -0.07183813  0.12118856 -0.03181678 -0.02106484\n",
      "  0.03403269  0.02096535  0.00828536  0.0973163   0.00715945 -0.03187969\n",
      "  0.00623459  0.10258788 -0.04045923 -0.02361501  0.087715   -0.051567\n",
      " -0.03350686  0.07744898 -0.02872236  0.01762374  0.00291161 -0.00720261\n",
      " -0.00720211 -0.0086514   0.01267427 -0.00800382  0.03510587 -0.00128733\n",
      "  0.05508557 -0.02301784  0.01276125 -0.03138829  0.01084567 -0.08107482]\n",
      "\n",
      "--- Ajuste de pesos ---\n",
      "NÃºmero de neuronas de la capa previa: 90\n",
      "NÃºmero de neuronas de la capa a eliminar: 60\n",
      "NÃºmero de neuronas de la capa siguiente: 60\n",
      "\n",
      "Ajustando pesos de la capa 'dense_4' de forma ((60, 60)) â†’ (90, 60)\n",
      "\n",
      "-----------La siguiente capa tiene mas neuronas que la actual, FS no apta-----------\n"
     ]
    }
   ],
   "source": [
    "# Strategy Selection: 1 = Backward, 2 = Forward, 3 = Standard\n",
    "pruning_strategy = 2  \n",
    "target_hidden_layer = 4\n",
    "\n",
    "if pruning_strategy == 1:\n",
    "    # Option 1: Backward Strategy Pruning (BS)\n",
    "    model_pruned = backward_strategy_prune(model, target_hidden_layer)\n",
    "elif pruning_strategy == 2:\n",
    "    # Option 2: Forward Strategy Pruning (FS)\n",
    "    model_pruned = forward_strategy_prune(model, target_hidden_layer)\n",
    "elif pruning_strategy == 3:\n",
    "    # Option 3: Standard Layer Pruning (Classic)\n",
    "    model_pruned = standard_pruning(model, target_hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Capa 0: input_layer_14 (InputLayer)\n",
      "  - âš ï¸ Esta capa no tiene pesos entrenables.\n",
      "\n",
      "ğŸ”¹ Capa 1: dense_65 (Dense)\n",
      "  - Pesos 0: (12, 40)\n",
      "[[-0.09370826  0.1648086  -0.04056354  0.20126562 -0.01161632 -0.08252753\n",
      "  -0.29845887 -0.20267463  0.04238677  0.04885807 -0.3260325   0.16161369\n",
      "   0.22421041  0.19623907  0.03051327 -0.03902812  0.2757984   0.04351014\n",
      "   0.04160324  0.1769534  -0.259557    0.27386674 -0.13647202  0.24432117\n",
      "   0.22435176  0.13586353 -0.04853562 -0.20521729  0.12013845 -0.06374133\n",
      "  -0.02477405  0.02528322 -0.01590031  0.04751011 -0.17829372 -0.22820728\n",
      "   0.2971012  -0.2446874  -0.05363576 -0.03390842]\n",
      " [-0.29390913  0.09263787 -0.33330426 -0.18944603 -0.25264004  0.06865249\n",
      "   0.26102686 -0.18672867 -0.07013597  0.09645228  0.06126654 -0.10778011\n",
      "  -0.04747451 -0.22576983  0.1012185   0.02811892 -0.17445968  0.27496547\n",
      "   0.05527949  0.08184452 -0.17765856  0.11106235 -0.16169366  0.00613702\n",
      "  -0.3017288   0.14146754  0.33003038  0.2176185   0.01011087 -0.06358144\n",
      "  -0.12042985 -0.1060584  -0.21358882  0.27947208 -0.19307391 -0.01903724\n",
      "  -0.23455887 -0.02675616  0.2753932  -0.1896125 ]\n",
      " [-0.26939207  0.27747908 -0.19412225  0.27902788 -0.08136605  0.28964138\n",
      "  -0.20648159 -0.2956281  -0.1370177   0.05202961 -0.1731085   0.14865576\n",
      "  -0.19031373 -0.0383183  -0.24685442 -0.14666638  0.03356162  0.10568856\n",
      "   0.16149172  0.22826272  0.17022443  0.20379084  0.10024427 -0.06832308\n",
      "  -0.14731659 -0.10833056  0.09913034 -0.2745185  -0.32387698 -0.1791534\n",
      "  -0.12181991  0.14582454 -0.12226651 -0.20755619 -0.2249327   0.2176223\n",
      "  -0.31444594  0.25875318  0.28079832 -0.20829879]\n",
      " [-0.15439995  0.21333124  0.11753169  0.08511163 -0.18557075 -0.01272423\n",
      "  -0.27159604 -0.2256349   0.20650138  0.07550941  0.04795396 -0.24368428\n",
      "   0.17720138 -0.13995908  0.1768803   0.05924888 -0.08895902  0.14866209\n",
      "   0.32201278  0.03995647 -0.2544598  -0.10435997 -0.29794377  0.28524283\n",
      "   0.17503457 -0.21782349 -0.2726403   0.18434635 -0.05935012 -0.19358435\n",
      "  -0.27989942 -0.00462236  0.14090157 -0.2354305  -0.34011975  0.31958637\n",
      "   0.07327966  0.04409036  0.13200754  0.12367194]\n",
      " [-0.03310163 -0.3113926   0.00739078 -0.01883604  0.25578526  0.13243517\n",
      "   0.03294142 -0.02489055  0.17028438 -0.00102609 -0.07493197  0.09092353\n",
      "  -0.05263808  0.19322139  0.32566732  0.16368876  0.30576056 -0.30650708\n",
      "  -0.29189643  0.20622537  0.04041605 -0.251908    0.34270304  0.25272444\n",
      "  -0.10614295 -0.07854681  0.08594411 -0.33532733  0.25443453 -0.26658207\n",
      "   0.30882296  0.0126534  -0.10716984 -0.1433002   0.09414403 -0.29873616\n",
      "   0.25792852 -0.28742144  0.11824343  0.17652233]\n",
      " [-0.24377947 -0.0822511   0.14921087  0.26140392 -0.15766965  0.0508007\n",
      "   0.27264133  0.20830473 -0.33149594 -0.28266907  0.04778343  0.00311946\n",
      "   0.14875953  0.11249211 -0.19029416  0.22747043 -0.14579758  0.14133982\n",
      "   0.29986274  0.21604133 -0.07363102 -0.2880475  -0.11789533 -0.06015079\n",
      "  -0.01511521  0.00099744  0.02330038 -0.24601072  0.08284986 -0.28535154\n",
      "  -0.23204532  0.01423197  0.18746865  0.25010565  0.06396925 -0.21994627\n",
      "  -0.05323256  0.05517508  0.2080108   0.07281043]\n",
      " [-0.00279183 -0.3019396   0.21971141 -0.11885459  0.05804576  0.0874868\n",
      "   0.21447292 -0.2061064   0.13112588 -0.1034178  -0.3303023   0.11543312\n",
      "   0.0895704  -0.28894845  0.264774    0.3305203  -0.32188684  0.13014682\n",
      "   0.06979819  0.10505269 -0.04977207 -0.3179738  -0.23907536  0.09002981\n",
      "  -0.1750987  -0.25516793  0.12882715 -0.22816613  0.26913124 -0.12731232\n",
      "   0.06362611  0.21504276  0.27763513 -0.0215969   0.27451712  0.24761751\n",
      "   0.00396323 -0.15485577  0.15804717  0.30691338]\n",
      " [ 0.24037132  0.10598037  0.28595734  0.11648489 -0.18796535  0.19848831\n",
      "   0.3170248   0.01195098  0.15664637  0.13579714 -0.02239792  0.11164998\n",
      "  -0.03070947 -0.27540502 -0.14257655  0.04429071 -0.2719183   0.21303883\n",
      "   0.3058439   0.12754537 -0.04247689  0.24626167 -0.00950589 -0.23823096\n",
      "  -0.01382003 -0.2544704   0.27217087 -0.30701888 -0.0396012  -0.26470593\n",
      "  -0.27280307  0.13631028 -0.0638867   0.1474298   0.2993741  -0.19851424\n",
      "  -0.17592098  0.09611715 -0.08822445  0.30522346]\n",
      " [ 0.27226847  0.16410877 -0.24920925 -0.08390294 -0.15553305 -0.28246683\n",
      "  -0.10984225  0.03274951 -0.14622831 -0.04914873 -0.00497701 -0.21890023\n",
      "  -0.11529093 -0.02234435  0.17727396 -0.1096582   0.24485639  0.1311078\n",
      "   0.1416424   0.0409972  -0.16100696 -0.33709708  0.20030811 -0.24833359\n",
      "  -0.05514384 -0.3185604   0.15016374  0.35757962 -0.24895778  0.1459829\n",
      "  -0.11675497  0.31609082  0.14556989 -0.15097928  0.02680645  0.00993035\n",
      "   0.21616264  0.01933387  0.3272921  -0.13851625]\n",
      " [ 0.01160496  0.14035332  0.21988724  0.17396756 -0.27377293  0.21545497\n",
      "  -0.24191628 -0.08687075  0.13328257  0.09732132 -0.27361152  0.34319922\n",
      "   0.25943446  0.06098701 -0.22173087  0.0844253  -0.01889438 -0.161244\n",
      "  -0.03542536  0.24431486 -0.10669971  0.27772287 -0.08525141 -0.22972524\n",
      "  -0.11086882 -0.2899766   0.1764158   0.05576904  0.01940067 -0.12687983\n",
      "  -0.31176546 -0.15585564 -0.02198737  0.18158743  0.12090573 -0.3293099\n",
      "  -0.00777267  0.3427922  -0.31523687  0.01295295]\n",
      " [-0.15222558  0.27160177  0.1372835   0.1984555   0.2057898  -0.03733971\n",
      "  -0.23026437 -0.29715618 -0.22579859  0.2597583   0.31517187  0.003873\n",
      "  -0.11977936  0.19890243 -0.0277024  -0.07070708  0.20241153 -0.05011777\n",
      "  -0.2009041  -0.29907626 -0.2969692  -0.12837672 -0.04925374  0.25209808\n",
      "   0.19506077  0.20720887  0.01636712  0.18499884  0.05672893 -0.32088256\n",
      "   0.34551808  0.0168306  -0.07150984 -0.32796854 -0.27861804 -0.16139427\n",
      "   0.19036624 -0.09693537  0.10517665  0.05256628]\n",
      " [ 0.05500288  0.1606446   0.07957129 -0.06405731 -0.18238817 -0.22333165\n",
      "  -0.0714185  -0.01721171  0.12964979  0.1589977   0.21879943 -0.25674704\n",
      "  -0.04752989  0.2556359   0.03898714 -0.14841713 -0.23441234 -0.12091725\n",
      "  -0.05743549  0.21249017 -0.18293433 -0.07969837  0.33786473  0.16421905\n",
      "  -0.32539865  0.10963008  0.23128381 -0.03347775  0.01392824  0.26824728\n",
      "  -0.22563313 -0.07650235 -0.27081934 -0.16144581  0.23914962  0.01058443\n",
      "  -0.08265892 -0.20125428 -0.218358   -0.09629954]]\n",
      "  - Pesos 1: (40,)\n",
      "[-0.00015946 -0.01544077 -0.00694535 -0.00136549  0.01667873  0.00778993\n",
      "  0.00445124 -0.01540794  0.00783247 -0.0038645   0.00663894  0.00863584\n",
      " -0.00608933 -0.00765862 -0.00636873 -0.00699021  0.01009415  0.00077657\n",
      "  0.00317885 -0.0110099  -0.00266565 -0.00364317 -0.01084948 -0.00017546\n",
      "  0.00584826  0.00280209 -0.01319782 -0.00240331  0.00175663 -0.01181797\n",
      "  0.01022485 -0.00633098  0.00568186  0.01780739 -0.01716635  0.01486338\n",
      " -0.00204067 -0.00702358 -0.00766381  0.00687402]\n",
      "\n",
      "ğŸ”¹ Capa 2: dense_66 (Dense)\n",
      "  - Pesos 0: (40, 60)\n",
      "[[ 0.11492094  0.11966398 -0.08762878 ...  0.2127994   0.238317\n",
      "  -0.15156628]\n",
      " [ 0.06667633 -0.16953804 -0.0100338  ...  0.03178664  0.12581512\n",
      "  -0.06719587]\n",
      " [ 0.13462824 -0.092703   -0.05398148 ... -0.06825818 -0.04627371\n",
      "   0.02669418]\n",
      " ...\n",
      " [-0.02558923  0.05632432  0.24952456 ...  0.06532087  0.09331114\n",
      "  -0.12650155]\n",
      " [-0.10579289  0.10783351 -0.08876651 ...  0.02276259 -0.05641151\n",
      "   0.02741361]\n",
      " [-0.22796649 -0.05964892 -0.07376745 ...  0.01203347 -0.16927782\n",
      "   0.05620176]]\n",
      "  - Pesos 1: (60,)\n",
      "[ 0.00739113  0.00296231  0.00024714 -0.00892219  0.01000487 -0.00274643\n",
      "  0.00547423  0.00712019  0.00411125  0.00256104  0.00563628 -0.00113014\n",
      " -0.02098165 -0.00155854  0.00675107  0.01054939 -0.00434957  0.01922797\n",
      "  0.00302092 -0.01216038 -0.00532472  0.00363371 -0.00039521  0.0022499\n",
      "  0.00192254 -0.01989438 -0.00922863 -0.00608169 -0.00380537  0.02859454\n",
      " -0.00802221 -0.01411367  0.01109087  0.01117563 -0.00239437  0.00166903\n",
      " -0.00066086 -0.01483597  0.00813614  0.00964791  0.00020759  0.02267933\n",
      " -0.00377752 -0.00087753 -0.00329181  0.00014134  0.00269309  0.00290385\n",
      "  0.00173101  0.00635185  0.01005517 -0.00880824  0.0031292  -0.02078521\n",
      "  0.01000595  0.00712689  0.00105383 -0.00208952  0.00634465  0.00325505]\n",
      "\n",
      "ğŸ”¹ Capa 3: dense_67 (Dense)\n",
      "  - Pesos 0: (60, 80)\n",
      "[[-0.10608682  0.03607523 -0.06328054 ...  0.11862912  0.00807579\n",
      "   0.20795418]\n",
      " [ 0.03405995 -0.00769318  0.15778624 ... -0.10570003 -0.07080966\n",
      "   0.12239359]\n",
      " [-0.16343284  0.0499783   0.16744237 ... -0.15804815  0.2399104\n",
      "  -0.02973077]\n",
      " ...\n",
      " [-0.12427769 -0.11529586 -0.20618768 ... -0.05198215 -0.1262459\n",
      "   0.19679138]\n",
      " [-0.19952124  0.18787183  0.1101336  ... -0.12355266 -0.17228992\n",
      "   0.14924614]\n",
      " [ 0.1931655  -0.05368262  0.1682382  ...  0.09848569  0.13447517\n",
      "   0.02309386]]\n",
      "  - Pesos 1: (80,)\n",
      "[ 9.2885913e-03 -1.1263599e-02 -2.2369900e-03  4.5678588e-03\n",
      "  5.9097582e-03  1.2327321e-02  2.1360996e-04  8.5589447e-05\n",
      " -4.0211915e-03 -1.9207475e-05  1.0703498e-02  9.1202697e-03\n",
      "  1.4225784e-03 -2.8245142e-03  3.0243788e-03 -2.9148769e-03\n",
      "  7.8793000e-03  1.2364125e-02 -1.7320093e-02  4.7194008e-03\n",
      " -1.4554620e-03 -1.1118796e-02 -2.8449367e-03  5.3134309e-03\n",
      "  1.9814696e-03  1.1792431e-03  5.9857504e-03  2.3695419e-03\n",
      " -1.0278092e-02 -9.1182395e-05 -1.5479128e-03 -9.1016386e-03\n",
      "  1.7082606e-02  4.3059583e-03 -1.9575050e-03  1.8490624e-03\n",
      "  2.3885628e-03  1.1330980e-02 -2.7420567e-03  1.0232566e-02\n",
      " -2.7596336e-03 -1.7133019e-03 -6.8844967e-03 -3.8760852e-03\n",
      "  1.0019329e-03 -3.1018810e-04  3.7702096e-03  6.4186694e-04\n",
      "  3.8757403e-03  7.3604730e-05  4.0337453e-03  5.1299133e-03\n",
      "  2.7289274e-03 -8.6063351e-03  1.3336869e-03  7.4197270e-04\n",
      "  1.0406590e-02  3.0745578e-03 -5.8506615e-03 -2.2253452e-03\n",
      " -5.0837710e-03 -1.1624986e-03  8.7008281e-03  7.6153944e-04\n",
      "  5.1392480e-03 -4.6751006e-03  1.8848580e-03 -7.4974837e-04\n",
      " -9.8141842e-04  3.1370206e-03 -3.2022763e-03 -7.4977316e-03\n",
      " -4.1018515e-03  2.0374518e-03  4.3459763e-04 -5.6668301e-03\n",
      " -2.6740549e-02 -1.8345891e-04 -8.2760546e-03 -3.7295988e-03]\n",
      "\n",
      "ğŸ”¹ Capa 4: dense_68 (Dense)\n",
      "  - Pesos 0: (80, 80)\n",
      "[[ 0.1676082   0.14400315 -0.02994482 ...  0.1431545   0.06770363\n",
      "   0.07861955]\n",
      " [ 0.18625672  0.1605919   0.05185982 ... -0.07977789  0.1085342\n",
      "   0.09883668]\n",
      " [ 0.1196783   0.07241159  0.16898702 ... -0.01090163 -0.13863769\n",
      "  -0.18608381]\n",
      " ...\n",
      " [ 0.12323667 -0.13565916 -0.00163673 ... -0.04367435 -0.07005361\n",
      "   0.06820615]\n",
      " [ 0.16430198  0.00482686  0.0392078  ... -0.16043457  0.01018622\n",
      "  -0.16995598]\n",
      " [ 0.11959296  0.01822918 -0.05914114 ... -0.0640229  -0.11208064\n",
      "   0.13564572]]\n",
      "  - Pesos 1: (80,)\n",
      "[-3.0627521e-03  2.6004820e-03  3.8496586e-03 -1.2969574e-03\n",
      " -7.6356246e-03 -7.6813432e-03 -3.2334652e-04  2.5260991e-03\n",
      "  2.5078396e-03  5.8574714e-03 -3.5924776e-04 -2.4250140e-03\n",
      " -6.2664128e-03 -7.4954843e-03 -4.1767373e-03  1.1470595e-02\n",
      " -7.4471242e-04 -4.2911558e-03 -5.0384579e-03  9.8782610e-03\n",
      "  3.3864003e-02  1.4037885e-03 -6.6495095e-03  3.1637594e-03\n",
      " -3.6944507e-03 -8.8008521e-03  1.0212683e-03  4.6619293e-03\n",
      " -3.5631638e-03 -1.1234125e-03 -5.0375918e-03  2.8839982e-03\n",
      "  2.0685964e-04 -1.0896377e-03 -1.0808072e-02 -1.8447203e-03\n",
      "  7.9219829e-04 -1.7744316e-04  2.7280863e-04 -8.3631743e-03\n",
      " -3.0687307e-03  5.9668547e-03 -7.4114319e-04 -1.5537710e-04\n",
      "  8.4406772e-04 -8.2706225e-05 -2.2608493e-03  6.6619636e-03\n",
      "  2.6158881e-03 -6.8883579e-03 -1.7908543e-02  3.3450662e-04\n",
      "  1.2341530e-02  2.3350515e-04  1.1421538e-02  6.7453841e-03\n",
      "  4.0096440e-03 -5.9764064e-03 -1.2346436e-03  4.9035992e-03\n",
      " -1.4549046e-03 -1.4453664e-05 -4.9573216e-03 -7.6589826e-04\n",
      "  3.6278300e-03  1.7378818e-02 -1.3096310e-02 -2.4145478e-03\n",
      "  1.2872962e-03 -2.2312179e-03 -2.1570048e-03  6.7740800e-03\n",
      "  8.0183253e-04 -3.8656392e-04  4.6779430e-03 -4.4404087e-03\n",
      " -1.0407979e-03  1.3033649e-03  9.2795235e-04  8.8427553e-04]\n",
      "\n",
      "ğŸ”¹ Capa 5: dense_69 (Dense)\n",
      "  - Pesos 0: (80, 70)\n",
      "[[-0.00537548  0.09631748  0.03362076 ...  0.17276724  0.16027534\n",
      "  -0.16347511]\n",
      " [-0.15472803 -0.02063469 -0.17636144 ...  0.09646577  0.09553502\n",
      "   0.16314726]\n",
      " [-0.1546117  -0.00421278  0.18581544 ... -0.05435497  0.13604048\n",
      "   0.18226255]\n",
      " ...\n",
      " [-0.11287683 -0.08003858  0.0127928  ...  0.06037443  0.18629904\n",
      "  -0.14718063]\n",
      " [ 0.01936869  0.03188994  0.15302277 ... -0.09690366 -0.16235676\n",
      "   0.03849727]\n",
      " [-0.18897444 -0.03668327  0.05853616 ... -0.15659955  0.03970696\n",
      "   0.04327745]]\n",
      "  - Pesos 1: (70,)\n",
      "[-1.7140382e-03 -3.5996153e-03  1.4112712e-02 -5.9259718e-04\n",
      " -5.6568375e-03 -1.0310664e-03 -2.1888399e-03 -5.7434877e-03\n",
      "  2.4589887e-03 -7.3298765e-04 -3.8911307e-03 -7.1166549e-05\n",
      "  3.1027442e-04 -1.5918514e-03 -6.2762736e-04  1.2254484e-03\n",
      " -1.3688690e-03 -8.0666761e-04  3.8099340e-03 -4.2250194e-04\n",
      "  2.7024554e-04  5.9730659e-04  9.4963135e-03 -2.3001649e-03\n",
      "  3.7594740e-03 -2.9160990e-03  1.8512051e-03  4.4483682e-03\n",
      "  2.6631418e-03 -4.9603656e-03  1.5207359e-03  6.6383453e-03\n",
      " -2.6069066e-04  1.5730890e-02  1.5150798e-04  2.0263612e-03\n",
      "  2.7080793e-03 -1.1986246e-02  4.0411530e-03 -7.5756446e-03\n",
      " -1.0626836e-03  1.1541931e-03  1.7140801e-03  1.1230456e-03\n",
      "  5.0919165e-04  4.1829338e-03 -4.7942838e-03  3.5535362e-05\n",
      " -2.3412041e-03  3.7976154e-03 -1.9307939e-03 -8.9018210e-04\n",
      "  1.2209684e-03 -1.6545619e-04  1.4983246e-03 -9.7165089e-03\n",
      "  5.0918601e-04  2.0886110e-03  3.7176721e-03  1.0795270e-03\n",
      "  5.4142317e-03 -1.0948430e-03  4.4361851e-04 -1.6153946e-03\n",
      "  1.1387839e-03  6.1154511e-04 -2.9251329e-04 -2.3766658e-03\n",
      " -7.3545217e-04 -3.2008547e-04]\n",
      "\n",
      "ğŸ”¹ Capa 6: dense_70 (Dense)\n",
      "  - Pesos 0: (70, 30)\n",
      "[[-0.0572822  -0.04478326 -0.24355897 ... -0.04998172  0.16011594\n",
      "  -0.18396781]\n",
      " [ 0.19791098 -0.2439152  -0.04821352 ... -0.180215    0.05792432\n",
      "   0.09601128]\n",
      " [ 0.06357272  0.14619154 -0.08151475 ...  0.18793428 -0.20890847\n",
      "   0.03867467]\n",
      " ...\n",
      " [ 0.11200663  0.10837794  0.03246728 ... -0.22998136  0.04627914\n",
      "  -0.13057277]\n",
      " [ 0.0914312  -0.17946884  0.0575766  ...  0.08076323 -0.00938431\n",
      "  -0.06699113]\n",
      " [-0.20021287  0.09238353  0.17030899 ...  0.11290384  0.10659574\n",
      "  -0.13206972]]\n",
      "  - Pesos 1: (30,)\n",
      "[ 3.9804978e-03  1.6351128e-03 -6.6269291e-05  1.1049142e-03\n",
      "  2.3693782e-03 -6.3598814e-04  7.4678725e-03  4.9212086e-04\n",
      " -2.0206594e-03  7.4533089e-03 -5.7992764e-04 -1.9817255e-04\n",
      "  2.0095014e-03 -6.6472413e-03 -2.7175224e-04 -1.6249201e-03\n",
      "  8.6805079e-04  2.4150636e-03  1.2941159e-02  2.1029357e-02\n",
      " -9.0312125e-04  1.6099617e-05 -7.3618195e-03  7.1462378e-04\n",
      " -4.3694889e-03  1.4708253e-03 -2.5241598e-04 -6.8017413e-05\n",
      " -7.5738505e-04 -1.7159791e-03]\n",
      "\n",
      "ğŸ”¹ Capa 7: dense_71 (Dense)\n",
      "  - Pesos 0: (30, 70)\n",
      "[[ 0.02925821 -0.21657938 -0.21905068 ... -0.06048652  0.06241437\n",
      "  -0.02625688]\n",
      " [ 0.06150954  0.00580834  0.22095656 ...  0.03280517 -0.18537982\n",
      "   0.1785157 ]\n",
      " [ 0.06511502  0.15469639 -0.10700864 ...  0.17404556 -0.13913742\n",
      "   0.22664294]\n",
      " ...\n",
      " [ 0.17425083  0.18171981  0.18206815 ...  0.20272048 -0.16971257\n",
      "  -0.09075041]\n",
      " [-0.25995818  0.06066614  0.13987076 ... -0.22323306 -0.23532976\n",
      "   0.03967312]\n",
      " [-0.07088081  0.06925678  0.20352781 ... -0.19793895  0.17911227\n",
      "  -0.03821677]]\n",
      "  - Pesos 1: (70,)\n",
      "[ 0.01420351  0.00208704 -0.00178142  0.00061722  0.00209306  0.00095346\n",
      "  0.0021252   0.00454157  0.0064567   0.00187016 -0.00109073  0.00167469\n",
      "  0.0016927  -0.00261632  0.00708979 -0.00346936 -0.0007635   0.00204552\n",
      " -0.00429573 -0.0007114   0.00511519 -0.00095617  0.00423976  0.01076115\n",
      " -0.00276729 -0.00258013  0.00273939  0.0023027  -0.01077158 -0.00108897\n",
      " -0.00144289 -0.00017126  0.00065975 -0.00241797 -0.00179048 -0.00063572\n",
      " -0.02016701 -0.00244249  0.00056144  0.00376078 -0.00189416  0.00310166\n",
      " -0.003387   -0.00274001  0.001203   -0.00314045  0.00264413 -0.00987351\n",
      " -0.00133661 -0.00131582 -0.00096668  0.0041019  -0.00021546  0.00274977\n",
      " -0.00065063  0.01191158  0.00544141  0.0018357   0.00280889 -0.0082397\n",
      " -0.00867153 -0.00093597  0.00031435  0.00162817  0.00013849 -0.00275696\n",
      " -0.00117544 -0.00236827  0.00032207  0.00506   ]\n",
      "\n",
      "ğŸ”¹ Capa 8: dense_72 (Dense)\n",
      "  - Pesos 0: (70, 70)\n",
      "[[ 0.14263618  0.04633788  0.12742923 ...  0.04190784 -0.09957184\n",
      "  -0.09983855]\n",
      " [ 0.11279597 -0.16477989 -0.09085345 ... -0.17105582 -0.15424669\n",
      "   0.06371266]\n",
      " [-0.05484029  0.06130867 -0.04282324 ... -0.06527739  0.09396312\n",
      "   0.15794408]\n",
      " ...\n",
      " [ 0.0302594  -0.12523708  0.04760653 ...  0.04238617  0.02891629\n",
      "   0.13377264]\n",
      " [-0.19516663  0.14063336 -0.12267358 ...  0.16304529 -0.10125075\n",
      "   0.16368723]\n",
      " [-0.15523086  0.19224386  0.04416298 ... -0.06552156 -0.10033971\n",
      "  -0.05197401]]\n",
      "  - Pesos 1: (70,)\n",
      "[-0.00051597  0.00477     0.01076919 -0.00269393  0.00239882  0.00332486\n",
      " -0.00377453 -0.00698879 -0.00895463 -0.00270485  0.00120399 -0.01044554\n",
      "  0.00453418 -0.00010901 -0.00355097  0.00187376  0.00112494 -0.00381862\n",
      " -0.00571527  0.00042936 -0.00080281  0.00140721  0.031514    0.00056845\n",
      "  0.00324485 -0.00052124 -0.0044281  -0.00212947 -0.0024969   0.00241625\n",
      "  0.00106984  0.00248603  0.00774493  0.00914011 -0.00658887 -0.00205804\n",
      "  0.00660224 -0.00187036 -0.00231655 -0.0002346   0.00239484  0.00111338\n",
      " -0.00210507 -0.0009127  -0.0019028   0.0021954  -0.00224824 -0.00073702\n",
      " -0.00287368 -0.00292457  0.00262824  0.00189266 -0.00070454  0.00263857\n",
      "  0.00259477 -0.00136987  0.00119798 -0.0031546   0.00213655 -0.00098024\n",
      " -0.00079346 -0.00152643 -0.00460598 -0.00021262 -0.00209319  0.0047548\n",
      " -0.00247032 -0.00354931  0.00740057 -0.00787834]\n",
      "\n",
      "ğŸ”¹ Capa 9: dense_73 (Dense)\n",
      "  - Pesos 0: (70, 30)\n",
      "[[-0.01499635  0.02576076  0.08102421 ... -0.00862523 -0.03549709\n",
      "  -0.1678079 ]\n",
      " [ 0.13892175  0.24650137  0.08317547 ...  0.23480566 -0.03405192\n",
      "   0.14688627]\n",
      " [ 0.19813168 -0.10347524 -0.07269574 ...  0.02590105  0.19465531\n",
      "  -0.13492845]\n",
      " ...\n",
      " [-0.00966195 -0.15968351  0.16845886 ... -0.23223951 -0.19861358\n",
      "  -0.13726184]\n",
      " [-0.1393497  -0.04089518  0.1508299  ... -0.16680402  0.15738577\n",
      "   0.1343412 ]\n",
      " [-0.05799662 -0.11248238 -0.17822681 ... -0.08017621  0.13870877\n",
      "  -0.07101724]]\n",
      "  - Pesos 1: (30,)\n",
      "[ 0.00160171 -0.0011744  -0.00955403 -0.0044128  -0.00524144 -0.00146118\n",
      " -0.00091272  0.00100836  0.00470012 -0.00262937  0.00183967 -0.00468721\n",
      "  0.00326239  0.00437855 -0.00309929  0.00022507 -0.00394417  0.00234318\n",
      "  0.00264716 -0.00404426  0.00356611 -0.0024908  -0.00429114  0.00244984\n",
      "  0.00197664 -0.0038123  -0.00280661  0.00329305  0.00354384  0.00253043]\n",
      "\n",
      "ğŸ”¹ Capa 10: dense_74 (Dense)\n",
      "  - Pesos 0: (30, 70)\n",
      "[[ 0.23377998 -0.1612903   0.12929606 ...  0.00856989  0.05056198\n",
      "  -0.00810315]\n",
      " [-0.10707744 -0.02734374 -0.04569679 ...  0.17261277  0.16667317\n",
      "   0.17172296]\n",
      " [-0.11084775  0.06884986  0.20373584 ...  0.13583188  0.02644454\n",
      "   0.16387236]\n",
      " ...\n",
      " [ 0.01513486 -0.14105809  0.03703817 ...  0.12949428 -0.06482385\n",
      "  -0.03654363]\n",
      " [ 0.04056544 -0.03648943  0.20415087 ...  0.03432176 -0.2167589\n",
      "   0.06786938]\n",
      " [ 0.16545506  0.03474021 -0.17935857 ... -0.22849779  0.03064802\n",
      "  -0.11086825]]\n",
      "  - Pesos 1: (70,)\n",
      "[ 0.00298763  0.00379388  0.0047887  -0.00177841  0.00044668  0.00258476\n",
      "  0.00329952 -0.00297026  0.00325193  0.0022754  -0.0044637  -0.00557331\n",
      "  0.00335169  0.00339202  0.00303375  0.00274497 -0.00234725  0.00068215\n",
      "  0.00325838  0.00912907 -0.00255536 -0.0023239   0.00721413  0.00333376\n",
      "  0.00182422  0.0040107  -0.00097991 -0.00303099 -0.0022462   0.00304939\n",
      " -0.00672587 -0.00299491 -0.00383233  0.00269747 -0.0014251   0.00440963\n",
      "  0.00260348 -0.00300197 -0.00889407 -0.00321892  0.00460117 -0.00238491\n",
      "  0.00266437  0.00198913  0.00255828  0.00299948  0.00020332  0.00229311\n",
      " -0.00423559  0.00199797 -0.00282534  0.00238958  0.00394783 -0.00329207\n",
      " -0.00282131 -0.00400997 -0.00305131  0.00126293  0.0027522  -0.00305967\n",
      " -0.0046631  -0.00212029 -0.00257733 -0.00626622 -0.00275599 -0.00256735\n",
      "  0.0016624   0.00066223 -0.00335352  0.00206749]\n",
      "\n",
      "ğŸ”¹ Capa 11: dense_75 (Dense)\n",
      "  - Pesos 0: (70, 20)\n",
      "[[ 0.07957371 -0.11157481  0.02538999 ...  0.07533664  0.17664471\n",
      "  -0.10251479]\n",
      " [ 0.12012471 -0.04286312  0.19270189 ... -0.07671645 -0.08182049\n",
      "   0.02923805]\n",
      " [ 0.21222256  0.0423151  -0.24557877 ... -0.01442664 -0.24386086\n",
      "   0.03670026]\n",
      " ...\n",
      " [-0.16340668 -0.14862154  0.00759646 ...  0.01090204  0.05172972\n",
      "   0.21722102]\n",
      " [ 0.0394811   0.24057852 -0.24431168 ... -0.01369335  0.27613163\n",
      "  -0.04670892]\n",
      " [ 0.14446059  0.05546029 -0.01390059 ... -0.05384252 -0.240457\n",
      "  -0.04184653]]\n",
      "  - Pesos 1: (20,)\n",
      "[ 3.8565630e-03 -3.0948329e-03  2.9936063e-03  2.4972560e-03\n",
      " -3.3670384e-03 -2.6253117e-03 -3.1749052e-03  1.9308863e-03\n",
      " -5.6237984e-03 -4.8313076e-03  3.0526693e-03 -2.9992987e-03\n",
      "  3.0814670e-03 -1.5648831e-02 -3.4845502e-03 -3.3102110e-03\n",
      " -3.9584697e-03  8.6935019e-05  3.6305906e-03 -3.1711233e-03]\n",
      "\n",
      "ğŸ”¹ Capa 12: dense_76 (Dense)\n",
      "  - Pesos 0: (20, 60)\n",
      "[[-0.23947988 -0.03296357 -0.21436642 ...  0.25065282  0.15965828\n",
      "   0.16486363]\n",
      " [ 0.06347056  0.01391031 -0.07585187 ...  0.22151802  0.12770408\n",
      "  -0.25240824]\n",
      " [ 0.12046175  0.02008232  0.22935215 ... -0.17085834  0.02744587\n",
      "   0.24371448]\n",
      " ...\n",
      " [-0.18407954  0.09364296  0.15525658 ...  0.03802914  0.02088518\n",
      "   0.00541358]\n",
      " [-0.01982836 -0.05325431 -0.18741211 ...  0.01598323 -0.18265367\n",
      "   0.0203526 ]\n",
      " [ 0.08292952  0.12209441 -0.256535   ...  0.12117828  0.22912931\n",
      "  -0.23350193]]\n",
      "  - Pesos 1: (60,)\n",
      "[ 0.00420171 -0.00354312  0.00399531  0.00440894  0.0025176  -0.00400685\n",
      " -0.00410902  0.00356304 -0.00419707  0.00384356  0.00397584 -0.00300009\n",
      "  0.00424652  0.00442437  0.00436973  0.00402188 -0.00416056  0.00340239\n",
      " -0.00427072 -0.00390653  0.00432575  0.00406683  0.00316564  0.00422287\n",
      "  0.00367838  0.00447909  0.00396014 -0.00410162 -0.00289084 -0.00314311\n",
      "  0.00406994 -0.00429361 -0.00424202 -0.00416433 -0.00349164  0.00408575\n",
      "  0.00419462  0.00396951 -0.00390121  0.00445297  0.00384048 -0.00403782\n",
      " -0.00419545  0.00343637  0.0043034   0.00305702 -0.00439897  0.00409744\n",
      " -0.00398466 -0.00345987  0.00435327  0.00379386 -0.00413777  0.00379393\n",
      "  0.00395873  0.00451272  0.00254866 -0.00399978  0.00449015  0.00345293]\n",
      "\n",
      "ğŸ”¹ Capa 13: dense_77 (Dense)\n",
      "  - Pesos 0: (60, 1)\n",
      "[[ 0.30339408]\n",
      " [-0.25767502]\n",
      " [ 0.22851272]\n",
      " [ 0.2996451 ]\n",
      " [ 0.30578646]\n",
      " [-0.15560094]\n",
      " [-0.20279178]\n",
      " [ 0.32001123]\n",
      " [-0.2670629 ]\n",
      " [ 0.01613952]\n",
      " [ 0.24431308]\n",
      " [-0.28504717]\n",
      " [ 0.2851922 ]\n",
      " [ 0.16749787]\n",
      " [ 0.12982461]\n",
      " [ 0.09436976]\n",
      " [-0.2157519 ]\n",
      " [ 0.2340564 ]\n",
      " [-0.19801776]\n",
      " [-0.20145048]\n",
      " [ 0.16525409]\n",
      " [ 0.06409822]\n",
      " [ 0.24772511]\n",
      " [ 0.10023061]\n",
      " [ 0.24897824]\n",
      " [ 0.26023105]\n",
      " [ 0.2411335 ]\n",
      " [-0.14561322]\n",
      " [-0.00183977]\n",
      " [-0.15970375]\n",
      " [ 0.2827731 ]\n",
      " [-0.18880963]\n",
      " [-0.14754646]\n",
      " [-0.08276491]\n",
      " [-0.07846962]\n",
      " [ 0.06988283]\n",
      " [ 0.17882833]\n",
      " [ 0.21063106]\n",
      " [-0.1436294 ]\n",
      " [ 0.3004852 ]\n",
      " [ 0.1135246 ]\n",
      " [-0.07758784]\n",
      " [-0.0350162 ]\n",
      " [ 0.02996452]\n",
      " [ 0.20162532]\n",
      " [ 0.0462306 ]\n",
      " [-0.00905516]\n",
      " [ 0.29509282]\n",
      " [-0.07062191]\n",
      " [-0.30493617]\n",
      " [ 0.30347845]\n",
      " [ 0.10970571]\n",
      " [-0.20478685]\n",
      " [ 0.00717148]\n",
      " [ 0.3223682 ]\n",
      " [ 0.02030658]\n",
      " [ 0.25251126]\n",
      " [-0.1957959 ]\n",
      " [ 0.23706701]\n",
      " [ 0.09537455]]\n",
      "  - Pesos 1: (1,)\n",
      "[0.00420095]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the weights of the model before the pruning process\n",
    "inspect_model_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Capa 0: input_layer_5 (InputLayer)\n",
      "  - âš ï¸ Esta capa no tiene pesos entrenables.\n",
      "\n",
      "ğŸ”¹ Capa 1: dense_66 (Dense)\n",
      "  - Pesos 0: (12, 60)\n",
      "[[-0.20643388  0.01737381 -0.00188578  0.00556127 -0.10054328 -0.2519836\n",
      "  -0.1667882   0.07135277 -0.17053965  0.1275013   0.04329761  0.08041992\n",
      "  -0.1192439  -0.11776188 -0.01921184  0.10459366 -0.11548372  0.08950839\n",
      "   0.1624882  -0.16331919  0.03551297  0.11267059 -0.04133165  0.03294617\n",
      "   0.13955274  0.12717809 -0.11313774 -0.1067669   0.06422283  0.09431536\n",
      "  -0.12213927 -0.08069505 -0.21390247 -0.07917381 -0.16724993 -0.14692762\n",
      "  -0.12473761  0.15342925  0.22386019 -0.08436671 -0.13789415  0.17510635\n",
      "  -0.14657678  0.07016288 -0.0576023  -0.18092096 -0.12540042 -0.05903937\n",
      "  -0.21648926  0.10846126 -0.04665549 -0.17362091 -0.19607621  0.17490526\n",
      "  -0.14085928  0.14255056 -0.01416865 -0.10074482 -0.04997594 -0.01044213]\n",
      " [ 0.20612204 -0.06837474  0.16418466  0.11965851 -0.05126453  0.16008167\n",
      "  -0.22026812 -0.1146555  -0.12831193  0.21519008 -0.20745929 -0.08214993\n",
      "   0.03506324 -0.08378301  0.10971073  0.20177875  0.03992837 -0.19704722\n",
      "  -0.0441857  -0.1606834  -0.15396902  0.15029132  0.05103984  0.18369538\n",
      "  -0.11211053 -0.2503213  -0.02455776  0.09199585 -0.09919521  0.06381448\n",
      "   0.17185453 -0.03882181 -0.19291402  0.08305123 -0.2540551  -0.16331059\n",
      "  -0.17100473 -0.27658358 -0.04295852  0.0375803  -0.18997319  0.06676216\n",
      "  -0.25422874  0.08914133 -0.02811018  0.14950083  0.0810666   0.22317043\n",
      "   0.14215343 -0.13810714  0.00868923 -0.17301434  0.17821193 -0.05030166\n",
      "   0.08237852 -0.1706292  -0.14226682 -0.01220831 -0.19573256 -0.14926565]\n",
      " [ 0.11492094  0.11966398 -0.08762878 -0.10194834 -0.1219135  -0.16812699\n",
      "  -0.16867441 -0.10744796  0.22477266  0.00492539 -0.20637766  0.14611484\n",
      "  -0.04962061  0.0842566  -0.09351897 -0.20570977 -0.10763266 -0.11942083\n",
      "   0.13120545 -0.12940237 -0.12196033 -0.188675   -0.04901424  0.03198989\n",
      "   0.10757046  0.05146294  0.06314678 -0.15038133 -0.00566329 -0.03033716\n",
      "  -0.20852153  0.18013495  0.07334907  0.15711676  0.08152432 -0.1271814\n",
      "  -0.14183398 -0.20366609 -0.12101471 -0.0308333  -0.21225263 -0.07132942\n",
      "   0.21519053 -0.18191238  0.00268374 -0.02470721  0.21680026 -0.18407878\n",
      "   0.20156111 -0.09919251 -0.11819895  0.2324274  -0.12819035 -0.04269591\n",
      "  -0.10297902  0.21743146  0.09678008  0.2127994   0.238317   -0.15156628]\n",
      " [-0.01428419  0.06050376 -0.08994191  0.0646475   0.18943271 -0.1980543\n",
      "  -0.1861147   0.06967444  0.15198873 -0.20054686  0.06514616  0.2521505\n",
      "  -0.07067734 -0.14422466 -0.04721655  0.06015626 -0.20996723 -0.14561322\n",
      "  -0.02752666  0.08888051 -0.22856775 -0.13312091 -0.16132712  0.09160241\n",
      "   0.20115389  0.00151712  0.04762238 -0.13285245  0.03478117 -0.16320819\n",
      "   0.02360097  0.07372314 -0.18285382 -0.20839995  0.16296828 -0.23720051\n",
      "  -0.1544409  -0.10516988  0.06892044 -0.02064239  0.02367531  0.06328005\n",
      "   0.16332503  0.17242189  0.14511305 -0.23327152  0.1667595   0.16266859\n",
      "  -0.04999879  0.07663527  0.21360348 -0.11583438 -0.20383565  0.272442\n",
      "  -0.08824301 -0.05518194 -0.12536292 -0.22440074  0.04942844  0.22470738]\n",
      " [-0.0231556  -0.1676987   0.08720452 -0.06515122  0.01408564  0.09413505\n",
      "   0.06207449 -0.07693487  0.21895288 -0.20205851  0.06904425 -0.08224034\n",
      "  -0.16087103  0.14203824 -0.22026303  0.08717046 -0.17448942  0.16289246\n",
      "   0.14937496  0.25984198  0.02535107  0.01707459 -0.2170642   0.20578635\n",
      "  -0.01308426  0.07785976 -0.08491426 -0.13181956 -0.20284751  0.2668738\n",
      "  -0.00795766 -0.11080091 -0.15652245  0.12403646 -0.06206387 -0.18461739\n",
      "  -0.1617989   0.04573339  0.23623906 -0.12117683 -0.07040909  0.13724504\n",
      "  -0.2510253   0.26140285 -0.08505484  0.04694069 -0.09643123  0.18118459\n",
      "   0.16657534 -0.07665169  0.11873905 -0.1509645  -0.06319245  0.20823382\n",
      "  -0.18129584  0.21550064  0.1433221  -0.14345622 -0.20371157 -0.09409145]\n",
      " [ 0.09146968  0.11580018  0.21613993 -0.08131562 -0.25894845 -0.03846938\n",
      "   0.16017854  0.08645979  0.13761672 -0.22295229  0.06644787  0.01991517\n",
      "   0.1841325   0.23047666 -0.23497543  0.21507894  0.12877919  0.08304773\n",
      "   0.04894144 -0.22037199 -0.23836927  0.14081645  0.1956483  -0.01689903\n",
      "  -0.10960986  0.22068554 -0.15421216 -0.01126357 -0.1306671  -0.01553756\n",
      "   0.15004843  0.14916192 -0.01819457 -0.03758598  0.20139779 -0.1261807\n",
      "   0.00201305 -0.05167918 -0.11864252 -0.13365783 -0.12212598 -0.03016192\n",
      "  -0.1793465  -0.17436273  0.09279738  0.16889383  0.10010829 -0.10930654\n",
      "  -0.17129384  0.17039539 -0.13531788 -0.07710206 -0.03750133  0.02833119\n",
      "   0.08592081 -0.01337658  0.08763099  0.11238766 -0.21832539 -0.07616583]\n",
      " [-0.02558923  0.05632432  0.24952456  0.0074418  -0.050544    0.14618596\n",
      "  -0.17316695  0.07565343 -0.19053398  0.11388733 -0.0939279  -0.06432713\n",
      "  -0.12231919  0.09234073 -0.18698512 -0.16128942 -0.22719236 -0.14609544\n",
      "   0.1361394   0.02546173  0.11775316  0.14922656 -0.04959105  0.24665694\n",
      "  -0.11109613  0.10775927 -0.01051914  0.22307642 -0.1900686  -0.06396717\n",
      "  -0.22384611 -0.22269574  0.01164548  0.08415885  0.22089782 -0.16796897\n",
      "   0.2268076   0.21813157 -0.1942285   0.03566102  0.18991709 -0.13135168\n",
      "   0.07852465  0.1794106   0.13104415  0.02091653  0.04232253 -0.2349731\n",
      "   0.02459416  0.09793469  0.05542767  0.1466469  -0.02196862 -0.22160095\n",
      "  -0.03919645  0.15070547  0.20421907  0.06532087  0.09331114 -0.12650155]\n",
      " [-0.06065678  0.04823832 -0.00974639  0.20061544  0.00110114  0.03724484\n",
      "  -0.22332905  0.16648313 -0.0605144  -0.08697945 -0.20253062  0.21986826\n",
      "  -0.164878    0.2374934   0.11330746  0.2115752  -0.13729541  0.00101431\n",
      "   0.1595332  -0.01229027  0.16654852  0.07912039 -0.02497488 -0.10365672\n",
      "   0.2368904   0.02569338 -0.00245751 -0.03024694  0.09347959  0.12484877\n",
      "  -0.03385837 -0.15551375  0.0028842   0.16112949 -0.0904448   0.1165902\n",
      "  -0.19448818  0.02837714 -0.02371855  0.05770582  0.02870775 -0.10351492\n",
      "  -0.10641455 -0.08342873  0.22119205 -0.19559611  0.10524955  0.22026928\n",
      "   0.0702781   0.25316963 -0.17852868 -0.18205667  0.04071123  0.09560478\n",
      "   0.07333196  0.06210322  0.04265329 -0.23136121  0.21985498 -0.14589174]\n",
      " [ 0.22079405 -0.15796947 -0.18205254 -0.04382699  0.03437828  0.00738822\n",
      "  -0.18715931  0.23647752  0.00086157  0.21918689  0.05214008  0.01490434\n",
      "   0.07794896  0.2368809   0.09236497  0.12547204  0.216773    0.01265821\n",
      "   0.22665368 -0.20410478 -0.07334402  0.1442253  -0.1343275   0.18700273\n",
      "   0.12884898 -0.16995299  0.03223453 -0.23798351 -0.14065552 -0.13779889\n",
      "   0.20342772 -0.16998939  0.06072322  0.12655482  0.20224492 -0.22338349\n",
      "  -0.1164763   0.02249017  0.04152068 -0.07913905 -0.13835973  0.24204178\n",
      "  -0.0949758  -0.16306934 -0.2230932   0.21801475  0.07018352  0.16620858\n",
      "   0.00523741 -0.02038754 -0.14892645  0.22967611 -0.22290231  0.09595413\n",
      "   0.23293078  0.0884331   0.2480489   0.03844362 -0.15066124  0.00240544]\n",
      " [ 0.22369872 -0.13612343  0.18657275 -0.16618691  0.2074167   0.16803662\n",
      "   0.02881564 -0.22509985  0.20893651  0.21073937  0.20553815  0.07940894\n",
      "   0.12038022 -0.22743383 -0.14730859  0.06045223 -0.16782412  0.02344881\n",
      "  -0.08281886 -0.01267933 -0.21213862  0.15269107 -0.03931411 -0.1833942\n",
      "  -0.09306526  0.24055107 -0.12971517 -0.02377069  0.11163896 -0.13749152\n",
      "   0.15752271  0.04698085  0.08372243 -0.06893733  0.04175101 -0.22521313\n",
      "   0.11134104 -0.02862199  0.17061186  0.00867947 -0.22769621  0.17801404\n",
      "   0.17823642  0.04569993  0.08030319  0.15400814  0.08920299 -0.0886587\n",
      "   0.0248056   0.15484515  0.12292059  0.11025443 -0.08138923 -0.14960702\n",
      "   0.08081213  0.22218673  0.07620777  0.13275631  0.13865533  0.20041417]\n",
      " [ 0.17314556  0.19764337  0.00083974 -0.03032672 -0.00948633 -0.1179531\n",
      "   0.20633154  0.24375138 -0.12416302  0.2206215   0.25235334  0.18050869\n",
      "   0.25501928 -0.00657528  0.07985066  0.12121056 -0.01311773 -0.05053203\n",
      "   0.02182744 -0.15885371  0.2377307  -0.14679617 -0.15884341  0.08252996\n",
      "  -0.07748709 -0.12091067  0.17083202  0.21856895  0.09038396  0.2056595\n",
      "  -0.18846217 -0.00349274 -0.25001392  0.10299999 -0.16923371  0.14885701\n",
      "   0.17246306 -0.03844144  0.2524821   0.22717531 -0.00163912  0.20122313\n",
      "  -0.20971812 -0.06085248 -0.04843016  0.02045977  0.11965886  0.10083672\n",
      "   0.1579533  -0.094689   -0.22533791 -0.06450021  0.06722289 -0.090488\n",
      "  -0.03473439  0.23754613  0.0491138  -0.0564012   0.1771803   0.14595342]\n",
      " [ 0.00104765  0.23002733 -0.11740354  0.16741745 -0.15703996 -0.17302652\n",
      "   0.01728963  0.10194273  0.19220456 -0.19955523  0.24327855  0.0132408\n",
      "   0.19400984 -0.18412118  0.09530464 -0.061668    0.12419719  0.15177034\n",
      "   0.0184892   0.22230674 -0.02032524  0.12454572  0.14600813  0.08075901\n",
      "   0.16385242  0.17524354  0.18392737  0.19550928  0.04977611 -0.14190283\n",
      "   0.1387951   0.18391302 -0.14879048  0.07414271  0.1912047   0.15661263\n",
      "  -0.1492823   0.12664816 -0.1703667   0.00622648 -0.035221   -0.11142295\n",
      "  -0.0560452   0.00455739  0.23289804  0.18337765 -0.06649549  0.22924711\n",
      "   0.18982074  0.00757828 -0.06798094  0.176223    0.00705983  0.05211855\n",
      "  -0.20384626  0.01767709  0.21478032 -0.09908085 -0.04057789 -0.09086047]]\n",
      "  - Pesos 1: (60,)\n",
      "[ 0.00739113  0.00296231  0.00024714 -0.00892219  0.01000487 -0.00274643\n",
      "  0.00547423  0.00712019  0.00411125  0.00256104  0.00563628 -0.00113014\n",
      " -0.02098165 -0.00155854  0.00675107  0.01054939 -0.00434957  0.01922797\n",
      "  0.00302092 -0.01216038 -0.00532472  0.00363371 -0.00039521  0.0022499\n",
      "  0.00192254 -0.01989438 -0.00922863 -0.00608169 -0.00380537  0.02859454\n",
      " -0.00802221 -0.01411367  0.01109087  0.01117563 -0.00239437  0.00166903\n",
      " -0.00066086 -0.01483597  0.00813614  0.00964791  0.00020759  0.02267933\n",
      " -0.00377752 -0.00087753 -0.00329181  0.00014134  0.00269309  0.00290385\n",
      "  0.00173101  0.00635185  0.01005517 -0.00880824  0.0031292  -0.02078521\n",
      "  0.01000595  0.00712689  0.00105383 -0.00208952  0.00634465  0.00325505]\n",
      "\n",
      "ğŸ”¹ Capa 2: dense_67 (Dense)\n",
      "  - Pesos 0: (60, 80)\n",
      "[[-0.10608682  0.03607523 -0.06328054 ...  0.11862912  0.00807579\n",
      "   0.20795418]\n",
      " [ 0.03405995 -0.00769318  0.15778624 ... -0.10570003 -0.07080966\n",
      "   0.12239359]\n",
      " [-0.16343284  0.0499783   0.16744237 ... -0.15804815  0.2399104\n",
      "  -0.02973077]\n",
      " ...\n",
      " [-0.12427769 -0.11529586 -0.20618768 ... -0.05198215 -0.1262459\n",
      "   0.19679138]\n",
      " [-0.19952124  0.18787183  0.1101336  ... -0.12355266 -0.17228992\n",
      "   0.14924614]\n",
      " [ 0.1931655  -0.05368262  0.1682382  ...  0.09848569  0.13447517\n",
      "   0.02309386]]\n",
      "  - Pesos 1: (80,)\n",
      "[ 9.2885913e-03 -1.1263599e-02 -2.2369900e-03  4.5678588e-03\n",
      "  5.9097582e-03  1.2327321e-02  2.1360996e-04  8.5589447e-05\n",
      " -4.0211915e-03 -1.9207475e-05  1.0703498e-02  9.1202697e-03\n",
      "  1.4225784e-03 -2.8245142e-03  3.0243788e-03 -2.9148769e-03\n",
      "  7.8793000e-03  1.2364125e-02 -1.7320093e-02  4.7194008e-03\n",
      " -1.4554620e-03 -1.1118796e-02 -2.8449367e-03  5.3134309e-03\n",
      "  1.9814696e-03  1.1792431e-03  5.9857504e-03  2.3695419e-03\n",
      " -1.0278092e-02 -9.1182395e-05 -1.5479128e-03 -9.1016386e-03\n",
      "  1.7082606e-02  4.3059583e-03 -1.9575050e-03  1.8490624e-03\n",
      "  2.3885628e-03  1.1330980e-02 -2.7420567e-03  1.0232566e-02\n",
      " -2.7596336e-03 -1.7133019e-03 -6.8844967e-03 -3.8760852e-03\n",
      "  1.0019329e-03 -3.1018810e-04  3.7702096e-03  6.4186694e-04\n",
      "  3.8757403e-03  7.3604730e-05  4.0337453e-03  5.1299133e-03\n",
      "  2.7289274e-03 -8.6063351e-03  1.3336869e-03  7.4197270e-04\n",
      "  1.0406590e-02  3.0745578e-03 -5.8506615e-03 -2.2253452e-03\n",
      " -5.0837710e-03 -1.1624986e-03  8.7008281e-03  7.6153944e-04\n",
      "  5.1392480e-03 -4.6751006e-03  1.8848580e-03 -7.4974837e-04\n",
      " -9.8141842e-04  3.1370206e-03 -3.2022763e-03 -7.4977316e-03\n",
      " -4.1018515e-03  2.0374518e-03  4.3459763e-04 -5.6668301e-03\n",
      " -2.6740549e-02 -1.8345891e-04 -8.2760546e-03 -3.7295988e-03]\n",
      "\n",
      "ğŸ”¹ Capa 3: dense_68 (Dense)\n",
      "  - Pesos 0: (80, 80)\n",
      "[[ 0.1676082   0.14400315 -0.02994482 ...  0.1431545   0.06770363\n",
      "   0.07861955]\n",
      " [ 0.18625672  0.1605919   0.05185982 ... -0.07977789  0.1085342\n",
      "   0.09883668]\n",
      " [ 0.1196783   0.07241159  0.16898702 ... -0.01090163 -0.13863769\n",
      "  -0.18608381]\n",
      " ...\n",
      " [ 0.12323667 -0.13565916 -0.00163673 ... -0.04367435 -0.07005361\n",
      "   0.06820615]\n",
      " [ 0.16430198  0.00482686  0.0392078  ... -0.16043457  0.01018622\n",
      "  -0.16995598]\n",
      " [ 0.11959296  0.01822918 -0.05914114 ... -0.0640229  -0.11208064\n",
      "   0.13564572]]\n",
      "  - Pesos 1: (80,)\n",
      "[-3.0627521e-03  2.6004820e-03  3.8496586e-03 -1.2969574e-03\n",
      " -7.6356246e-03 -7.6813432e-03 -3.2334652e-04  2.5260991e-03\n",
      "  2.5078396e-03  5.8574714e-03 -3.5924776e-04 -2.4250140e-03\n",
      " -6.2664128e-03 -7.4954843e-03 -4.1767373e-03  1.1470595e-02\n",
      " -7.4471242e-04 -4.2911558e-03 -5.0384579e-03  9.8782610e-03\n",
      "  3.3864003e-02  1.4037885e-03 -6.6495095e-03  3.1637594e-03\n",
      " -3.6944507e-03 -8.8008521e-03  1.0212683e-03  4.6619293e-03\n",
      " -3.5631638e-03 -1.1234125e-03 -5.0375918e-03  2.8839982e-03\n",
      "  2.0685964e-04 -1.0896377e-03 -1.0808072e-02 -1.8447203e-03\n",
      "  7.9219829e-04 -1.7744316e-04  2.7280863e-04 -8.3631743e-03\n",
      " -3.0687307e-03  5.9668547e-03 -7.4114319e-04 -1.5537710e-04\n",
      "  8.4406772e-04 -8.2706225e-05 -2.2608493e-03  6.6619636e-03\n",
      "  2.6158881e-03 -6.8883579e-03 -1.7908543e-02  3.3450662e-04\n",
      "  1.2341530e-02  2.3350515e-04  1.1421538e-02  6.7453841e-03\n",
      "  4.0096440e-03 -5.9764064e-03 -1.2346436e-03  4.9035992e-03\n",
      " -1.4549046e-03 -1.4453664e-05 -4.9573216e-03 -7.6589826e-04\n",
      "  3.6278300e-03  1.7378818e-02 -1.3096310e-02 -2.4145478e-03\n",
      "  1.2872962e-03 -2.2312179e-03 -2.1570048e-03  6.7740800e-03\n",
      "  8.0183253e-04 -3.8656392e-04  4.6779430e-03 -4.4404087e-03\n",
      " -1.0407979e-03  1.3033649e-03  9.2795235e-04  8.8427553e-04]\n",
      "\n",
      "ğŸ”¹ Capa 4: dense_69 (Dense)\n",
      "  - Pesos 0: (80, 70)\n",
      "[[-0.00537548  0.09631748  0.03362076 ...  0.17276724  0.16027534\n",
      "  -0.16347511]\n",
      " [-0.15472803 -0.02063469 -0.17636144 ...  0.09646577  0.09553502\n",
      "   0.16314726]\n",
      " [-0.1546117  -0.00421278  0.18581544 ... -0.05435497  0.13604048\n",
      "   0.18226255]\n",
      " ...\n",
      " [-0.11287683 -0.08003858  0.0127928  ...  0.06037443  0.18629904\n",
      "  -0.14718063]\n",
      " [ 0.01936869  0.03188994  0.15302277 ... -0.09690366 -0.16235676\n",
      "   0.03849727]\n",
      " [-0.18897444 -0.03668327  0.05853616 ... -0.15659955  0.03970696\n",
      "   0.04327745]]\n",
      "  - Pesos 1: (70,)\n",
      "[-1.7140382e-03 -3.5996153e-03  1.4112712e-02 -5.9259718e-04\n",
      " -5.6568375e-03 -1.0310664e-03 -2.1888399e-03 -5.7434877e-03\n",
      "  2.4589887e-03 -7.3298765e-04 -3.8911307e-03 -7.1166549e-05\n",
      "  3.1027442e-04 -1.5918514e-03 -6.2762736e-04  1.2254484e-03\n",
      " -1.3688690e-03 -8.0666761e-04  3.8099340e-03 -4.2250194e-04\n",
      "  2.7024554e-04  5.9730659e-04  9.4963135e-03 -2.3001649e-03\n",
      "  3.7594740e-03 -2.9160990e-03  1.8512051e-03  4.4483682e-03\n",
      "  2.6631418e-03 -4.9603656e-03  1.5207359e-03  6.6383453e-03\n",
      " -2.6069066e-04  1.5730890e-02  1.5150798e-04  2.0263612e-03\n",
      "  2.7080793e-03 -1.1986246e-02  4.0411530e-03 -7.5756446e-03\n",
      " -1.0626836e-03  1.1541931e-03  1.7140801e-03  1.1230456e-03\n",
      "  5.0919165e-04  4.1829338e-03 -4.7942838e-03  3.5535362e-05\n",
      " -2.3412041e-03  3.7976154e-03 -1.9307939e-03 -8.9018210e-04\n",
      "  1.2209684e-03 -1.6545619e-04  1.4983246e-03 -9.7165089e-03\n",
      "  5.0918601e-04  2.0886110e-03  3.7176721e-03  1.0795270e-03\n",
      "  5.4142317e-03 -1.0948430e-03  4.4361851e-04 -1.6153946e-03\n",
      "  1.1387839e-03  6.1154511e-04 -2.9251329e-04 -2.3766658e-03\n",
      " -7.3545217e-04 -3.2008547e-04]\n",
      "\n",
      "ğŸ”¹ Capa 5: dense_70 (Dense)\n",
      "  - Pesos 0: (70, 30)\n",
      "[[-0.0572822  -0.04478326 -0.24355897 ... -0.04998172  0.16011594\n",
      "  -0.18396781]\n",
      " [ 0.19791098 -0.2439152  -0.04821352 ... -0.180215    0.05792432\n",
      "   0.09601128]\n",
      " [ 0.06357272  0.14619154 -0.08151475 ...  0.18793428 -0.20890847\n",
      "   0.03867467]\n",
      " ...\n",
      " [ 0.11200663  0.10837794  0.03246728 ... -0.22998136  0.04627914\n",
      "  -0.13057277]\n",
      " [ 0.0914312  -0.17946884  0.0575766  ...  0.08076323 -0.00938431\n",
      "  -0.06699113]\n",
      " [-0.20021287  0.09238353  0.17030899 ...  0.11290384  0.10659574\n",
      "  -0.13206972]]\n",
      "  - Pesos 1: (30,)\n",
      "[ 3.9804978e-03  1.6351128e-03 -6.6269291e-05  1.1049142e-03\n",
      "  2.3693782e-03 -6.3598814e-04  7.4678725e-03  4.9212086e-04\n",
      " -2.0206594e-03  7.4533089e-03 -5.7992764e-04 -1.9817255e-04\n",
      "  2.0095014e-03 -6.6472413e-03 -2.7175224e-04 -1.6249201e-03\n",
      "  8.6805079e-04  2.4150636e-03  1.2941159e-02  2.1029357e-02\n",
      " -9.0312125e-04  1.6099617e-05 -7.3618195e-03  7.1462378e-04\n",
      " -4.3694889e-03  1.4708253e-03 -2.5241598e-04 -6.8017413e-05\n",
      " -7.5738505e-04 -1.7159791e-03]\n",
      "\n",
      "ğŸ”¹ Capa 6: dense_71 (Dense)\n",
      "  - Pesos 0: (30, 70)\n",
      "[[ 0.02925821 -0.21657938 -0.21905068 ... -0.06048652  0.06241437\n",
      "  -0.02625688]\n",
      " [ 0.06150954  0.00580834  0.22095656 ...  0.03280517 -0.18537982\n",
      "   0.1785157 ]\n",
      " [ 0.06511502  0.15469639 -0.10700864 ...  0.17404556 -0.13913742\n",
      "   0.22664294]\n",
      " ...\n",
      " [ 0.17425083  0.18171981  0.18206815 ...  0.20272048 -0.16971257\n",
      "  -0.09075041]\n",
      " [-0.25995818  0.06066614  0.13987076 ... -0.22323306 -0.23532976\n",
      "   0.03967312]\n",
      " [-0.07088081  0.06925678  0.20352781 ... -0.19793895  0.17911227\n",
      "  -0.03821677]]\n",
      "  - Pesos 1: (70,)\n",
      "[ 0.01420351  0.00208704 -0.00178142  0.00061722  0.00209306  0.00095346\n",
      "  0.0021252   0.00454157  0.0064567   0.00187016 -0.00109073  0.00167469\n",
      "  0.0016927  -0.00261632  0.00708979 -0.00346936 -0.0007635   0.00204552\n",
      " -0.00429573 -0.0007114   0.00511519 -0.00095617  0.00423976  0.01076115\n",
      " -0.00276729 -0.00258013  0.00273939  0.0023027  -0.01077158 -0.00108897\n",
      " -0.00144289 -0.00017126  0.00065975 -0.00241797 -0.00179048 -0.00063572\n",
      " -0.02016701 -0.00244249  0.00056144  0.00376078 -0.00189416  0.00310166\n",
      " -0.003387   -0.00274001  0.001203   -0.00314045  0.00264413 -0.00987351\n",
      " -0.00133661 -0.00131582 -0.00096668  0.0041019  -0.00021546  0.00274977\n",
      " -0.00065063  0.01191158  0.00544141  0.0018357   0.00280889 -0.0082397\n",
      " -0.00867153 -0.00093597  0.00031435  0.00162817  0.00013849 -0.00275696\n",
      " -0.00117544 -0.00236827  0.00032207  0.00506   ]\n",
      "\n",
      "ğŸ”¹ Capa 7: dense_72 (Dense)\n",
      "  - Pesos 0: (70, 70)\n",
      "[[ 0.14263618  0.04633788  0.12742923 ...  0.04190784 -0.09957184\n",
      "  -0.09983855]\n",
      " [ 0.11279597 -0.16477989 -0.09085345 ... -0.17105582 -0.15424669\n",
      "   0.06371266]\n",
      " [-0.05484029  0.06130867 -0.04282324 ... -0.06527739  0.09396312\n",
      "   0.15794408]\n",
      " ...\n",
      " [ 0.0302594  -0.12523708  0.04760653 ...  0.04238617  0.02891629\n",
      "   0.13377264]\n",
      " [-0.19516663  0.14063336 -0.12267358 ...  0.16304529 -0.10125075\n",
      "   0.16368723]\n",
      " [-0.15523086  0.19224386  0.04416298 ... -0.06552156 -0.10033971\n",
      "  -0.05197401]]\n",
      "  - Pesos 1: (70,)\n",
      "[-0.00051597  0.00477     0.01076919 -0.00269393  0.00239882  0.00332486\n",
      " -0.00377453 -0.00698879 -0.00895463 -0.00270485  0.00120399 -0.01044554\n",
      "  0.00453418 -0.00010901 -0.00355097  0.00187376  0.00112494 -0.00381862\n",
      " -0.00571527  0.00042936 -0.00080281  0.00140721  0.031514    0.00056845\n",
      "  0.00324485 -0.00052124 -0.0044281  -0.00212947 -0.0024969   0.00241625\n",
      "  0.00106984  0.00248603  0.00774493  0.00914011 -0.00658887 -0.00205804\n",
      "  0.00660224 -0.00187036 -0.00231655 -0.0002346   0.00239484  0.00111338\n",
      " -0.00210507 -0.0009127  -0.0019028   0.0021954  -0.00224824 -0.00073702\n",
      " -0.00287368 -0.00292457  0.00262824  0.00189266 -0.00070454  0.00263857\n",
      "  0.00259477 -0.00136987  0.00119798 -0.0031546   0.00213655 -0.00098024\n",
      " -0.00079346 -0.00152643 -0.00460598 -0.00021262 -0.00209319  0.0047548\n",
      " -0.00247032 -0.00354931  0.00740057 -0.00787834]\n",
      "\n",
      "ğŸ”¹ Capa 8: dense_73 (Dense)\n",
      "  - Pesos 0: (70, 30)\n",
      "[[-0.01499635  0.02576076  0.08102421 ... -0.00862523 -0.03549709\n",
      "  -0.1678079 ]\n",
      " [ 0.13892175  0.24650137  0.08317547 ...  0.23480566 -0.03405192\n",
      "   0.14688627]\n",
      " [ 0.19813168 -0.10347524 -0.07269574 ...  0.02590105  0.19465531\n",
      "  -0.13492845]\n",
      " ...\n",
      " [-0.00966195 -0.15968351  0.16845886 ... -0.23223951 -0.19861358\n",
      "  -0.13726184]\n",
      " [-0.1393497  -0.04089518  0.1508299  ... -0.16680402  0.15738577\n",
      "   0.1343412 ]\n",
      " [-0.05799662 -0.11248238 -0.17822681 ... -0.08017621  0.13870877\n",
      "  -0.07101724]]\n",
      "  - Pesos 1: (30,)\n",
      "[ 0.00160171 -0.0011744  -0.00955403 -0.0044128  -0.00524144 -0.00146118\n",
      " -0.00091272  0.00100836  0.00470012 -0.00262937  0.00183967 -0.00468721\n",
      "  0.00326239  0.00437855 -0.00309929  0.00022507 -0.00394417  0.00234318\n",
      "  0.00264716 -0.00404426  0.00356611 -0.0024908  -0.00429114  0.00244984\n",
      "  0.00197664 -0.0038123  -0.00280661  0.00329305  0.00354384  0.00253043]\n",
      "\n",
      "ğŸ”¹ Capa 9: dense_74 (Dense)\n",
      "  - Pesos 0: (30, 70)\n",
      "[[ 0.23377998 -0.1612903   0.12929606 ...  0.00856989  0.05056198\n",
      "  -0.00810315]\n",
      " [-0.10707744 -0.02734374 -0.04569679 ...  0.17261277  0.16667317\n",
      "   0.17172296]\n",
      " [-0.11084775  0.06884986  0.20373584 ...  0.13583188  0.02644454\n",
      "   0.16387236]\n",
      " ...\n",
      " [ 0.01513486 -0.14105809  0.03703817 ...  0.12949428 -0.06482385\n",
      "  -0.03654363]\n",
      " [ 0.04056544 -0.03648943  0.20415087 ...  0.03432176 -0.2167589\n",
      "   0.06786938]\n",
      " [ 0.16545506  0.03474021 -0.17935857 ... -0.22849779  0.03064802\n",
      "  -0.11086825]]\n",
      "  - Pesos 1: (70,)\n",
      "[ 0.00298763  0.00379388  0.0047887  -0.00177841  0.00044668  0.00258476\n",
      "  0.00329952 -0.00297026  0.00325193  0.0022754  -0.0044637  -0.00557331\n",
      "  0.00335169  0.00339202  0.00303375  0.00274497 -0.00234725  0.00068215\n",
      "  0.00325838  0.00912907 -0.00255536 -0.0023239   0.00721413  0.00333376\n",
      "  0.00182422  0.0040107  -0.00097991 -0.00303099 -0.0022462   0.00304939\n",
      " -0.00672587 -0.00299491 -0.00383233  0.00269747 -0.0014251   0.00440963\n",
      "  0.00260348 -0.00300197 -0.00889407 -0.00321892  0.00460117 -0.00238491\n",
      "  0.00266437  0.00198913  0.00255828  0.00299948  0.00020332  0.00229311\n",
      " -0.00423559  0.00199797 -0.00282534  0.00238958  0.00394783 -0.00329207\n",
      " -0.00282131 -0.00400997 -0.00305131  0.00126293  0.0027522  -0.00305967\n",
      " -0.0046631  -0.00212029 -0.00257733 -0.00626622 -0.00275599 -0.00256735\n",
      "  0.0016624   0.00066223 -0.00335352  0.00206749]\n",
      "\n",
      "ğŸ”¹ Capa 10: dense_75 (Dense)\n",
      "  - Pesos 0: (70, 20)\n",
      "[[ 0.07957371 -0.11157481  0.02538999 ...  0.07533664  0.17664471\n",
      "  -0.10251479]\n",
      " [ 0.12012471 -0.04286312  0.19270189 ... -0.07671645 -0.08182049\n",
      "   0.02923805]\n",
      " [ 0.21222256  0.0423151  -0.24557877 ... -0.01442664 -0.24386086\n",
      "   0.03670026]\n",
      " ...\n",
      " [-0.16340668 -0.14862154  0.00759646 ...  0.01090204  0.05172972\n",
      "   0.21722102]\n",
      " [ 0.0394811   0.24057852 -0.24431168 ... -0.01369335  0.27613163\n",
      "  -0.04670892]\n",
      " [ 0.14446059  0.05546029 -0.01390059 ... -0.05384252 -0.240457\n",
      "  -0.04184653]]\n",
      "  - Pesos 1: (20,)\n",
      "[ 3.8565630e-03 -3.0948329e-03  2.9936063e-03  2.4972560e-03\n",
      " -3.3670384e-03 -2.6253117e-03 -3.1749052e-03  1.9308863e-03\n",
      " -5.6237984e-03 -4.8313076e-03  3.0526693e-03 -2.9992987e-03\n",
      "  3.0814670e-03 -1.5648831e-02 -3.4845502e-03 -3.3102110e-03\n",
      " -3.9584697e-03  8.6935019e-05  3.6305906e-03 -3.1711233e-03]\n",
      "\n",
      "ğŸ”¹ Capa 11: dense_76 (Dense)\n",
      "  - Pesos 0: (20, 60)\n",
      "[[-0.23947988 -0.03296357 -0.21436642 ...  0.25065282  0.15965828\n",
      "   0.16486363]\n",
      " [ 0.06347056  0.01391031 -0.07585187 ...  0.22151802  0.12770408\n",
      "  -0.25240824]\n",
      " [ 0.12046175  0.02008232  0.22935215 ... -0.17085834  0.02744587\n",
      "   0.24371448]\n",
      " ...\n",
      " [-0.18407954  0.09364296  0.15525658 ...  0.03802914  0.02088518\n",
      "   0.00541358]\n",
      " [-0.01982836 -0.05325431 -0.18741211 ...  0.01598323 -0.18265367\n",
      "   0.0203526 ]\n",
      " [ 0.08292952  0.12209441 -0.256535   ...  0.12117828  0.22912931\n",
      "  -0.23350193]]\n",
      "  - Pesos 1: (60,)\n",
      "[ 0.00420171 -0.00354312  0.00399531  0.00440894  0.0025176  -0.00400685\n",
      " -0.00410902  0.00356304 -0.00419707  0.00384356  0.00397584 -0.00300009\n",
      "  0.00424652  0.00442437  0.00436973  0.00402188 -0.00416056  0.00340239\n",
      " -0.00427072 -0.00390653  0.00432575  0.00406683  0.00316564  0.00422287\n",
      "  0.00367838  0.00447909  0.00396014 -0.00410162 -0.00289084 -0.00314311\n",
      "  0.00406994 -0.00429361 -0.00424202 -0.00416433 -0.00349164  0.00408575\n",
      "  0.00419462  0.00396951 -0.00390121  0.00445297  0.00384048 -0.00403782\n",
      " -0.00419545  0.00343637  0.0043034   0.00305702 -0.00439897  0.00409744\n",
      " -0.00398466 -0.00345987  0.00435327  0.00379386 -0.00413777  0.00379393\n",
      "  0.00395873  0.00451272  0.00254866 -0.00399978  0.00449015  0.00345293]\n",
      "\n",
      "ğŸ”¹ Capa 12: dense_77 (Dense)\n",
      "  - Pesos 0: (60, 1)\n",
      "[[ 0.30339408]\n",
      " [-0.25767502]\n",
      " [ 0.22851272]\n",
      " [ 0.2996451 ]\n",
      " [ 0.30578646]\n",
      " [-0.15560094]\n",
      " [-0.20279178]\n",
      " [ 0.32001123]\n",
      " [-0.2670629 ]\n",
      " [ 0.01613952]\n",
      " [ 0.24431308]\n",
      " [-0.28504717]\n",
      " [ 0.2851922 ]\n",
      " [ 0.16749787]\n",
      " [ 0.12982461]\n",
      " [ 0.09436976]\n",
      " [-0.2157519 ]\n",
      " [ 0.2340564 ]\n",
      " [-0.19801776]\n",
      " [-0.20145048]\n",
      " [ 0.16525409]\n",
      " [ 0.06409822]\n",
      " [ 0.24772511]\n",
      " [ 0.10023061]\n",
      " [ 0.24897824]\n",
      " [ 0.26023105]\n",
      " [ 0.2411335 ]\n",
      " [-0.14561322]\n",
      " [-0.00183977]\n",
      " [-0.15970375]\n",
      " [ 0.2827731 ]\n",
      " [-0.18880963]\n",
      " [-0.14754646]\n",
      " [-0.08276491]\n",
      " [-0.07846962]\n",
      " [ 0.06988283]\n",
      " [ 0.17882833]\n",
      " [ 0.21063106]\n",
      " [-0.1436294 ]\n",
      " [ 0.3004852 ]\n",
      " [ 0.1135246 ]\n",
      " [-0.07758784]\n",
      " [-0.0350162 ]\n",
      " [ 0.02996452]\n",
      " [ 0.20162532]\n",
      " [ 0.0462306 ]\n",
      " [-0.00905516]\n",
      " [ 0.29509282]\n",
      " [-0.07062191]\n",
      " [-0.30493617]\n",
      " [ 0.30347845]\n",
      " [ 0.10970571]\n",
      " [-0.20478685]\n",
      " [ 0.00717148]\n",
      " [ 0.3223682 ]\n",
      " [ 0.02030658]\n",
      " [ 0.25251126]\n",
      " [-0.1957959 ]\n",
      " [ 0.23706701]\n",
      " [ 0.09537455]]\n",
      "  - Pesos 1: (1,)\n",
      "[0.00420095]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the weights of the model after the pruning process\n",
    "inspect_model_weights(model_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4409e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.2497e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.3683e-04 - val_loss: 0.0140 - val_mae: 0.0140 - val_mse: 3.2911e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3082e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4451e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.3360e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3356e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.3354e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.7957e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3196e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.1822e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3015e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4474e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.3823e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.0994e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.2816e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.6262e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3143e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.3903e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3145e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.2362e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2727e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3095e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2660e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.9384e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2693e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.8052e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3211e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1659e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2518e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3534e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.2903e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 2.9136e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2722e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2127e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2431e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4481e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2630e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.5176e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2473e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.1969e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2492e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1082e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m953/953\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.2540e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1278e-04\n",
      "\u001b[1m4667/4667\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      "\u001b[1m7622/7622\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Configure Early Stopping for the pruned model (Fine-tuning phase)\n",
    "early_stopping_pruned = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',         # Metric to monitor (validation loss)\n",
    "    patience=15,                # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True   # Restore model weights from the best epoch\n",
    ")\n",
    "\n",
    "# Measure fine-tuning execution time\n",
    "start_time_pruned = time.time()\n",
    "\n",
    "# Re-train (fine-tune) the pruned model\n",
    "history_pruned = model_pruned.fit(\n",
    "    X_train_norm, \n",
    "    y_train_norm, \n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size, \n",
    "    validation_data=(X_val_norm, y_val_norm), \n",
    "    callbacks=[early_stopping_pruned]\n",
    ")\n",
    "\n",
    "# Capture end time for fine-tuning\n",
    "end_time_pruned = time.time()\n",
    "\n",
    "# Perform predictions on the test set using the pruned and fine-tuned model\n",
    "y_pred_pruned = model_pruned.predict(X_test_norm)\n",
    "# print(y_pred_pruned)\n",
    "\n",
    "# Perform predictions on the training set for bias analysis\n",
    "y_train_pred = model_pruned.predict(X_train_norm)\n",
    "# print(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo total de fine-tuning: 439.62 segundos\n"
     ]
    }
   ],
   "source": [
    "# Print the total fine-tuning execution time\n",
    "# print(f\"Total fine-tuning time: {(end_time_pruned - start_time_pruned):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error (MAPE): 1.0341%\n",
      "DesviaciÃ³n estÃ¡ndar del MAPE): 1.018%\n",
      "-----------------------------------\n",
      "Se ha usado la opcion FS para eliminar la capa oculta numero 4\n",
      "Mean Absolute Percentage Error (MAPE): 1.0341%\n",
      "Tiempo total de fine-tuning: 170.70 segundos\n",
      "Ã‰pocas utilizadas en el fine-tuning: 23\n"
     ]
    }
   ],
   "source": [
    "# --- Denormalization and Global MAPE Calculation (Pruned Model) ---\n",
    "original_data = pd.read_csv('dataset.csv')\n",
    "min_val = original_data['consumption'].min()\n",
    "max_val = original_data['consumption'].max()\n",
    "\n",
    "# Denormalize values (N x 24 Arrays)\n",
    "y_pred_pruned_denorm = y_pred_pruned * (max_val - min_val) + min_val\n",
    "y_test_denorm = y_test * (max_val - min_val) + min_val\n",
    "\n",
    "# Calculate MAPE with denormalized data\n",
    "mape_pruned = mean_absolute_percentage_error(y_test_denorm, y_pred_pruned_denorm) * 100\n",
    "\n",
    "# --- MAPE STANDARD DEVIATION CALCULATION ---\n",
    "\n",
    "# 1. Flatten arrays for point-by-point calculation\n",
    "y_true_flat = y_test_denorm.flatten()\n",
    "y_pred_flat = y_pred_pruned_denorm.flatten()\n",
    "\n",
    "# 2. Handle division by zero for APE calculation\n",
    "epsilon = np.finfo(np.float32).eps \n",
    "y_true_for_mape = np.copy(y_true_flat)\n",
    "y_true_for_mape[y_true_for_mape == 0] = epsilon\n",
    "\n",
    "# 3. Calculate Absolute Percentage Error (APE) for each data point\n",
    "absolute_percentage_errors = (np.abs(y_true_flat - y_pred_flat) / y_true_for_mape) * 100\n",
    "\n",
    "# 4. Calculate MAPE Standard Deviation\n",
    "std_dev_mape = np.std(absolute_percentage_errors) \n",
    "\n",
    "# --- Print Final Results ---\n",
    "\n",
    "print(\"-\" * 35)\n",
    "\n",
    "strategy_map = {\n",
    "    1: \"BS (Backward Strategy)\",\n",
    "    2: \"FS (Forward Strategy)\",\n",
    "    3: \"Standard Pruning\"\n",
    "}\n",
    "strategy_text = strategy_map.get(pruning_strategy, \"Unknown Option\")\n",
    "\n",
    "print(f\"Strategy used: {strategy_text}\")\n",
    "print(f\"Pruned hidden layer index: {target_hidden_layer}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape_pruned:.4f}%\")\n",
    "print(f\"MAPE Standard Deviation: {std_dev_mape:.3f}%\")\n",
    "print(f\"Total fine-tuning time: {(end_time_pruned - start_time_pruned):.2f} seconds\")\n",
    "\n",
    "# Get the actual number of epochs until Early Stopping triggered\n",
    "final_epochs = len(history_pruned.history['loss'])\n",
    "print(f\"Epochs used during fine-tuning: {final_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando evaluaciÃ³n de Standard Pruning en 5 capas ---\n",
      "------------------------------------------------------------\n",
      "\n",
      "[EXPERIMENTO] Poda de la capa oculta nÃºmero: 1 usando Standard\n",
      "Eliminando la capa oculta #1 con 60 neuronas.\n",
      "Nueva arquitectura (neuronas): [60, 60, 60, 60]\n",
      "\n",
      "--- Resumen del Modelo Reducido ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,140</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_37 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚        \u001b[38;5;34m10,140\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_38 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_39 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_40 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_41 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             â”‚         \u001b[38;5;34m1,464\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0344 - mae: 0.0344 - mse: 0.0041 - val_loss: 0.0243 - val_mae: 0.0243 - val_mse: 0.0016\n",
      "Epoch 2/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0230 - mae: 0.0230 - mse: 0.0014 - val_loss: 0.0220 - val_mae: 0.0220 - val_mse: 0.0013\n",
      "Epoch 3/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0212 - mae: 0.0212 - mse: 0.0012 - val_loss: 0.0253 - val_mae: 0.0253 - val_mse: 0.0013\n",
      "Epoch 4/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0200 - mae: 0.0200 - mse: 9.8956e-04 - val_loss: 0.0197 - val_mae: 0.0197 - val_mse: 9.3491e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0191 - mae: 0.0191 - mse: 8.7058e-04 - val_loss: 0.0180 - val_mae: 0.0180 - val_mse: 7.8349e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0185 - mae: 0.0185 - mse: 7.9559e-04 - val_loss: 0.0177 - val_mae: 0.0177 - val_mse: 7.3719e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0180 - mae: 0.0180 - mse: 7.3871e-04 - val_loss: 0.0174 - val_mae: 0.0174 - val_mse: 7.0620e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0177 - mae: 0.0177 - mse: 7.0437e-04 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 6.9772e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0172 - mae: 0.0172 - mse: 6.6185e-04 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 6.1590e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0170 - mae: 0.0170 - mse: 6.3652e-04 - val_loss: 0.0161 - val_mae: 0.0161 - val_mse: 5.8855e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0167 - mae: 0.0167 - mse: 6.1337e-04 - val_loss: 0.0168 - val_mae: 0.0168 - val_mse: 5.9763e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0165 - mae: 0.0165 - mse: 5.9448e-04 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 5.8023e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0162 - mae: 0.0162 - mse: 5.7074e-04 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 5.6763e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0160 - mse: 5.5354e-04 - val_loss: 0.0157 - val_mae: 0.0157 - val_mse: 5.2723e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0159 - mae: 0.0159 - mse: 5.4076e-04 - val_loss: 0.0157 - val_mae: 0.0157 - val_mse: 5.3003e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0157 - mae: 0.0157 - mse: 5.2393e-04 - val_loss: 0.0149 - val_mae: 0.0149 - val_mse: 4.8483e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0155 - mae: 0.0155 - mse: 5.1051e-04 - val_loss: 0.0161 - val_mae: 0.0161 - val_mse: 5.3484e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0155 - mae: 0.0155 - mse: 5.0537e-04 - val_loss: 0.0182 - val_mae: 0.0182 - val_mse: 6.6711e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0151 - mae: 0.0151 - mse: 4.8346e-04 - val_loss: 0.0147 - val_mae: 0.0147 - val_mse: 4.5791e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0151 - mae: 0.0151 - mse: 4.7862e-04 - val_loss: 0.0150 - val_mae: 0.0150 - val_mse: 4.7686e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0150 - mae: 0.0150 - mse: 4.6907e-04 - val_loss: 0.0148 - val_mae: 0.0148 - val_mse: 4.5578e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0148 - mae: 0.0148 - mse: 4.5743e-04 - val_loss: 0.0146 - val_mae: 0.0146 - val_mse: 4.4384e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0147 - mae: 0.0147 - mse: 4.4598e-04 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 4.4317e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0146 - mse: 4.3977e-04 - val_loss: 0.0141 - val_mae: 0.0141 - val_mse: 4.1537e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0145 - mae: 0.0145 - mse: 4.3233e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 4.0049e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0143 - mse: 4.2084e-04 - val_loss: 0.0175 - val_mae: 0.0175 - val_mse: 5.5310e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0143 - mse: 4.1971e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 4.0042e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0141 - mse: 4.0928e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.8576e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0141 - mse: 4.0681e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.8202e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0140 - mse: 3.9990e-04 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 3.9210e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.9535e-04 - val_loss: 0.0140 - val_mae: 0.0140 - val_mse: 4.1488e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.8862e-04 - val_loss: 0.0140 - val_mae: 0.0140 - val_mse: 3.9121e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.8660e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.7065e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0137 - mae: 0.0137 - mse: 3.8262e-04 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 3.7390e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0136 - mse: 3.7769e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 3.4632e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0136 - mse: 3.7355e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.6190e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.6998e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.6513e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0134 - mse: 3.6331e-04 - val_loss: 0.0141 - val_mae: 0.0141 - val_mse: 3.8844e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.5995e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.6224e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.5896e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.4182e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5439e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.5632e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5214e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.2908e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.4778e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.5267e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.4534e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.3368e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.4222e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.4478e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.4106e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.2355e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.3577e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.1430e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.3332e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.6194e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.2951e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.4059e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.2922e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.1072e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2549e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.6415e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2307e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.3569e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2187e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.4039e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1900e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.9988e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1528e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.2227e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1429e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0434e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.1104e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.1340e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1103e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0550e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0753e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9698e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0811e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.9327e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0458e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8950e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9989e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9601e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9986e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.8374e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9857e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 3.0009e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9638e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.3249e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9608e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.8078e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9291e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8745e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9065e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7922e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9038e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.5045e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8917e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.8830e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.8997e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.8093e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8626e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7612e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8479e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.9063e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8268e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7482e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8109e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7362e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8076e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 3.0006e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8074e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 3.0306e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.7976e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.9471e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7715e-04 - val_loss: 0.0139 - val_mae: 0.0139 - val_mse: 3.5179e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7601e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6314e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7503e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 3.2589e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7410e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7180e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7206e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7292e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7068e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6668e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6890e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5601e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6934e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8814e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6662e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6583e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6550e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7716e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6526e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5519e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6453e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6407e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6408e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.6667e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6292e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5577e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6114e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5943e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6023e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5835e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6029e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.7822e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5819e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.7476e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5872e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6691e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5673e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.6319e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5612e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4890e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5589e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4662e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5301e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4729e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5419e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6154e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5158e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5881e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5239e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.5736e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5144e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4479e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.4952e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4620e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4878e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4639e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4880e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5179e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4758e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7041e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4760e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4605e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4544e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5872e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4657e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3581e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4612e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3692e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4389e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5159e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4373e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.7168e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4300e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.7924e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4186e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4903e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4162e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4517e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4193e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4668e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.3994e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4801e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3922e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.5110e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.3975e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3332e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3887e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4080e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3863e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3577e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3723e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.4811e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3804e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3426e-04\n",
      "Epoch 127/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3606e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.7038e-04\n",
      "Epoch 128/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3764e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3043e-04\n",
      "Epoch 129/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3566e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3501e-04\n",
      "Epoch 130/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3432e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4177e-04\n",
      "Epoch 131/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3512e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3098e-04\n",
      "Epoch 132/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3497e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2787e-04\n",
      "Epoch 133/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3402e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.4009e-04\n",
      "Epoch 134/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3367e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4549e-04\n",
      "Epoch 135/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3275e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4395e-04\n",
      "Epoch 136/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3258e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2788e-04\n",
      "Epoch 137/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3301e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2945e-04\n",
      "Epoch 138/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3255e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2796e-04\n",
      "Epoch 139/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3144e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.6518e-04\n",
      "Epoch 140/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3083e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.2984e-04\n",
      "Epoch 141/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3075e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2376e-04\n",
      "Epoch 142/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2927e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3706e-04\n",
      "Epoch 143/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3047e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2960e-04\n",
      "Epoch 144/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2952e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2231e-04\n",
      "Epoch 145/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2791e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2860e-04\n",
      "Epoch 146/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2866e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.4782e-04\n",
      "Epoch 147/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2799e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2178e-04\n",
      "Epoch 148/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2763e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.3936e-04\n",
      "Epoch 149/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2726e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2158e-04\n",
      "Epoch 150/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2712e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4112e-04\n",
      "Epoch 151/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2789e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6917e-04\n",
      "Epoch 152/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2578e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.3948e-04\n",
      "Epoch 153/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2653e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2275e-04\n",
      "Epoch 154/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2569e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1692e-04\n",
      "Epoch 155/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2551e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 2.8628e-04\n",
      "Epoch 156/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2544e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3228e-04\n",
      "Epoch 157/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2537e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2217e-04\n",
      "Epoch 158/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2499e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2381e-04\n",
      "Epoch 159/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2428e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2782e-04\n",
      "Epoch 160/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2419e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1796e-04\n",
      "Epoch 161/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2340e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2457e-04\n",
      "Epoch 162/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2416e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1911e-04\n",
      "Epoch 163/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2292e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.5302e-04\n",
      "Epoch 164/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2288e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2701e-04\n",
      "Epoch 165/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2255e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.3988e-04\n",
      "Epoch 166/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2230e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2554e-04\n",
      "Epoch 167/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2230e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2628e-04\n",
      "Epoch 168/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2176e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3170e-04\n",
      "Epoch 169/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2166e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2201e-04\n",
      "\u001b[1m9334/9334\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 810us/step\n",
      "-----------------------------------\n",
      "Se ha usado la opcion Standard para eliminar la capa oculta numero 1\n",
      "Mean Absolute Percentage Error (MAPE): 1.0472%\n",
      "DesviaciÃ³n estÃ¡ndar del MAPE: 1.083%\n",
      "Tiempo total de fine-tuning: 1091.39 segundos\n",
      "Ã‰pocas utilizadas en el fine-tuning: 169\n",
      "------------------------------------------------------------\n",
      "\n",
      "[EXPERIMENTO] Poda de la capa oculta nÃºmero: 2 usando Standard\n",
      "Eliminando la capa oculta #2 con 60 neuronas.\n",
      "Nueva arquitectura (neuronas): [60, 60, 60, 60]\n",
      "\n",
      "--- Resumen del Modelo Reducido ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,140</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_15 (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_42 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚        \u001b[38;5;34m10,140\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_43 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_44 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_45 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_46 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             â”‚         \u001b[38;5;34m1,464\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.0340 - mse: 0.0038 - val_loss: 0.0233 - val_mae: 0.0233 - val_mse: 0.0016\n",
      "Epoch 2/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0228 - mae: 0.0228 - mse: 0.0014 - val_loss: 0.0208 - val_mae: 0.0208 - val_mse: 0.0012\n",
      "Epoch 3/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0209 - mae: 0.0209 - mse: 0.0012 - val_loss: 0.0195 - val_mae: 0.0195 - val_mse: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0199 - mae: 0.0199 - mse: 0.0010 - val_loss: 0.0186 - val_mae: 0.0186 - val_mse: 8.9151e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0190 - mae: 0.0190 - mse: 8.7610e-04 - val_loss: 0.0183 - val_mae: 0.0183 - val_mse: 8.0868e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0185 - mae: 0.0185 - mse: 7.9617e-04 - val_loss: 0.0179 - val_mae: 0.0179 - val_mse: 7.6942e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0179 - mae: 0.0179 - mse: 7.2980e-04 - val_loss: 0.0175 - val_mae: 0.0175 - val_mse: 7.0184e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0175 - mae: 0.0175 - mse: 6.8921e-04 - val_loss: 0.0174 - val_mae: 0.0174 - val_mse: 6.7793e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0173 - mae: 0.0173 - mse: 6.6597e-04 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 6.3508e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0169 - mae: 0.0169 - mse: 6.3023e-04 - val_loss: 0.0169 - val_mae: 0.0169 - val_mse: 6.3384e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0168 - mae: 0.0168 - mse: 6.1411e-04 - val_loss: 0.0171 - val_mae: 0.0171 - val_mse: 6.1509e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.0165 - mse: 5.8951e-04 - val_loss: 0.0178 - val_mae: 0.0178 - val_mse: 6.9533e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0163 - mae: 0.0163 - mse: 5.7429e-04 - val_loss: 0.0164 - val_mae: 0.0164 - val_mse: 5.7912e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0160 - mae: 0.0160 - mse: 5.5468e-04 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 5.4110e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0159 - mae: 0.0159 - mse: 5.4029e-04 - val_loss: 0.0158 - val_mae: 0.0158 - val_mse: 5.3016e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0157 - mae: 0.0157 - mse: 5.2695e-04 - val_loss: 0.0152 - val_mae: 0.0152 - val_mse: 4.9399e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0155 - mae: 0.0155 - mse: 5.1421e-04 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 5.8685e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0153 - mae: 0.0153 - mse: 4.9946e-04 - val_loss: 0.0157 - val_mae: 0.0157 - val_mse: 5.0816e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0153 - mae: 0.0153 - mse: 4.9349e-04 - val_loss: 0.0155 - val_mae: 0.0155 - val_mse: 5.2155e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0152 - mae: 0.0152 - mse: 4.8569e-04 - val_loss: 0.0147 - val_mae: 0.0147 - val_mse: 4.5810e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0150 - mae: 0.0150 - mse: 4.7563e-04 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 4.5773e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0148 - mae: 0.0148 - mse: 4.6115e-04 - val_loss: 0.0148 - val_mae: 0.0148 - val_mse: 4.5903e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0147 - mae: 0.0147 - mse: 4.5430e-04 - val_loss: 0.0157 - val_mae: 0.0157 - val_mse: 5.1816e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0147 - mae: 0.0147 - mse: 4.5047e-04 - val_loss: 0.0169 - val_mae: 0.0169 - val_mse: 5.4033e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0145 - mae: 0.0145 - mse: 4.3981e-04 - val_loss: 0.0150 - val_mae: 0.0150 - val_mse: 4.7849e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0144 - mae: 0.0144 - mse: 4.3516e-04 - val_loss: 0.0159 - val_mae: 0.0159 - val_mse: 4.8368e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0144 - mae: 0.0144 - mse: 4.2827e-04 - val_loss: 0.0142 - val_mae: 0.0142 - val_mse: 4.1910e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0142 - mae: 0.0142 - mse: 4.1896e-04 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 3.9904e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0141 - mse: 4.1484e-04 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 4.1582e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0140 - mse: 4.0722e-04 - val_loss: 0.0151 - val_mae: 0.0151 - val_mse: 4.6217e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0141 - mse: 4.0748e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 4.2680e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.9887e-04 - val_loss: 0.0141 - val_mae: 0.0141 - val_mse: 4.2464e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.9216e-04 - val_loss: 0.0139 - val_mae: 0.0139 - val_mse: 3.8698e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.9099e-04 - val_loss: 0.0150 - val_mae: 0.0150 - val_mse: 4.4094e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0137 - mae: 0.0137 - mse: 3.8698e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.7135e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0136 - mse: 3.8106e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.6329e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.7513e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.8154e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.7336e-04 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 4.3802e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.7188e-04 - val_loss: 0.0139 - val_mae: 0.0139 - val_mse: 3.8653e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0134 - mse: 3.6504e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.5922e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.6041e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.5408e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.6070e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.6390e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5448e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.5693e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5377e-04 - val_loss: 0.0136 - val_mae: 0.0136 - val_mse: 3.8463e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5179e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.2674e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.4669e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.3754e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.4350e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.3549e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.3965e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.4472e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.4091e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.2091e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.3242e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.5028e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.3527e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 3.2923e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.3114e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.4978e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2763e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1770e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2676e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.5547e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2599e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.2900e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.2221e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.1592e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.2136e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1220e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1913e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.2873e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1804e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1684e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1608e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 3.3956e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.1367e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0825e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.1201e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0711e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.1093e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.9940e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0800e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.2720e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0630e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.9324e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0658e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.0771e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - mse: 3.0185e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 3.0080e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 3.0267e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.9453e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 3.0024e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8905e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9946e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.8718e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9589e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.2349e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9494e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.8146e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9356e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.0981e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.9196e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0672e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.9032e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8648e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8880e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7720e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8642e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.1561e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8433e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.8737e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8333e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7566e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.8083e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.8215e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.8027e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 2.9913e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7740e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7171e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7538e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7449e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7413e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6761e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7216e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7889e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6977e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.2500e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6826e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.7928e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6567e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5454e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6436e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5747e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6274e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6045e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6232e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.9625e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6240e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4909e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5897e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.6450e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5927e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.6714e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5739e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5178e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5665e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.6435e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5523e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7077e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5569e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7867e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5550e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.7572e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5327e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4804e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5247e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5612e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5106e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4677e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5070e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6126e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4880e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5035e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4966e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4986e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4761e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5121e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4739e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3979e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4633e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3889e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4636e-04 - val_loss: 0.0140 - val_mae: 0.0140 - val_mse: 3.3327e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4542e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3711e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4548e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3451e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4461e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4824e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4265e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4405e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4255e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7940e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4121e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.4875e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4166e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.5706e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4059e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3605e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4028e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3915e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3907e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4502e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3893e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3533e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3817e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3944e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3803e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3402e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3770e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3499e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3678e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3526e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3600e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3362e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3670e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4558e-04\n",
      "\u001b[1m9334/9334\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 923us/step\n",
      "-----------------------------------\n",
      "Se ha usado la opcion Standard para eliminar la capa oculta numero 2\n",
      "Mean Absolute Percentage Error (MAPE): 1.0960%\n",
      "DesviaciÃ³n estÃ¡ndar del MAPE: 1.125%\n",
      "Tiempo total de fine-tuning: 822.97 segundos\n",
      "Ã‰pocas utilizadas en el fine-tuning: 126\n",
      "------------------------------------------------------------\n",
      "\n",
      "[EXPERIMENTO] Poda de la capa oculta nÃºmero: 3 usando Standard\n",
      "Eliminando la capa oculta #3 con 60 neuronas.\n",
      "Nueva arquitectura (neuronas): [60, 60, 60, 60]\n",
      "\n",
      "--- Resumen del Modelo Reducido ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,140</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_16 (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_47 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚        \u001b[38;5;34m10,140\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_48 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_49 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_50 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_51 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             â”‚         \u001b[38;5;34m1,464\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0323 - mae: 0.0323 - mse: 0.0035 - val_loss: 0.0254 - val_mae: 0.0254 - val_mse: 0.0016\n",
      "Epoch 2/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0223 - mae: 0.0223 - mse: 0.0013 - val_loss: 0.0206 - val_mae: 0.0206 - val_mse: 0.0011\n",
      "Epoch 3/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0206 - mae: 0.0206 - mse: 0.0011 - val_loss: 0.0208 - val_mae: 0.0208 - val_mse: 9.8200e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0196 - mae: 0.0196 - mse: 9.1094e-04 - val_loss: 0.0189 - val_mae: 0.0189 - val_mse: 8.5252e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0188 - mae: 0.0188 - mse: 8.1983e-04 - val_loss: 0.0178 - val_mae: 0.0178 - val_mse: 7.6655e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0182 - mae: 0.0182 - mse: 7.5855e-04 - val_loss: 0.0173 - val_mae: 0.0173 - val_mse: 6.8309e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0179 - mae: 0.0179 - mse: 7.1324e-04 - val_loss: 0.0171 - val_mae: 0.0171 - val_mse: 6.5410e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0176 - mae: 0.0176 - mse: 6.8168e-04 - val_loss: 0.0165 - val_mae: 0.0165 - val_mse: 6.0950e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0172 - mae: 0.0172 - mse: 6.4266e-04 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 6.0031e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0170 - mae: 0.0170 - mse: 6.2148e-04 - val_loss: 0.0167 - val_mae: 0.0167 - val_mse: 5.9555e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0167 - mae: 0.0167 - mse: 5.9989e-04 - val_loss: 0.0160 - val_mae: 0.0160 - val_mse: 5.4864e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0165 - mae: 0.0165 - mse: 5.7742e-04 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 5.6555e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0163 - mae: 0.0163 - mse: 5.6016e-04 - val_loss: 0.0153 - val_mae: 0.0153 - val_mse: 5.1819e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0160 - mse: 5.4242e-04 - val_loss: 0.0156 - val_mae: 0.0156 - val_mse: 5.1823e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0159 - mae: 0.0159 - mse: 5.3426e-04 - val_loss: 0.0151 - val_mae: 0.0151 - val_mse: 4.9406e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0158 - mae: 0.0158 - mse: 5.2324e-04 - val_loss: 0.0162 - val_mae: 0.0162 - val_mse: 5.3563e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0155 - mse: 5.0507e-04 - val_loss: 0.0148 - val_mae: 0.0148 - val_mse: 4.6817e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0154 - mae: 0.0154 - mse: 4.9706e-04 - val_loss: 0.0162 - val_mae: 0.0162 - val_mse: 5.1040e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0153 - mae: 0.0153 - mse: 4.8624e-04 - val_loss: 0.0164 - val_mae: 0.0164 - val_mse: 5.2923e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0151 - mae: 0.0151 - mse: 4.7814e-04 - val_loss: 0.0146 - val_mae: 0.0146 - val_mse: 4.5176e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0149 - mae: 0.0149 - mse: 4.6589e-04 - val_loss: 0.0158 - val_mae: 0.0158 - val_mse: 4.8373e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0149 - mae: 0.0149 - mse: 4.6321e-04 - val_loss: 0.0176 - val_mae: 0.0176 - val_mse: 6.3698e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0147 - mae: 0.0147 - mse: 4.5206e-04 - val_loss: 0.0152 - val_mae: 0.0152 - val_mse: 4.9272e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0147 - mae: 0.0147 - mse: 4.4959e-04 - val_loss: 0.0146 - val_mae: 0.0146 - val_mse: 4.4729e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0145 - mae: 0.0145 - mse: 4.3956e-04 - val_loss: 0.0152 - val_mae: 0.0152 - val_mse: 4.5573e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0145 - mae: 0.0145 - mse: 4.3822e-04 - val_loss: 0.0148 - val_mae: 0.0148 - val_mse: 4.3494e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0144 - mae: 0.0144 - mse: 4.2736e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 4.0378e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0143 - mse: 4.2202e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 4.1770e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0142 - mae: 0.0142 - mse: 4.1949e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.9851e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0141 - mse: 4.1272e-04 - val_loss: 0.0139 - val_mae: 0.0139 - val_mse: 4.0734e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0142 - mae: 0.0142 - mse: 4.1281e-04 - val_loss: 0.0147 - val_mae: 0.0147 - val_mse: 4.4738e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0140 - mse: 4.0320e-04 - val_loss: 0.0151 - val_mae: 0.0151 - val_mse: 4.3219e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.9756e-04 - val_loss: 0.0142 - val_mae: 0.0142 - val_mse: 4.0498e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.9702e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.7391e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.9342e-04 - val_loss: 0.0140 - val_mae: 0.0140 - val_mse: 4.0064e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0137 - mae: 0.0137 - mse: 3.8616e-04 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 3.8544e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0137 - mae: 0.0137 - mse: 3.8731e-04 - val_loss: 0.0159 - val_mae: 0.0159 - val_mse: 4.7146e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0136 - mse: 3.7992e-04 - val_loss: 0.0136 - val_mae: 0.0136 - val_mse: 3.9939e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0136 - mse: 3.7782e-04 - val_loss: 0.0143 - val_mae: 0.0143 - val_mse: 3.9715e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.7177e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 3.4757e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0134 - mse: 3.7037e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.5619e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.6417e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.5334e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.6244e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.3973e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.6181e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.4924e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5765e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.3756e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5357e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.6098e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5355e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.4680e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.4658e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.4455e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.4551e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.2187e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.4176e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.3627e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.4193e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.2185e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.3548e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.2808e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.3199e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.3677e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.3177e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 3.1012e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2561e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.2012e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2477e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.1195e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.2261e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1289e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1940e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.2289e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1823e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 3.0474e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1376e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.1117e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.1140e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.1853e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0865e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.3300e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0769e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.4634e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0555e-04 - val_loss: 0.0147 - val_mae: 0.0147 - val_mse: 3.8876e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0277e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1017e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0116e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.9422e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9924e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9375e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9776e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.1609e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9627e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.8130e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.9108e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.0775e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.9032e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.3412e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8955e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9156e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8666e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.9358e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8594e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7574e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8212e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8101e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.8086e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 2.9833e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.8068e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.9097e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7968e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7621e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7669e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6784e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7585e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8567e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7496e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7290e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7233e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6217e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7146e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6894e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7101e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6564e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6897e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6254e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6981e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7728e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6562e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7933e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6580e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6044e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6441e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6528e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6574e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.8474e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6320e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6255e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6226e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6043e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6123e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5699e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6203e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5425e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5968e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7696e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5997e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6111e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5849e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.5224e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5917e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7382e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5606e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5643e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5644e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.5797e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5476e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4730e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5457e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5176e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5571e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 2.8538e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5417e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5416e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5483e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4458e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.5179e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4368e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5276e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3945e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5112e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4724e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4934e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4534e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.5077e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4712e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4892e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6305e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4915e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3856e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4667e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6012e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4751e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4375e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4688e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4033e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4605e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4511e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4547e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4502e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4587e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.5773e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4477e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4247e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4244e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.4054e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4377e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3651e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4254e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3256e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4342e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3827e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4303e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3676e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4056e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3915e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4094e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.4971e-04\n",
      "Epoch 127/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4131e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3887e-04\n",
      "Epoch 128/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3932e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3828e-04\n",
      "Epoch 129/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3930e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3126e-04\n",
      "Epoch 130/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3999e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.5638e-04\n",
      "Epoch 131/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3830e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4705e-04\n",
      "Epoch 132/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3903e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4266e-04\n",
      "Epoch 133/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3712e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3342e-04\n",
      "Epoch 134/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3661e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3318e-04\n",
      "Epoch 135/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3702e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4278e-04\n",
      "Epoch 136/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3692e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3062e-04\n",
      "Epoch 137/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3594e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3820e-04\n",
      "Epoch 138/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3688e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4299e-04\n",
      "Epoch 139/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3406e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2826e-04\n",
      "Epoch 140/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3558e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3676e-04\n",
      "Epoch 141/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3360e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2923e-04\n",
      "Epoch 142/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3464e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3790e-04\n",
      "Epoch 143/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3340e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4252e-04\n",
      "Epoch 144/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3440e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3311e-04\n",
      "Epoch 145/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3319e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5624e-04\n",
      "Epoch 146/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3240e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3226e-04\n",
      "Epoch 147/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3318e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3212e-04\n",
      "Epoch 148/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3146e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2386e-04\n",
      "Epoch 149/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3188e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.0805e-04\n",
      "Epoch 150/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3105e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6638e-04\n",
      "Epoch 151/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3116e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2812e-04\n",
      "Epoch 152/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3008e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3989e-04\n",
      "Epoch 153/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.3202e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.5574e-04\n",
      "Epoch 154/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2872e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3516e-04\n",
      "Epoch 155/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2897e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3370e-04\n",
      "Epoch 156/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2877e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2980e-04\n",
      "Epoch 157/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2843e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4261e-04\n",
      "Epoch 158/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2826e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2375e-04\n",
      "Epoch 159/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0108 - mae: 0.0108 - mse: 2.2817e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2782e-04\n",
      "Epoch 160/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2720e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.4359e-04\n",
      "Epoch 161/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2668e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3541e-04\n",
      "Epoch 162/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2727e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2111e-04\n",
      "Epoch 163/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2688e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.3645e-04\n",
      "Epoch 164/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2674e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4161e-04\n",
      "Epoch 165/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2594e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2816e-04\n",
      "Epoch 166/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2539e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1863e-04\n",
      "Epoch 167/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2468e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2307e-04\n",
      "Epoch 168/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2439e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2483e-04\n",
      "Epoch 169/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2458e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2262e-04\n",
      "Epoch 170/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2395e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6121e-04\n",
      "Epoch 171/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2476e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3796e-04\n",
      "Epoch 172/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2411e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2314e-04\n",
      "Epoch 173/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2366e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1608e-04\n",
      "Epoch 174/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2375e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2208e-04\n",
      "Epoch 175/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0107 - mae: 0.0107 - mse: 2.2404e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.0309e-04\n",
      "Epoch 176/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2279e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2743e-04\n",
      "Epoch 177/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2283e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2908e-04\n",
      "Epoch 178/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2278e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3251e-04\n",
      "Epoch 179/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2234e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3068e-04\n",
      "Epoch 180/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2126e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.4085e-04\n",
      "Epoch 181/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2235e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.3995e-04\n",
      "Epoch 182/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2224e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3357e-04\n",
      "Epoch 183/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2091e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1278e-04\n",
      "Epoch 184/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2046e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2430e-04\n",
      "Epoch 185/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2137e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2904e-04\n",
      "Epoch 186/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1963e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2519e-04\n",
      "Epoch 187/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1937e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1222e-04\n",
      "Epoch 188/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2007e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.2061e-04\n",
      "Epoch 189/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1852e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.1753e-04\n",
      "Epoch 190/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.2019e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.2984e-04\n",
      "Epoch 191/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1963e-04 - val_loss: 0.0106 - val_mae: 0.0106 - val_mse: 2.2149e-04\n",
      "Epoch 192/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1919e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.2429e-04\n",
      "Epoch 193/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1872e-04 - val_loss: 0.0103 - val_mae: 0.0103 - val_mse: 2.1309e-04\n",
      "Epoch 194/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1867e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1582e-04\n",
      "Epoch 195/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1797e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.2344e-04\n",
      "Epoch 196/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1764e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1350e-04\n",
      "Epoch 197/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0106 - mse: 2.1904e-04 - val_loss: 0.0105 - val_mae: 0.0105 - val_mse: 2.1555e-04\n",
      "Epoch 198/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0105 - mae: 0.0105 - mse: 2.1743e-04 - val_loss: 0.0104 - val_mae: 0.0104 - val_mse: 2.1336e-04\n",
      "\u001b[1m9334/9334\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 862us/step\n",
      "-----------------------------------\n",
      "Se ha usado la opcion Standard para eliminar la capa oculta numero 3\n",
      "Mean Absolute Percentage Error (MAPE): 1.0338%\n",
      "DesviaciÃ³n estÃ¡ndar del MAPE: 1.053%\n",
      "Tiempo total de fine-tuning: 1280.16 segundos\n",
      "Ã‰pocas utilizadas en el fine-tuning: 198\n",
      "------------------------------------------------------------\n",
      "\n",
      "[EXPERIMENTO] Poda de la capa oculta nÃºmero: 4 usando Standard\n",
      "Eliminando la capa oculta #4 con 60 neuronas.\n",
      "Nueva arquitectura (neuronas): [60, 60, 60, 60]\n",
      "\n",
      "--- Resumen del Modelo Reducido ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,140</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_17 (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_52 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚        \u001b[38;5;34m10,140\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_53 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_54 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_55 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_56 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             â”‚         \u001b[38;5;34m1,464\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.0351 - mse: 0.0041 - val_loss: 0.0237 - val_mae: 0.0237 - val_mse: 0.0016\n",
      "Epoch 2/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0229 - mae: 0.0229 - mse: 0.0014 - val_loss: 0.0224 - val_mae: 0.0224 - val_mse: 0.0013\n",
      "Epoch 3/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0211 - mae: 0.0211 - mse: 0.0011 - val_loss: 0.0194 - val_mae: 0.0194 - val_mse: 9.6942e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0196 - mae: 0.0196 - mse: 9.3076e-04 - val_loss: 0.0190 - val_mae: 0.0190 - val_mse: 8.5512e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0190 - mae: 0.0190 - mse: 8.3526e-04 - val_loss: 0.0183 - val_mae: 0.0183 - val_mse: 7.7134e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0184 - mae: 0.0184 - mse: 7.7290e-04 - val_loss: 0.0176 - val_mae: 0.0176 - val_mse: 7.0745e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0179 - mae: 0.0179 - mse: 7.1951e-04 - val_loss: 0.0184 - val_mae: 0.0184 - val_mse: 7.3151e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0175 - mae: 0.0175 - mse: 6.8248e-04 - val_loss: 0.0169 - val_mae: 0.0169 - val_mse: 6.5853e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0172 - mae: 0.0172 - mse: 6.5246e-04 - val_loss: 0.0161 - val_mae: 0.0161 - val_mse: 5.8954e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0168 - mae: 0.0168 - mse: 6.1705e-04 - val_loss: 0.0162 - val_mae: 0.0162 - val_mse: 5.8170e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0166 - mae: 0.0166 - mse: 5.9314e-04 - val_loss: 0.0179 - val_mae: 0.0179 - val_mse: 6.8792e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0164 - mae: 0.0164 - mse: 5.7595e-04 - val_loss: 0.0155 - val_mae: 0.0155 - val_mse: 5.2705e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0161 - mse: 5.5252e-04 - val_loss: 0.0159 - val_mae: 0.0159 - val_mse: 5.4562e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0159 - mae: 0.0159 - mse: 5.3523e-04 - val_loss: 0.0180 - val_mae: 0.0180 - val_mse: 6.1164e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0156 - mae: 0.0156 - mse: 5.1658e-04 - val_loss: 0.0156 - val_mae: 0.0156 - val_mse: 5.1672e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0155 - mse: 5.0692e-04 - val_loss: 0.0156 - val_mae: 0.0156 - val_mse: 5.0788e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0153 - mae: 0.0153 - mse: 4.8925e-04 - val_loss: 0.0150 - val_mae: 0.0150 - val_mse: 4.8459e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0153 - mae: 0.0153 - mse: 4.8647e-04 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 4.4921e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0151 - mae: 0.0151 - mse: 4.7584e-04 - val_loss: 0.0156 - val_mae: 0.0156 - val_mse: 4.8889e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0149 - mae: 0.0149 - mse: 4.6232e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 4.4532e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0150 - mae: 0.0150 - mse: 4.6371e-04 - val_loss: 0.0155 - val_mae: 0.0155 - val_mse: 4.9398e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0146 - mse: 4.4621e-04 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 4.3375e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0146 - mse: 4.4056e-04 - val_loss: 0.0141 - val_mae: 0.0141 - val_mse: 4.1700e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0146 - mse: 4.4029e-04 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 5.3169e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0144 - mae: 0.0144 - mse: 4.3186e-04 - val_loss: 0.0142 - val_mae: 0.0142 - val_mse: 4.1860e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0143 - mse: 4.2359e-04 - val_loss: 0.0143 - val_mae: 0.0143 - val_mse: 4.1576e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0142 - mae: 0.0142 - mse: 4.1730e-04 - val_loss: 0.0146 - val_mae: 0.0146 - val_mse: 4.3914e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0142 - mae: 0.0142 - mse: 4.1356e-04 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 3.9797e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0141 - mse: 4.0864e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.8011e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0140 - mse: 4.0562e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.9090e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0140 - mse: 4.0194e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 4.1477e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.9254e-04 - val_loss: 0.0148 - val_mae: 0.0148 - val_mse: 4.4908e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.9017e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.6815e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0138 - mse: 3.8890e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 4.0057e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0137 - mse: 3.8386e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.5990e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0136 - mse: 3.7893e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.7819e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.7480e-04 - val_loss: 0.0139 - val_mae: 0.0139 - val_mse: 4.0560e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.7306e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.7053e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0134 - mse: 3.6725e-04 - val_loss: 0.0141 - val_mae: 0.0141 - val_mse: 3.9271e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.6453e-04 - val_loss: 0.0154 - val_mae: 0.0154 - val_mse: 4.3906e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.6124e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.5550e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.6054e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.6834e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5411e-04 - val_loss: 0.0133 - val_mae: 0.0133 - val_mse: 3.7381e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.5113e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.3051e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.4875e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.7255e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.4808e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.2455e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.4440e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.3596e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.4011e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.1858e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.3721e-04 - val_loss: 0.0140 - val_mae: 0.0140 - val_mse: 3.7612e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.3327e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.4924e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.3338e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.2665e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.3011e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.6541e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2773e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.4554e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2468e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0983e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2292e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 3.0854e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1835e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0956e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1955e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 3.0611e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1548e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9971e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1277e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9942e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1302e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 3.0735e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0990e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.2790e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0665e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.4226e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0653e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.9088e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0391e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.9665e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0273e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.9161e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0132e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9627e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9875e-04 - val_loss: 0.0147 - val_mae: 0.0147 - val_mse: 3.9470e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9645e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.0099e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9466e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8992e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.9118e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8621e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9163e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.8535e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.9017e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8815e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8798e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7392e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8734e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7745e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8417e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.9378e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8363e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7844e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8245e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8504e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8071e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.8015e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7789e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7080e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7867e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6693e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7722e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8508e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7432e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7395e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7487e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.7111e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7362e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7446e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.7038e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6901e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6933e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6125e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6678e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6197e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6832e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6004e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6666e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7735e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6462e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 3.0462e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6334e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6548e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6201e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6743e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6137e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5361e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.6041e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5905e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.6012e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.2342e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5850e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6273e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5751e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5073e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5608e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5154e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5406e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5780e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5476e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4918e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5374e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5484e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5287e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.6749e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5297e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4771e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5216e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4968e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.5099e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4664e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4991e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5247e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4888e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5193e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4946e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4112e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4793e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.8502e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4758e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5949e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4801e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4481e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4715e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4050e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4520e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4219e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4452e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3863e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4425e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4722e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4355e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3422e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4354e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7043e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4201e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4523e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4160e-04 - val_loss: 0.0107 - val_mae: 0.0107 - val_mse: 2.3255e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4198e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4912e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4096e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.5367e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4104e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3790e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3921e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4590e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.4037e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.6081e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3936e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.4083e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3775e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.6091e-04\n",
      "Epoch 127/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3928e-04 - val_loss: 0.0127 - val_mae: 0.0127 - val_mse: 2.9348e-04\n",
      "Epoch 128/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3716e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4205e-04\n",
      "Epoch 129/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3773e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3480e-04\n",
      "Epoch 130/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3651e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4519e-04\n",
      "Epoch 131/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0110 - mse: 2.3690e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3679e-04\n",
      "Epoch 132/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3512e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.4106e-04\n",
      "Epoch 133/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3481e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4337e-04\n",
      "Epoch 134/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0109 - mae: 0.0109 - mse: 2.3472e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.3772e-04\n",
      "\u001b[1m9334/9334\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 849us/step\n",
      "-----------------------------------\n",
      "Se ha usado la opcion Standard para eliminar la capa oculta numero 4\n",
      "Mean Absolute Percentage Error (MAPE): 1.0801%\n",
      "DesviaciÃ³n estÃ¡ndar del MAPE: 1.116%\n",
      "Tiempo total de fine-tuning: 892.95 segundos\n",
      "Ã‰pocas utilizadas en el fine-tuning: 134\n",
      "------------------------------------------------------------\n",
      "\n",
      "[EXPERIMENTO] Poda de la capa oculta nÃºmero: 5 usando Standard\n",
      "Eliminando la capa oculta #5 con 60 neuronas.\n",
      "Nueva arquitectura (neuronas): [60, 60, 60, 60]\n",
      "\n",
      "--- Resumen del Modelo Reducido ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,140</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,660</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,464</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_18 (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m168\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_57 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚        \u001b[38;5;34m10,140\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_58 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_59 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_60 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)             â”‚         \u001b[38;5;34m3,660\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_61 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             â”‚         \u001b[38;5;34m1,464\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,584</span> (88.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,584\u001b[0m (88.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.0342 - mse: 0.0038 - val_loss: 0.0241 - val_mae: 0.0241 - val_mse: 0.0016\n",
      "Epoch 2/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0229 - mae: 0.0229 - mse: 0.0014 - val_loss: 0.0213 - val_mae: 0.0213 - val_mse: 0.0012\n",
      "Epoch 3/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0210 - mae: 0.0210 - mse: 0.0011 - val_loss: 0.0195 - val_mae: 0.0195 - val_mse: 9.7794e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0194 - mae: 0.0194 - mse: 9.1493e-04 - val_loss: 0.0182 - val_mae: 0.0182 - val_mse: 8.1782e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0188 - mae: 0.0188 - mse: 8.2137e-04 - val_loss: 0.0186 - val_mae: 0.0186 - val_mse: 7.7723e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0182 - mae: 0.0182 - mse: 7.5237e-04 - val_loss: 0.0180 - val_mae: 0.0180 - val_mse: 7.1213e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0177 - mae: 0.0177 - mse: 6.9615e-04 - val_loss: 0.0175 - val_mae: 0.0175 - val_mse: 6.6705e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0173 - mae: 0.0173 - mse: 6.5963e-04 - val_loss: 0.0164 - val_mae: 0.0164 - val_mse: 6.0918e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0170 - mae: 0.0170 - mse: 6.3129e-04 - val_loss: 0.0158 - val_mae: 0.0158 - val_mse: 5.7328e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0166 - mae: 0.0166 - mse: 6.0106e-04 - val_loss: 0.0169 - val_mae: 0.0169 - val_mse: 5.9186e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0163 - mae: 0.0163 - mse: 5.7828e-04 - val_loss: 0.0163 - val_mae: 0.0163 - val_mse: 5.5461e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0162 - mae: 0.0162 - mse: 5.6366e-04 - val_loss: 0.0154 - val_mae: 0.0154 - val_mse: 5.2380e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0160 - mse: 5.4873e-04 - val_loss: 0.0243 - val_mae: 0.0243 - val_mse: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0159 - mae: 0.0159 - mse: 5.3928e-04 - val_loss: 0.0161 - val_mae: 0.0161 - val_mse: 5.4424e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0156 - mae: 0.0156 - mse: 5.1783e-04 - val_loss: 0.0170 - val_mae: 0.0170 - val_mse: 5.6222e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0156 - mae: 0.0156 - mse: 5.1261e-04 - val_loss: 0.0153 - val_mae: 0.0153 - val_mse: 5.0366e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0153 - mae: 0.0153 - mse: 4.9849e-04 - val_loss: 0.0150 - val_mae: 0.0150 - val_mse: 4.7965e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0152 - mae: 0.0152 - mse: 4.8832e-04 - val_loss: 0.0152 - val_mae: 0.0152 - val_mse: 4.7364e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0152 - mae: 0.0152 - mse: 4.8473e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 4.5065e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0149 - mae: 0.0149 - mse: 4.6703e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 4.4189e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0148 - mae: 0.0148 - mse: 4.5717e-04 - val_loss: 0.0154 - val_mae: 0.0154 - val_mse: 4.8267e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0146 - mse: 4.4736e-04 - val_loss: 0.0144 - val_mae: 0.0144 - val_mse: 4.3136e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0146 - mse: 4.4344e-04 - val_loss: 0.0139 - val_mae: 0.0139 - val_mse: 4.1313e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0144 - mae: 0.0144 - mse: 4.3227e-04 - val_loss: 0.0182 - val_mae: 0.0182 - val_mse: 6.3620e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0143 - mse: 4.2306e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 4.0576e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0143 - mse: 4.1929e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.9741e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0142 - mse: 4.1195e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.9154e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0141 - mse: 4.0692e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.9414e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.9915e-04 - val_loss: 0.0140 - val_mae: 0.0140 - val_mse: 3.9411e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.9410e-04 - val_loss: 0.0136 - val_mae: 0.0136 - val_mse: 3.7941e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0139 - mse: 3.9109e-04 - val_loss: 0.0135 - val_mae: 0.0135 - val_mse: 3.7062e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0137 - mae: 0.0137 - mse: 3.8316e-04 - val_loss: 0.0152 - val_mae: 0.0152 - val_mse: 4.3143e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0137 - mae: 0.0137 - mse: 3.7935e-04 - val_loss: 0.0134 - val_mae: 0.0134 - val_mse: 3.6307e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0135 - mae: 0.0135 - mse: 3.7228e-04 - val_loss: 0.0137 - val_mae: 0.0137 - val_mse: 3.7474e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0136 - mse: 3.7224e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.4461e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0134 - mse: 3.6420e-04 - val_loss: 0.0131 - val_mae: 0.0131 - val_mse: 3.4471e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0134 - mse: 3.6126e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.3638e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0133 - mse: 3.5556e-04 - val_loss: 0.0143 - val_mae: 0.0143 - val_mse: 3.8846e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5360e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.4337e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0132 - mse: 3.5070e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.3263e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0131 - mse: 3.4608e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.3190e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.4189e-04 - val_loss: 0.0132 - val_mae: 0.0132 - val_mse: 3.3664e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0130 - mse: 3.3828e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.3422e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.3574e-04 - val_loss: 0.0145 - val_mae: 0.0145 - val_mse: 3.8501e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0129 - mse: 3.3563e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1518e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.2947e-04 - val_loss: 0.0148 - val_mae: 0.0148 - val_mse: 3.8805e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.2872e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1761e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0128 - mae: 0.0128 - mse: 3.2541e-04 - val_loss: 0.0136 - val_mae: 0.0136 - val_mse: 3.5879e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0127 - mae: 0.0127 - mse: 3.2225e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.5917e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1830e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 3.1641e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1624e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.2760e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0126 - mse: 3.1532e-04 - val_loss: 0.0129 - val_mae: 0.0129 - val_mse: 3.2886e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1146e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.2737e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0125 - mae: 0.0125 - mse: 3.1004e-04 - val_loss: 0.0124 - val_mae: 0.0124 - val_mse: 3.0535e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0807e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 3.1616e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0530e-04 - val_loss: 0.0126 - val_mae: 0.0126 - val_mse: 3.1416e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0124 - mse: 3.0443e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9071e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0171e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8480e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0123 - mse: 3.0055e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8619e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9749e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8549e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0122 - mse: 2.9534e-04 - val_loss: 0.0130 - val_mae: 0.0130 - val_mse: 3.2243e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9341e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.8319e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9129e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 3.0074e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0121 - mse: 2.9234e-04 - val_loss: 0.0120 - val_mae: 0.0120 - val_mse: 2.8676e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8907e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7715e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8615e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.9113e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8444e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.9008e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0120 - mse: 2.8592e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.8815e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8111e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.7994e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.8107e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6519e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0119 - mae: 0.0119 - mse: 2.7953e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.7400e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7809e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.8920e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7603e-04 - val_loss: 0.0122 - val_mae: 0.0122 - val_mse: 2.8874e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7475e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7357e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0118 - mse: 2.7481e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6577e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7156e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5858e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.7193e-04 - val_loss: 0.0123 - val_mae: 0.0123 - val_mse: 2.8648e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6984e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5898e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6894e-04 - val_loss: 0.0125 - val_mae: 0.0125 - val_mse: 2.9563e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0117 - mse: 2.6917e-04 - val_loss: 0.0115 - val_mae: 0.0115 - val_mse: 2.6496e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6774e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5848e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6640e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7825e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6475e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5420e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6499e-04 - val_loss: 0.0118 - val_mae: 0.0118 - val_mse: 2.6772e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0116 - mse: 2.6413e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5816e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6244e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4904e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6152e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5667e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.6112e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4797e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0115 - mse: 2.5974e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5263e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5834e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4934e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5832e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.5810e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5724e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5574e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5533e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.4964e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5611e-04 - val_loss: 0.0114 - val_mae: 0.0114 - val_mse: 2.6529e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5473e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 2.9675e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5390e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5037e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5309e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4505e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5273e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4398e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0114 - mse: 2.5361e-04 - val_loss: 0.0119 - val_mae: 0.0119 - val_mse: 2.7107e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5095e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4344e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.5102e-04 - val_loss: 0.0108 - val_mae: 0.0108 - val_mse: 2.3582e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4892e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.5019e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0113 - mse: 2.4952e-04 - val_loss: 0.0117 - val_mae: 0.0117 - val_mse: 2.6265e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4789e-04 - val_loss: 0.0113 - val_mae: 0.0113 - val_mse: 2.5022e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4811e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4658e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4642e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3503e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4634e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4427e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4703e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4244e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4559e-04 - val_loss: 0.0116 - val_mae: 0.0116 - val_mse: 2.5727e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4405e-04 - val_loss: 0.0111 - val_mae: 0.0111 - val_mse: 2.4346e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4439e-04 - val_loss: 0.0128 - val_mae: 0.0128 - val_mse: 2.9506e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4367e-04 - val_loss: 0.0138 - val_mae: 0.0138 - val_mse: 3.2707e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0112 - mae: 0.0112 - mse: 2.4420e-04 - val_loss: 0.0121 - val_mae: 0.0121 - val_mse: 2.7465e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4216e-04 - val_loss: 0.0110 - val_mae: 0.0110 - val_mse: 2.4483e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4216e-04 - val_loss: 0.0109 - val_mae: 0.0109 - val_mse: 2.3582e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m1906/1906\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0111 - mse: 2.4070e-04 - val_loss: 0.0112 - val_mae: 0.0112 - val_mse: 2.4540e-04\n",
      "\u001b[1m9334/9334\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 858us/step\n",
      "-----------------------------------\n",
      "Se ha usado la opcion Standard para eliminar la capa oculta numero 5\n",
      "Mean Absolute Percentage Error (MAPE): 1.0903%\n",
      "DesviaciÃ³n estÃ¡ndar del MAPE: 1.128%\n",
      "Tiempo total de fine-tuning: 757.69 segundos\n",
      "Ã‰pocas utilizadas en el fine-tuning: 116\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "=============== RESUMEN FINAL DE LA PODA POR CAPA ===============\n",
      "Capa #1: MAPE=1.0472%, Desv Std=1.0827%,  Tiempo=1091.39s, Ã‰pocas=169\n",
      "Capa #2: MAPE=1.0960%, Desv Std=1.1251%,  Tiempo=822.97s, Ã‰pocas=126\n",
      "Capa #3: MAPE=1.0338%, Desv Std=1.0532%,  Tiempo=1280.16s, Ã‰pocas=198\n",
      "Capa #4: MAPE=1.0801%, Desv Std=1.1161%,  Tiempo=892.95s, Ã‰pocas=134\n",
      "Capa #5: MAPE=1.0903%, Desv Std=1.1280%,  Tiempo=757.69s, Ã‰pocas=116\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "# FOR LOOP CODE TO ITERATE OVER LAYERS TO BE PRUNED USING 3 METHODOLOGIES\n",
    "\n",
    "# Indices are 1-based\n",
    "layers_to_prune = [1, 2, 3, 4, 5]\n",
    "pruning_strategy = 3  # Fix the methodology\n",
    "strategy_map = {1: \"BS\", 2: \"FS\", 3: \"Standard\"}\n",
    "strategy_text = strategy_map.get(pruning_strategy, \"Unknown Option\")\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "print(f\"--- Starting evaluation of {strategy_text} Pruning on {len(layers_to_prune)} layers ---\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# --- Load dataset for denormalization ---\n",
    "original_data = pd.read_csv('dataset.csv')\n",
    "min_val = original_data['consumption'].min()\n",
    "max_val = original_data['consumption'].max()\n",
    "\n",
    "# --- Experimentation Loop ---\n",
    "\n",
    "for target_layer in layers_to_prune:\n",
    "    # Configure Early Stopping for each iteration\n",
    "    early_stopping_pruned = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[EXPERIMENT] Pruning hidden layer number: {target_layer} using {strategy_text}\")\n",
    "    \n",
    "    # Select the pruning strategy\n",
    "    if pruning_strategy == 1:\n",
    "        model_pruned = backward_strategy_prune(model, target_layer)\n",
    "    elif pruning_strategy == 2:\n",
    "        model_pruned = forward_strategy_prune(model, target_layer)\n",
    "    elif pruning_strategy == 3:\n",
    "        model_pruned = standard_pruning(model, target_layer)\n",
    "\n",
    "    # Fine-tuning the pruned model\n",
    "    start_time_ft = time.time()\n",
    "    history_pruned = model_pruned.fit(\n",
    "        X_train_norm, \n",
    "        y_train_norm, \n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size, \n",
    "        validation_data=(X_val_norm, y_val_norm), \n",
    "        callbacks=[early_stopping_pruned]\n",
    "    )\n",
    "    end_time_ft = time.time()\n",
    "    \n",
    "    # Perform predictions on test set\n",
    "    y_pred_pruned = model_pruned.predict(X_test_norm)\n",
    "\n",
    "    # --- Denormalization Process (N x 24 Arrays) ---\n",
    "    y_pred_denorm = y_pred_pruned * (max_val - min_val) + min_val\n",
    "    y_test_denorm = y_test * (max_val - min_val) + min_val\n",
    "\n",
    "    # Calculate global MAPE\n",
    "    mape_pruned = mean_absolute_percentage_error(y_test_denorm, y_pred_denorm) * 100\n",
    "\n",
    "    # --- MAPE STANDARD DEVIATION CALCULATION ---\n",
    "\n",
    "    # 1. Flatten arrays for point-by-point error calculation\n",
    "    y_true_flat = y_test_denorm.flatten()\n",
    "    y_pred_flat = y_pred_denorm.flatten()\n",
    "\n",
    "    # 2. Handle division by zero (using epsilon)\n",
    "    epsilon = np.finfo(np.float32).eps \n",
    "    y_true_for_mape = np.copy(y_true_flat)\n",
    "    y_true_for_mape[y_true_for_mape == 0] = epsilon\n",
    "\n",
    "    # 3. Calculate Absolute Percentage Error (APE)\n",
    "    absolute_percentage_errors = (np.abs(y_true_flat - y_pred_flat) / y_true_for_mape) * 100\n",
    "\n",
    "    # 4. Calculate Standard Deviation\n",
    "    std_dev_mape = np.std(absolute_percentage_errors) \n",
    "\n",
    "    # --- Print Iteration Results ---\n",
    "    print(\"-\" * 35)\n",
    "    print(f'Methodology: {strategy_text} | Target Layer: {target_layer}')\n",
    "    print(f'Mean Absolute Percentage Error (MAPE): {mape_pruned:.4f}%')\n",
    "    print(f\"MAPE Standard Deviation: {std_dev_mape:.3f}%\")\n",
    "    \n",
    "    ft_duration = end_time_ft - start_time_ft\n",
    "    print(f\"Total fine-tuning time: {ft_duration:.2f} seconds\")\n",
    "    \n",
    "    final_epochs = len(history_pruned.history['loss'])\n",
    "    print(f\"Epochs used in fine-tuning: {final_epochs}\")\n",
    "    \n",
    "    # Store results for final summary\n",
    "    comparison_results.append({\n",
    "        'strategy': strategy_text,\n",
    "        'pruned_layer': target_layer,\n",
    "        'std_dev': std_dev_mape,\n",
    "        'mape': mape_pruned,\n",
    "        'duration': ft_duration,\n",
    "        'epochs': final_epochs\n",
    "    })\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# --- Final Summary Table ---\n",
    "print(\"\\n\\n=============== FINAL PRUNING SUMMARY BY LAYER ===============\")\n",
    "print(f\"{'Layer':<10} | {'MAPE':<12} | {'Std Dev':<12} | {'Time (s)':<10} | {'Epochs':<8}\")\n",
    "print(\"-\" * 65)\n",
    "for res in comparison_results:\n",
    "    print(f\"#{res['pruned_layer']:<9} | {res['mape']:<11.4f}% | {res['std_dev']:<11.4f}% | {res['duration']:<9.2f} | {res['epochs']:<7}\")\n",
    "print(\"================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filename using strategy and target layer index\n",
    "# filename = f\"PredictionResults/MartinDataset_Methodology-{pruning_strategy}_HiddenLayer-{target_layer}.csv\"\n",
    "\n",
    "# Save results to a CSV file with semicolon as delimiter\n",
    "# results_pruned.to_csv(filename, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation metrics for the pruned model\n",
    "train_val_graph(history_pruned, target_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
